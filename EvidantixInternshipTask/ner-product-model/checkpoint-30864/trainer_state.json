{
  "best_global_step": 30864,
  "best_metric": 0.996487180831542,
  "best_model_checkpoint": "ner-product-model/checkpoint-30864",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 30864,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0019440124416796269,
      "grad_norm": 5.976772785186768,
      "learning_rate": 3.4992223950233286e-08,
      "loss": 1.0987,
      "step": 10
    },
    {
      "epoch": 0.0038880248833592537,
      "grad_norm": 6.584815502166748,
      "learning_rate": 7.387247278382582e-08,
      "loss": 1.097,
      "step": 20
    },
    {
      "epoch": 0.00583203732503888,
      "grad_norm": 4.721055030822754,
      "learning_rate": 1.1275272161741835e-07,
      "loss": 1.1084,
      "step": 30
    },
    {
      "epoch": 0.007776049766718507,
      "grad_norm": 4.849710941314697,
      "learning_rate": 1.516329704510109e-07,
      "loss": 1.1103,
      "step": 40
    },
    {
      "epoch": 0.009720062208398134,
      "grad_norm": 4.31583309173584,
      "learning_rate": 1.9051321928460342e-07,
      "loss": 1.1017,
      "step": 50
    },
    {
      "epoch": 0.01166407465007776,
      "grad_norm": 5.6807169914245605,
      "learning_rate": 2.2939346811819596e-07,
      "loss": 1.094,
      "step": 60
    },
    {
      "epoch": 0.013608087091757388,
      "grad_norm": 5.160384178161621,
      "learning_rate": 2.682737169517885e-07,
      "loss": 1.0559,
      "step": 70
    },
    {
      "epoch": 0.015552099533437015,
      "grad_norm": 4.902927398681641,
      "learning_rate": 3.0715396578538105e-07,
      "loss": 1.0618,
      "step": 80
    },
    {
      "epoch": 0.017496111975116642,
      "grad_norm": 4.073573112487793,
      "learning_rate": 3.460342146189736e-07,
      "loss": 1.042,
      "step": 90
    },
    {
      "epoch": 0.019440124416796267,
      "grad_norm": 4.989640712738037,
      "learning_rate": 3.849144634525661e-07,
      "loss": 1.0327,
      "step": 100
    },
    {
      "epoch": 0.021384136858475893,
      "grad_norm": 5.308993816375732,
      "learning_rate": 4.237947122861586e-07,
      "loss": 1.0042,
      "step": 110
    },
    {
      "epoch": 0.02332814930015552,
      "grad_norm": 5.159919261932373,
      "learning_rate": 4.626749611197512e-07,
      "loss": 1.0004,
      "step": 120
    },
    {
      "epoch": 0.025272161741835147,
      "grad_norm": 6.198256492614746,
      "learning_rate": 5.015552099533437e-07,
      "loss": 1.0125,
      "step": 130
    },
    {
      "epoch": 0.027216174183514776,
      "grad_norm": 4.8221964836120605,
      "learning_rate": 5.404354587869362e-07,
      "loss": 1.0222,
      "step": 140
    },
    {
      "epoch": 0.0291601866251944,
      "grad_norm": 4.168514251708984,
      "learning_rate": 5.793157076205288e-07,
      "loss": 0.9393,
      "step": 150
    },
    {
      "epoch": 0.03110419906687403,
      "grad_norm": 5.478057384490967,
      "learning_rate": 6.181959564541214e-07,
      "loss": 0.9395,
      "step": 160
    },
    {
      "epoch": 0.03304821150855365,
      "grad_norm": 4.718171119689941,
      "learning_rate": 6.570762052877139e-07,
      "loss": 0.9597,
      "step": 170
    },
    {
      "epoch": 0.034992223950233284,
      "grad_norm": 5.1758880615234375,
      "learning_rate": 6.959564541213064e-07,
      "loss": 0.8758,
      "step": 180
    },
    {
      "epoch": 0.03693623639191291,
      "grad_norm": 3.949373722076416,
      "learning_rate": 7.34836702954899e-07,
      "loss": 0.929,
      "step": 190
    },
    {
      "epoch": 0.038880248833592534,
      "grad_norm": 4.934795379638672,
      "learning_rate": 7.737169517884915e-07,
      "loss": 0.8481,
      "step": 200
    },
    {
      "epoch": 0.04082426127527216,
      "grad_norm": 4.391996383666992,
      "learning_rate": 8.12597200622084e-07,
      "loss": 0.8695,
      "step": 210
    },
    {
      "epoch": 0.042768273716951785,
      "grad_norm": 4.810366153717041,
      "learning_rate": 8.514774494556766e-07,
      "loss": 0.8681,
      "step": 220
    },
    {
      "epoch": 0.04471228615863142,
      "grad_norm": 4.265420436859131,
      "learning_rate": 8.90357698289269e-07,
      "loss": 0.8149,
      "step": 230
    },
    {
      "epoch": 0.04665629860031104,
      "grad_norm": 3.3827126026153564,
      "learning_rate": 9.292379471228615e-07,
      "loss": 0.8433,
      "step": 240
    },
    {
      "epoch": 0.04860031104199067,
      "grad_norm": 4.313113212585449,
      "learning_rate": 9.68118195956454e-07,
      "loss": 0.8116,
      "step": 250
    },
    {
      "epoch": 0.05054432348367029,
      "grad_norm": 4.444670677185059,
      "learning_rate": 1.0069984447900468e-06,
      "loss": 0.773,
      "step": 260
    },
    {
      "epoch": 0.052488335925349926,
      "grad_norm": 4.5754194259643555,
      "learning_rate": 1.0458786936236391e-06,
      "loss": 0.7742,
      "step": 270
    },
    {
      "epoch": 0.05443234836702955,
      "grad_norm": 3.458894968032837,
      "learning_rate": 1.0847589424572319e-06,
      "loss": 0.7248,
      "step": 280
    },
    {
      "epoch": 0.056376360808709176,
      "grad_norm": 5.236632347106934,
      "learning_rate": 1.1236391912908242e-06,
      "loss": 0.7527,
      "step": 290
    },
    {
      "epoch": 0.0583203732503888,
      "grad_norm": 4.402448654174805,
      "learning_rate": 1.162519440124417e-06,
      "loss": 0.7122,
      "step": 300
    },
    {
      "epoch": 0.06026438569206843,
      "grad_norm": 4.217493057250977,
      "learning_rate": 1.2013996889580093e-06,
      "loss": 0.6805,
      "step": 310
    },
    {
      "epoch": 0.06220839813374806,
      "grad_norm": 3.8909530639648438,
      "learning_rate": 1.2402799377916018e-06,
      "loss": 0.6744,
      "step": 320
    },
    {
      "epoch": 0.06415241057542768,
      "grad_norm": 5.080102443695068,
      "learning_rate": 1.2791601866251943e-06,
      "loss": 0.638,
      "step": 330
    },
    {
      "epoch": 0.0660964230171073,
      "grad_norm": 3.969595432281494,
      "learning_rate": 1.3180404354587869e-06,
      "loss": 0.5997,
      "step": 340
    },
    {
      "epoch": 0.06804043545878694,
      "grad_norm": 3.868227958679199,
      "learning_rate": 1.3569206842923796e-06,
      "loss": 0.5611,
      "step": 350
    },
    {
      "epoch": 0.06998444790046657,
      "grad_norm": 3.6963417530059814,
      "learning_rate": 1.395800933125972e-06,
      "loss": 0.5228,
      "step": 360
    },
    {
      "epoch": 0.07192846034214619,
      "grad_norm": 6.656741142272949,
      "learning_rate": 1.4346811819595647e-06,
      "loss": 0.5822,
      "step": 370
    },
    {
      "epoch": 0.07387247278382582,
      "grad_norm": 3.5486762523651123,
      "learning_rate": 1.473561430793157e-06,
      "loss": 0.4923,
      "step": 380
    },
    {
      "epoch": 0.07581648522550544,
      "grad_norm": 3.8877413272857666,
      "learning_rate": 1.5124416796267498e-06,
      "loss": 0.5459,
      "step": 390
    },
    {
      "epoch": 0.07776049766718507,
      "grad_norm": 4.369079113006592,
      "learning_rate": 1.551321928460342e-06,
      "loss": 0.4433,
      "step": 400
    },
    {
      "epoch": 0.0797045101088647,
      "grad_norm": 4.177433967590332,
      "learning_rate": 1.5902021772939348e-06,
      "loss": 0.4805,
      "step": 410
    },
    {
      "epoch": 0.08164852255054432,
      "grad_norm": 3.692223072052002,
      "learning_rate": 1.6290824261275271e-06,
      "loss": 0.4297,
      "step": 420
    },
    {
      "epoch": 0.08359253499222395,
      "grad_norm": 3.6091206073760986,
      "learning_rate": 1.66796267496112e-06,
      "loss": 0.3916,
      "step": 430
    },
    {
      "epoch": 0.08553654743390357,
      "grad_norm": 3.2595834732055664,
      "learning_rate": 1.7068429237947122e-06,
      "loss": 0.3893,
      "step": 440
    },
    {
      "epoch": 0.0874805598755832,
      "grad_norm": 2.6798219680786133,
      "learning_rate": 1.745723172628305e-06,
      "loss": 0.4016,
      "step": 450
    },
    {
      "epoch": 0.08942457231726283,
      "grad_norm": 4.6364336013793945,
      "learning_rate": 1.7846034214618975e-06,
      "loss": 0.3298,
      "step": 460
    },
    {
      "epoch": 0.09136858475894245,
      "grad_norm": 6.353128910064697,
      "learning_rate": 1.82348367029549e-06,
      "loss": 0.3544,
      "step": 470
    },
    {
      "epoch": 0.09331259720062209,
      "grad_norm": 3.214402198791504,
      "learning_rate": 1.8623639191290826e-06,
      "loss": 0.3568,
      "step": 480
    },
    {
      "epoch": 0.0952566096423017,
      "grad_norm": 3.164005756378174,
      "learning_rate": 1.9012441679626749e-06,
      "loss": 0.3673,
      "step": 490
    },
    {
      "epoch": 0.09720062208398134,
      "grad_norm": 3.7669711112976074,
      "learning_rate": 1.9401244167962676e-06,
      "loss": 0.298,
      "step": 500
    },
    {
      "epoch": 0.09914463452566097,
      "grad_norm": 3.736581802368164,
      "learning_rate": 1.9790046656298604e-06,
      "loss": 0.3715,
      "step": 510
    },
    {
      "epoch": 0.10108864696734059,
      "grad_norm": 5.237093925476074,
      "learning_rate": 2.0178849144634523e-06,
      "loss": 0.3381,
      "step": 520
    },
    {
      "epoch": 0.10303265940902022,
      "grad_norm": 6.035196304321289,
      "learning_rate": 2.056765163297045e-06,
      "loss": 0.3087,
      "step": 530
    },
    {
      "epoch": 0.10497667185069985,
      "grad_norm": 3.949709892272949,
      "learning_rate": 2.0956454121306378e-06,
      "loss": 0.2844,
      "step": 540
    },
    {
      "epoch": 0.10692068429237947,
      "grad_norm": 3.8889150619506836,
      "learning_rate": 2.1345256609642305e-06,
      "loss": 0.2423,
      "step": 550
    },
    {
      "epoch": 0.1088646967340591,
      "grad_norm": 3.4912126064300537,
      "learning_rate": 2.1734059097978224e-06,
      "loss": 0.3248,
      "step": 560
    },
    {
      "epoch": 0.11080870917573872,
      "grad_norm": 5.084039211273193,
      "learning_rate": 2.212286158631415e-06,
      "loss": 0.247,
      "step": 570
    },
    {
      "epoch": 0.11275272161741835,
      "grad_norm": 5.128610610961914,
      "learning_rate": 2.251166407465008e-06,
      "loss": 0.2454,
      "step": 580
    },
    {
      "epoch": 0.11469673405909799,
      "grad_norm": 2.2829456329345703,
      "learning_rate": 2.2900466562986006e-06,
      "loss": 0.2309,
      "step": 590
    },
    {
      "epoch": 0.1166407465007776,
      "grad_norm": 6.212671279907227,
      "learning_rate": 2.328926905132193e-06,
      "loss": 0.3629,
      "step": 600
    },
    {
      "epoch": 0.11858475894245724,
      "grad_norm": 5.364411354064941,
      "learning_rate": 2.3678071539657853e-06,
      "loss": 0.1669,
      "step": 610
    },
    {
      "epoch": 0.12052877138413685,
      "grad_norm": 3.3672215938568115,
      "learning_rate": 2.406687402799378e-06,
      "loss": 0.2648,
      "step": 620
    },
    {
      "epoch": 0.12247278382581649,
      "grad_norm": 8.122859954833984,
      "learning_rate": 2.4455676516329708e-06,
      "loss": 0.2317,
      "step": 630
    },
    {
      "epoch": 0.12441679626749612,
      "grad_norm": 5.08116340637207,
      "learning_rate": 2.484447900466563e-06,
      "loss": 0.1835,
      "step": 640
    },
    {
      "epoch": 0.12636080870917574,
      "grad_norm": 3.145751476287842,
      "learning_rate": 2.5233281493001554e-06,
      "loss": 0.2616,
      "step": 650
    },
    {
      "epoch": 0.12830482115085537,
      "grad_norm": 8.513029098510742,
      "learning_rate": 2.562208398133748e-06,
      "loss": 0.3281,
      "step": 660
    },
    {
      "epoch": 0.130248833592535,
      "grad_norm": 1.4203307628631592,
      "learning_rate": 2.6010886469673405e-06,
      "loss": 0.1569,
      "step": 670
    },
    {
      "epoch": 0.1321928460342146,
      "grad_norm": 4.85371208190918,
      "learning_rate": 2.6399688958009332e-06,
      "loss": 0.2588,
      "step": 680
    },
    {
      "epoch": 0.13413685847589424,
      "grad_norm": 2.865786552429199,
      "learning_rate": 2.6788491446345256e-06,
      "loss": 0.1455,
      "step": 690
    },
    {
      "epoch": 0.13608087091757387,
      "grad_norm": 4.630277156829834,
      "learning_rate": 2.7177293934681183e-06,
      "loss": 0.1672,
      "step": 700
    },
    {
      "epoch": 0.1380248833592535,
      "grad_norm": 10.48057746887207,
      "learning_rate": 2.7566096423017106e-06,
      "loss": 0.2512,
      "step": 710
    },
    {
      "epoch": 0.13996889580093314,
      "grad_norm": 3.5179247856140137,
      "learning_rate": 2.7954898911353034e-06,
      "loss": 0.2242,
      "step": 720
    },
    {
      "epoch": 0.14191290824261274,
      "grad_norm": 3.5543174743652344,
      "learning_rate": 2.834370139968896e-06,
      "loss": 0.2063,
      "step": 730
    },
    {
      "epoch": 0.14385692068429237,
      "grad_norm": 3.759005308151245,
      "learning_rate": 2.8732503888024884e-06,
      "loss": 0.157,
      "step": 740
    },
    {
      "epoch": 0.145800933125972,
      "grad_norm": 6.108063220977783,
      "learning_rate": 2.9121306376360808e-06,
      "loss": 0.2173,
      "step": 750
    },
    {
      "epoch": 0.14774494556765164,
      "grad_norm": 2.9650208950042725,
      "learning_rate": 2.9510108864696735e-06,
      "loss": 0.1963,
      "step": 760
    },
    {
      "epoch": 0.14968895800933127,
      "grad_norm": 5.088470935821533,
      "learning_rate": 2.9898911353032663e-06,
      "loss": 0.1263,
      "step": 770
    },
    {
      "epoch": 0.15163297045101087,
      "grad_norm": 0.4492734968662262,
      "learning_rate": 3.0287713841368586e-06,
      "loss": 0.1433,
      "step": 780
    },
    {
      "epoch": 0.1535769828926905,
      "grad_norm": 5.574378967285156,
      "learning_rate": 3.067651632970451e-06,
      "loss": 0.2024,
      "step": 790
    },
    {
      "epoch": 0.15552099533437014,
      "grad_norm": 0.9533241391181946,
      "learning_rate": 3.1065318818040436e-06,
      "loss": 0.1164,
      "step": 800
    },
    {
      "epoch": 0.15746500777604977,
      "grad_norm": 1.2141345739364624,
      "learning_rate": 3.1454121306376364e-06,
      "loss": 0.2606,
      "step": 810
    },
    {
      "epoch": 0.1594090202177294,
      "grad_norm": 7.824886798858643,
      "learning_rate": 3.1842923794712283e-06,
      "loss": 0.1701,
      "step": 820
    },
    {
      "epoch": 0.161353032659409,
      "grad_norm": 2.5700690746307373,
      "learning_rate": 3.223172628304821e-06,
      "loss": 0.1905,
      "step": 830
    },
    {
      "epoch": 0.16329704510108864,
      "grad_norm": 2.3615572452545166,
      "learning_rate": 3.2620528771384138e-06,
      "loss": 0.2016,
      "step": 840
    },
    {
      "epoch": 0.16524105754276827,
      "grad_norm": 8.95279598236084,
      "learning_rate": 3.3009331259720065e-06,
      "loss": 0.214,
      "step": 850
    },
    {
      "epoch": 0.1671850699844479,
      "grad_norm": 1.0288093090057373,
      "learning_rate": 3.339813374805599e-06,
      "loss": 0.1733,
      "step": 860
    },
    {
      "epoch": 0.16912908242612754,
      "grad_norm": 3.5736398696899414,
      "learning_rate": 3.378693623639191e-06,
      "loss": 0.1335,
      "step": 870
    },
    {
      "epoch": 0.17107309486780714,
      "grad_norm": 7.218218803405762,
      "learning_rate": 3.417573872472784e-06,
      "loss": 0.119,
      "step": 880
    },
    {
      "epoch": 0.17301710730948677,
      "grad_norm": 8.609760284423828,
      "learning_rate": 3.4564541213063767e-06,
      "loss": 0.1643,
      "step": 890
    },
    {
      "epoch": 0.1749611197511664,
      "grad_norm": 2.3295061588287354,
      "learning_rate": 3.495334370139969e-06,
      "loss": 0.1229,
      "step": 900
    },
    {
      "epoch": 0.17690513219284604,
      "grad_norm": 0.1694212704896927,
      "learning_rate": 3.5342146189735613e-06,
      "loss": 0.1639,
      "step": 910
    },
    {
      "epoch": 0.17884914463452567,
      "grad_norm": 0.2556315064430237,
      "learning_rate": 3.573094867807154e-06,
      "loss": 0.0969,
      "step": 920
    },
    {
      "epoch": 0.18079315707620527,
      "grad_norm": 7.987865924835205,
      "learning_rate": 3.611975116640747e-06,
      "loss": 0.1299,
      "step": 930
    },
    {
      "epoch": 0.1827371695178849,
      "grad_norm": 0.09457846730947495,
      "learning_rate": 3.650855365474339e-06,
      "loss": 0.1068,
      "step": 940
    },
    {
      "epoch": 0.18468118195956454,
      "grad_norm": 3.9261956214904785,
      "learning_rate": 3.689735614307932e-06,
      "loss": 0.1962,
      "step": 950
    },
    {
      "epoch": 0.18662519440124417,
      "grad_norm": 7.754511833190918,
      "learning_rate": 3.728615863141524e-06,
      "loss": 0.1866,
      "step": 960
    },
    {
      "epoch": 0.1885692068429238,
      "grad_norm": 10.491329193115234,
      "learning_rate": 3.767496111975117e-06,
      "loss": 0.1594,
      "step": 970
    },
    {
      "epoch": 0.1905132192846034,
      "grad_norm": 8.645960807800293,
      "learning_rate": 3.8063763608087097e-06,
      "loss": 0.1053,
      "step": 980
    },
    {
      "epoch": 0.19245723172628304,
      "grad_norm": 13.832451820373535,
      "learning_rate": 3.845256609642302e-06,
      "loss": 0.1349,
      "step": 990
    },
    {
      "epoch": 0.19440124416796267,
      "grad_norm": 5.2573323249816895,
      "learning_rate": 3.884136858475894e-06,
      "loss": 0.1093,
      "step": 1000
    },
    {
      "epoch": 0.1963452566096423,
      "grad_norm": 10.903511047363281,
      "learning_rate": 3.923017107309487e-06,
      "loss": 0.0892,
      "step": 1010
    },
    {
      "epoch": 0.19828926905132194,
      "grad_norm": 5.566726207733154,
      "learning_rate": 3.961897356143079e-06,
      "loss": 0.0876,
      "step": 1020
    },
    {
      "epoch": 0.20023328149300154,
      "grad_norm": 6.252418518066406,
      "learning_rate": 4.000777604976672e-06,
      "loss": 0.0923,
      "step": 1030
    },
    {
      "epoch": 0.20217729393468117,
      "grad_norm": 0.3162573575973511,
      "learning_rate": 4.039657853810265e-06,
      "loss": 0.1132,
      "step": 1040
    },
    {
      "epoch": 0.2041213063763608,
      "grad_norm": 8.623355865478516,
      "learning_rate": 4.078538102643857e-06,
      "loss": 0.0945,
      "step": 1050
    },
    {
      "epoch": 0.20606531881804044,
      "grad_norm": 5.735077381134033,
      "learning_rate": 4.1174183514774495e-06,
      "loss": 0.1422,
      "step": 1060
    },
    {
      "epoch": 0.20800933125972007,
      "grad_norm": 0.2944203317165375,
      "learning_rate": 4.156298600311042e-06,
      "loss": 0.0476,
      "step": 1070
    },
    {
      "epoch": 0.2099533437013997,
      "grad_norm": 4.12234354019165,
      "learning_rate": 4.195178849144634e-06,
      "loss": 0.1264,
      "step": 1080
    },
    {
      "epoch": 0.2118973561430793,
      "grad_norm": 4.960911750793457,
      "learning_rate": 4.234059097978227e-06,
      "loss": 0.0941,
      "step": 1090
    },
    {
      "epoch": 0.21384136858475894,
      "grad_norm": 8.798017501831055,
      "learning_rate": 4.27293934681182e-06,
      "loss": 0.0909,
      "step": 1100
    },
    {
      "epoch": 0.21578538102643857,
      "grad_norm": 12.241209983825684,
      "learning_rate": 4.311819595645412e-06,
      "loss": 0.0918,
      "step": 1110
    },
    {
      "epoch": 0.2177293934681182,
      "grad_norm": 9.192343711853027,
      "learning_rate": 4.350699844479005e-06,
      "loss": 0.1512,
      "step": 1120
    },
    {
      "epoch": 0.21967340590979784,
      "grad_norm": 3.2338593006134033,
      "learning_rate": 4.3895800933125975e-06,
      "loss": 0.0688,
      "step": 1130
    },
    {
      "epoch": 0.22161741835147744,
      "grad_norm": 9.754732131958008,
      "learning_rate": 4.42846034214619e-06,
      "loss": 0.1031,
      "step": 1140
    },
    {
      "epoch": 0.22356143079315707,
      "grad_norm": 0.062161121517419815,
      "learning_rate": 4.467340590979782e-06,
      "loss": 0.0612,
      "step": 1150
    },
    {
      "epoch": 0.2255054432348367,
      "grad_norm": 5.606031894683838,
      "learning_rate": 4.5062208398133744e-06,
      "loss": 0.1304,
      "step": 1160
    },
    {
      "epoch": 0.22744945567651634,
      "grad_norm": 0.2994155287742615,
      "learning_rate": 4.545101088646968e-06,
      "loss": 0.048,
      "step": 1170
    },
    {
      "epoch": 0.22939346811819597,
      "grad_norm": 3.5731546878814697,
      "learning_rate": 4.58398133748056e-06,
      "loss": 0.0616,
      "step": 1180
    },
    {
      "epoch": 0.23133748055987557,
      "grad_norm": 8.068175315856934,
      "learning_rate": 4.622861586314152e-06,
      "loss": 0.0316,
      "step": 1190
    },
    {
      "epoch": 0.2332814930015552,
      "grad_norm": 0.17861373722553253,
      "learning_rate": 4.6617418351477454e-06,
      "loss": 0.0993,
      "step": 1200
    },
    {
      "epoch": 0.23522550544323484,
      "grad_norm": 6.024631500244141,
      "learning_rate": 4.700622083981338e-06,
      "loss": 0.0314,
      "step": 1210
    },
    {
      "epoch": 0.23716951788491447,
      "grad_norm": 15.380515098571777,
      "learning_rate": 4.73950233281493e-06,
      "loss": 0.1453,
      "step": 1220
    },
    {
      "epoch": 0.2391135303265941,
      "grad_norm": 8.212577819824219,
      "learning_rate": 4.778382581648522e-06,
      "loss": 0.0686,
      "step": 1230
    },
    {
      "epoch": 0.2410575427682737,
      "grad_norm": 0.4542061686515808,
      "learning_rate": 4.817262830482115e-06,
      "loss": 0.077,
      "step": 1240
    },
    {
      "epoch": 0.24300155520995334,
      "grad_norm": 0.5423593521118164,
      "learning_rate": 4.856143079315708e-06,
      "loss": 0.1447,
      "step": 1250
    },
    {
      "epoch": 0.24494556765163297,
      "grad_norm": 6.700893878936768,
      "learning_rate": 4.8950233281493e-06,
      "loss": 0.056,
      "step": 1260
    },
    {
      "epoch": 0.2468895800933126,
      "grad_norm": 0.42258116602897644,
      "learning_rate": 4.933903576982893e-06,
      "loss": 0.1124,
      "step": 1270
    },
    {
      "epoch": 0.24883359253499224,
      "grad_norm": 0.30737248063087463,
      "learning_rate": 4.972783825816486e-06,
      "loss": 0.1019,
      "step": 1280
    },
    {
      "epoch": 0.25077760497667184,
      "grad_norm": 1.3678463697433472,
      "learning_rate": 5.011664074650077e-06,
      "loss": 0.0397,
      "step": 1290
    },
    {
      "epoch": 0.2527216174183515,
      "grad_norm": 17.39996910095215,
      "learning_rate": 5.05054432348367e-06,
      "loss": 0.0734,
      "step": 1300
    },
    {
      "epoch": 0.2546656298600311,
      "grad_norm": 4.1569929122924805,
      "learning_rate": 5.089424572317263e-06,
      "loss": 0.0644,
      "step": 1310
    },
    {
      "epoch": 0.25660964230171074,
      "grad_norm": 10.804482460021973,
      "learning_rate": 5.128304821150856e-06,
      "loss": 0.0627,
      "step": 1320
    },
    {
      "epoch": 0.25855365474339037,
      "grad_norm": 8.349943161010742,
      "learning_rate": 5.167185069984448e-06,
      "loss": 0.0673,
      "step": 1330
    },
    {
      "epoch": 0.26049766718507,
      "grad_norm": 4.235875129699707,
      "learning_rate": 5.2060653188180405e-06,
      "loss": 0.035,
      "step": 1340
    },
    {
      "epoch": 0.26244167962674964,
      "grad_norm": 12.693769454956055,
      "learning_rate": 5.244945567651634e-06,
      "loss": 0.0701,
      "step": 1350
    },
    {
      "epoch": 0.2643856920684292,
      "grad_norm": 9.177323341369629,
      "learning_rate": 5.283825816485226e-06,
      "loss": 0.0378,
      "step": 1360
    },
    {
      "epoch": 0.26632970451010884,
      "grad_norm": 0.34673386812210083,
      "learning_rate": 5.3227060653188174e-06,
      "loss": 0.0754,
      "step": 1370
    },
    {
      "epoch": 0.2682737169517885,
      "grad_norm": 0.022783102467656136,
      "learning_rate": 5.361586314152411e-06,
      "loss": 0.0882,
      "step": 1380
    },
    {
      "epoch": 0.2702177293934681,
      "grad_norm": 0.394003301858902,
      "learning_rate": 5.400466562986003e-06,
      "loss": 0.1181,
      "step": 1390
    },
    {
      "epoch": 0.27216174183514774,
      "grad_norm": 6.093593597412109,
      "learning_rate": 5.439346811819596e-06,
      "loss": 0.0745,
      "step": 1400
    },
    {
      "epoch": 0.2741057542768274,
      "grad_norm": 9.570717811584473,
      "learning_rate": 5.4782270606531884e-06,
      "loss": 0.0714,
      "step": 1410
    },
    {
      "epoch": 0.276049766718507,
      "grad_norm": 0.5431656837463379,
      "learning_rate": 5.517107309486781e-06,
      "loss": 0.0636,
      "step": 1420
    },
    {
      "epoch": 0.27799377916018664,
      "grad_norm": 3.4253532886505127,
      "learning_rate": 5.555987558320374e-06,
      "loss": 0.079,
      "step": 1430
    },
    {
      "epoch": 0.27993779160186627,
      "grad_norm": 1.7019413709640503,
      "learning_rate": 5.594867807153966e-06,
      "loss": 0.0345,
      "step": 1440
    },
    {
      "epoch": 0.2818818040435459,
      "grad_norm": 0.7676395177841187,
      "learning_rate": 5.6337480559875586e-06,
      "loss": 0.0883,
      "step": 1450
    },
    {
      "epoch": 0.2838258164852255,
      "grad_norm": 1.8178253173828125,
      "learning_rate": 5.672628304821151e-06,
      "loss": 0.0874,
      "step": 1460
    },
    {
      "epoch": 0.2857698289269051,
      "grad_norm": 8.016520500183105,
      "learning_rate": 5.711508553654743e-06,
      "loss": 0.0795,
      "step": 1470
    },
    {
      "epoch": 0.28771384136858474,
      "grad_norm": 4.6652116775512695,
      "learning_rate": 5.750388802488336e-06,
      "loss": 0.0544,
      "step": 1480
    },
    {
      "epoch": 0.2896578538102644,
      "grad_norm": 0.6457633376121521,
      "learning_rate": 5.789269051321929e-06,
      "loss": 0.0222,
      "step": 1490
    },
    {
      "epoch": 0.291601866251944,
      "grad_norm": 0.02786046266555786,
      "learning_rate": 5.828149300155521e-06,
      "loss": 0.021,
      "step": 1500
    },
    {
      "epoch": 0.29354587869362364,
      "grad_norm": 7.846120834350586,
      "learning_rate": 5.867029548989114e-06,
      "loss": 0.0745,
      "step": 1510
    },
    {
      "epoch": 0.2954898911353033,
      "grad_norm": 9.55692195892334,
      "learning_rate": 5.905909797822706e-06,
      "loss": 0.0549,
      "step": 1520
    },
    {
      "epoch": 0.2974339035769829,
      "grad_norm": 2.527169704437256,
      "learning_rate": 5.944790046656299e-06,
      "loss": 0.0574,
      "step": 1530
    },
    {
      "epoch": 0.29937791601866254,
      "grad_norm": 1.320194125175476,
      "learning_rate": 5.983670295489891e-06,
      "loss": 0.0215,
      "step": 1540
    },
    {
      "epoch": 0.30132192846034217,
      "grad_norm": 0.24193601310253143,
      "learning_rate": 6.0225505443234835e-06,
      "loss": 0.0897,
      "step": 1550
    },
    {
      "epoch": 0.30326594090202175,
      "grad_norm": 7.723960876464844,
      "learning_rate": 6.061430793157077e-06,
      "loss": 0.0233,
      "step": 1560
    },
    {
      "epoch": 0.3052099533437014,
      "grad_norm": 0.5176500082015991,
      "learning_rate": 6.100311041990669e-06,
      "loss": 0.0578,
      "step": 1570
    },
    {
      "epoch": 0.307153965785381,
      "grad_norm": 7.536765098571777,
      "learning_rate": 6.139191290824262e-06,
      "loss": 0.0477,
      "step": 1580
    },
    {
      "epoch": 0.30909797822706064,
      "grad_norm": 13.676911354064941,
      "learning_rate": 6.1780715396578545e-06,
      "loss": 0.0753,
      "step": 1590
    },
    {
      "epoch": 0.3110419906687403,
      "grad_norm": 5.169715881347656,
      "learning_rate": 6.216951788491446e-06,
      "loss": 0.0155,
      "step": 1600
    },
    {
      "epoch": 0.3129860031104199,
      "grad_norm": 0.06998679041862488,
      "learning_rate": 6.255832037325039e-06,
      "loss": 0.0048,
      "step": 1610
    },
    {
      "epoch": 0.31493001555209954,
      "grad_norm": 0.4598332643508911,
      "learning_rate": 6.2947122861586314e-06,
      "loss": 0.0358,
      "step": 1620
    },
    {
      "epoch": 0.3168740279937792,
      "grad_norm": 0.3428729474544525,
      "learning_rate": 6.333592534992224e-06,
      "loss": 0.0397,
      "step": 1630
    },
    {
      "epoch": 0.3188180404354588,
      "grad_norm": 0.15136009454727173,
      "learning_rate": 6.372472783825817e-06,
      "loss": 0.0274,
      "step": 1640
    },
    {
      "epoch": 0.32076205287713844,
      "grad_norm": 1.5020078420639038,
      "learning_rate": 6.411353032659409e-06,
      "loss": 0.011,
      "step": 1650
    },
    {
      "epoch": 0.322706065318818,
      "grad_norm": 0.5147070288658142,
      "learning_rate": 6.450233281493002e-06,
      "loss": 0.0273,
      "step": 1660
    },
    {
      "epoch": 0.32465007776049765,
      "grad_norm": 4.943755626678467,
      "learning_rate": 6.489113530326594e-06,
      "loss": 0.0145,
      "step": 1670
    },
    {
      "epoch": 0.3265940902021773,
      "grad_norm": 0.03738168627023697,
      "learning_rate": 6.527993779160186e-06,
      "loss": 0.0238,
      "step": 1680
    },
    {
      "epoch": 0.3285381026438569,
      "grad_norm": 0.8517005443572998,
      "learning_rate": 6.566874027993779e-06,
      "loss": 0.0112,
      "step": 1690
    },
    {
      "epoch": 0.33048211508553654,
      "grad_norm": 10.945096969604492,
      "learning_rate": 6.605754276827372e-06,
      "loss": 0.0134,
      "step": 1700
    },
    {
      "epoch": 0.3324261275272162,
      "grad_norm": 8.618983268737793,
      "learning_rate": 6.644634525660965e-06,
      "loss": 0.0778,
      "step": 1710
    },
    {
      "epoch": 0.3343701399688958,
      "grad_norm": 0.045486412942409515,
      "learning_rate": 6.683514774494557e-06,
      "loss": 0.0324,
      "step": 1720
    },
    {
      "epoch": 0.33631415241057544,
      "grad_norm": 0.029274288564920425,
      "learning_rate": 6.7223950233281495e-06,
      "loss": 0.0808,
      "step": 1730
    },
    {
      "epoch": 0.33825816485225507,
      "grad_norm": 2.236079692840576,
      "learning_rate": 6.761275272161743e-06,
      "loss": 0.0509,
      "step": 1740
    },
    {
      "epoch": 0.3402021772939347,
      "grad_norm": 0.5235880613327026,
      "learning_rate": 6.800155520995334e-06,
      "loss": 0.0266,
      "step": 1750
    },
    {
      "epoch": 0.3421461897356143,
      "grad_norm": 0.020724166184663773,
      "learning_rate": 6.8390357698289265e-06,
      "loss": 0.0328,
      "step": 1760
    },
    {
      "epoch": 0.3440902021772939,
      "grad_norm": 0.08028304576873779,
      "learning_rate": 6.87791601866252e-06,
      "loss": 0.0077,
      "step": 1770
    },
    {
      "epoch": 0.34603421461897355,
      "grad_norm": 0.03161725401878357,
      "learning_rate": 6.916796267496112e-06,
      "loss": 0.0279,
      "step": 1780
    },
    {
      "epoch": 0.3479782270606532,
      "grad_norm": 0.16455581784248352,
      "learning_rate": 6.955676516329705e-06,
      "loss": 0.0055,
      "step": 1790
    },
    {
      "epoch": 0.3499222395023328,
      "grad_norm": 10.69105339050293,
      "learning_rate": 6.9945567651632975e-06,
      "loss": 0.0207,
      "step": 1800
    },
    {
      "epoch": 0.35186625194401244,
      "grad_norm": 0.31035831570625305,
      "learning_rate": 7.03343701399689e-06,
      "loss": 0.0098,
      "step": 1810
    },
    {
      "epoch": 0.3538102643856921,
      "grad_norm": 0.032988592982292175,
      "learning_rate": 7.072317262830482e-06,
      "loss": 0.0189,
      "step": 1820
    },
    {
      "epoch": 0.3557542768273717,
      "grad_norm": 0.7964960336685181,
      "learning_rate": 7.1111975116640744e-06,
      "loss": 0.0224,
      "step": 1830
    },
    {
      "epoch": 0.35769828926905134,
      "grad_norm": 0.01116441935300827,
      "learning_rate": 7.150077760497668e-06,
      "loss": 0.023,
      "step": 1840
    },
    {
      "epoch": 0.35964230171073097,
      "grad_norm": 21.470895767211914,
      "learning_rate": 7.18895800933126e-06,
      "loss": 0.0359,
      "step": 1850
    },
    {
      "epoch": 0.36158631415241055,
      "grad_norm": 0.019808735698461533,
      "learning_rate": 7.227838258164852e-06,
      "loss": 0.0364,
      "step": 1860
    },
    {
      "epoch": 0.3635303265940902,
      "grad_norm": 0.05177484452724457,
      "learning_rate": 7.266718506998445e-06,
      "loss": 0.0116,
      "step": 1870
    },
    {
      "epoch": 0.3654743390357698,
      "grad_norm": 6.191153526306152,
      "learning_rate": 7.305598755832038e-06,
      "loss": 0.01,
      "step": 1880
    },
    {
      "epoch": 0.36741835147744945,
      "grad_norm": 15.917215347290039,
      "learning_rate": 7.34447900466563e-06,
      "loss": 0.0329,
      "step": 1890
    },
    {
      "epoch": 0.3693623639191291,
      "grad_norm": 0.031048836186528206,
      "learning_rate": 7.383359253499222e-06,
      "loss": 0.0213,
      "step": 1900
    },
    {
      "epoch": 0.3713063763608087,
      "grad_norm": 2.6307265758514404,
      "learning_rate": 7.422239502332815e-06,
      "loss": 0.014,
      "step": 1910
    },
    {
      "epoch": 0.37325038880248834,
      "grad_norm": 18.612628936767578,
      "learning_rate": 7.461119751166408e-06,
      "loss": 0.0372,
      "step": 1920
    },
    {
      "epoch": 0.375194401244168,
      "grad_norm": 0.02122408337891102,
      "learning_rate": 7.5e-06,
      "loss": 0.0061,
      "step": 1930
    },
    {
      "epoch": 0.3771384136858476,
      "grad_norm": 0.024294598028063774,
      "learning_rate": 7.5388802488335925e-06,
      "loss": 0.0323,
      "step": 1940
    },
    {
      "epoch": 0.37908242612752724,
      "grad_norm": 1.8742563724517822,
      "learning_rate": 7.577760497667186e-06,
      "loss": 0.0327,
      "step": 1950
    },
    {
      "epoch": 0.3810264385692068,
      "grad_norm": 1.9244002103805542,
      "learning_rate": 7.616640746500778e-06,
      "loss": 0.091,
      "step": 1960
    },
    {
      "epoch": 0.38297045101088645,
      "grad_norm": 0.015278415754437447,
      "learning_rate": 7.65552099533437e-06,
      "loss": 0.0013,
      "step": 1970
    },
    {
      "epoch": 0.3849144634525661,
      "grad_norm": 0.05641346797347069,
      "learning_rate": 7.694401244167963e-06,
      "loss": 0.0604,
      "step": 1980
    },
    {
      "epoch": 0.3868584758942457,
      "grad_norm": 0.05097290128469467,
      "learning_rate": 7.733281493001557e-06,
      "loss": 0.0324,
      "step": 1990
    },
    {
      "epoch": 0.38880248833592534,
      "grad_norm": 0.2919906675815582,
      "learning_rate": 7.772161741835148e-06,
      "loss": 0.0386,
      "step": 2000
    },
    {
      "epoch": 0.390746500777605,
      "grad_norm": 0.049408745020627975,
      "learning_rate": 7.81104199066874e-06,
      "loss": 0.026,
      "step": 2010
    },
    {
      "epoch": 0.3926905132192846,
      "grad_norm": 0.01166438963264227,
      "learning_rate": 7.849922239502333e-06,
      "loss": 0.0166,
      "step": 2020
    },
    {
      "epoch": 0.39463452566096424,
      "grad_norm": 0.06464764475822449,
      "learning_rate": 7.888802488335924e-06,
      "loss": 0.0419,
      "step": 2030
    },
    {
      "epoch": 0.3965785381026439,
      "grad_norm": 0.08914312720298767,
      "learning_rate": 7.927682737169517e-06,
      "loss": 0.0214,
      "step": 2040
    },
    {
      "epoch": 0.3985225505443235,
      "grad_norm": 0.21841011941432953,
      "learning_rate": 7.96656298600311e-06,
      "loss": 0.0312,
      "step": 2050
    },
    {
      "epoch": 0.4004665629860031,
      "grad_norm": 0.018437111750245094,
      "learning_rate": 8.005443234836704e-06,
      "loss": 0.0339,
      "step": 2060
    },
    {
      "epoch": 0.4024105754276827,
      "grad_norm": 5.090346813201904,
      "learning_rate": 8.044323483670295e-06,
      "loss": 0.0187,
      "step": 2070
    },
    {
      "epoch": 0.40435458786936235,
      "grad_norm": 13.167872428894043,
      "learning_rate": 8.083203732503888e-06,
      "loss": 0.0617,
      "step": 2080
    },
    {
      "epoch": 0.406298600311042,
      "grad_norm": 0.011709936894476414,
      "learning_rate": 8.122083981337482e-06,
      "loss": 0.0013,
      "step": 2090
    },
    {
      "epoch": 0.4082426127527216,
      "grad_norm": 0.19205792248249054,
      "learning_rate": 8.160964230171073e-06,
      "loss": 0.0011,
      "step": 2100
    },
    {
      "epoch": 0.41018662519440124,
      "grad_norm": 0.023326434195041656,
      "learning_rate": 8.199844479004666e-06,
      "loss": 0.0161,
      "step": 2110
    },
    {
      "epoch": 0.4121306376360809,
      "grad_norm": 0.0109035549685359,
      "learning_rate": 8.23872472783826e-06,
      "loss": 0.0141,
      "step": 2120
    },
    {
      "epoch": 0.4140746500777605,
      "grad_norm": 0.2264987826347351,
      "learning_rate": 8.277604976671851e-06,
      "loss": 0.0009,
      "step": 2130
    },
    {
      "epoch": 0.41601866251944014,
      "grad_norm": 0.019026318565011024,
      "learning_rate": 8.316485225505444e-06,
      "loss": 0.0007,
      "step": 2140
    },
    {
      "epoch": 0.4179626749611198,
      "grad_norm": 0.008708895184099674,
      "learning_rate": 8.355365474339037e-06,
      "loss": 0.0197,
      "step": 2150
    },
    {
      "epoch": 0.4199066874027994,
      "grad_norm": 0.0560898594558239,
      "learning_rate": 8.394245723172627e-06,
      "loss": 0.0395,
      "step": 2160
    },
    {
      "epoch": 0.421850699844479,
      "grad_norm": 0.011461765505373478,
      "learning_rate": 8.43312597200622e-06,
      "loss": 0.0151,
      "step": 2170
    },
    {
      "epoch": 0.4237947122861586,
      "grad_norm": 0.006458388175815344,
      "learning_rate": 8.472006220839813e-06,
      "loss": 0.0318,
      "step": 2180
    },
    {
      "epoch": 0.42573872472783825,
      "grad_norm": 0.007142635062336922,
      "learning_rate": 8.510886469673406e-06,
      "loss": 0.0067,
      "step": 2190
    },
    {
      "epoch": 0.4276827371695179,
      "grad_norm": 0.012419276870787144,
      "learning_rate": 8.549766718506998e-06,
      "loss": 0.0326,
      "step": 2200
    },
    {
      "epoch": 0.4296267496111975,
      "grad_norm": 0.02620098739862442,
      "learning_rate": 8.588646967340591e-06,
      "loss": 0.0086,
      "step": 2210
    },
    {
      "epoch": 0.43157076205287714,
      "grad_norm": 0.011183732189238071,
      "learning_rate": 8.627527216174184e-06,
      "loss": 0.0194,
      "step": 2220
    },
    {
      "epoch": 0.4335147744945568,
      "grad_norm": 1.545310616493225,
      "learning_rate": 8.666407465007776e-06,
      "loss": 0.014,
      "step": 2230
    },
    {
      "epoch": 0.4354587869362364,
      "grad_norm": 0.020968269556760788,
      "learning_rate": 8.705287713841369e-06,
      "loss": 0.0114,
      "step": 2240
    },
    {
      "epoch": 0.43740279937791604,
      "grad_norm": 0.02342340536415577,
      "learning_rate": 8.744167962674962e-06,
      "loss": 0.0018,
      "step": 2250
    },
    {
      "epoch": 0.4393468118195957,
      "grad_norm": 0.011170036159455776,
      "learning_rate": 8.783048211508554e-06,
      "loss": 0.0024,
      "step": 2260
    },
    {
      "epoch": 0.44129082426127525,
      "grad_norm": 0.023013638332486153,
      "learning_rate": 8.821928460342147e-06,
      "loss": 0.0077,
      "step": 2270
    },
    {
      "epoch": 0.4432348367029549,
      "grad_norm": 0.03646254539489746,
      "learning_rate": 8.86080870917574e-06,
      "loss": 0.0655,
      "step": 2280
    },
    {
      "epoch": 0.4451788491446345,
      "grad_norm": 0.006427300628274679,
      "learning_rate": 8.899688958009331e-06,
      "loss": 0.0053,
      "step": 2290
    },
    {
      "epoch": 0.44712286158631415,
      "grad_norm": 0.006042849272489548,
      "learning_rate": 8.938569206842925e-06,
      "loss": 0.0586,
      "step": 2300
    },
    {
      "epoch": 0.4490668740279938,
      "grad_norm": 0.05689529702067375,
      "learning_rate": 8.977449455676516e-06,
      "loss": 0.0209,
      "step": 2310
    },
    {
      "epoch": 0.4510108864696734,
      "grad_norm": 0.010041370056569576,
      "learning_rate": 9.01632970451011e-06,
      "loss": 0.0058,
      "step": 2320
    },
    {
      "epoch": 0.45295489891135304,
      "grad_norm": 0.00816496554762125,
      "learning_rate": 9.0552099533437e-06,
      "loss": 0.031,
      "step": 2330
    },
    {
      "epoch": 0.4548989113530327,
      "grad_norm": 1.2738076448440552,
      "learning_rate": 9.094090202177294e-06,
      "loss": 0.0035,
      "step": 2340
    },
    {
      "epoch": 0.4568429237947123,
      "grad_norm": 0.004251263104379177,
      "learning_rate": 9.132970451010887e-06,
      "loss": 0.0066,
      "step": 2350
    },
    {
      "epoch": 0.45878693623639194,
      "grad_norm": 0.01887298747897148,
      "learning_rate": 9.171850699844479e-06,
      "loss": 0.0253,
      "step": 2360
    },
    {
      "epoch": 0.4607309486780715,
      "grad_norm": 0.1374102532863617,
      "learning_rate": 9.210730948678072e-06,
      "loss": 0.0023,
      "step": 2370
    },
    {
      "epoch": 0.46267496111975115,
      "grad_norm": 0.018558001145720482,
      "learning_rate": 9.249611197511665e-06,
      "loss": 0.0052,
      "step": 2380
    },
    {
      "epoch": 0.4646189735614308,
      "grad_norm": 0.26225826144218445,
      "learning_rate": 9.288491446345256e-06,
      "loss": 0.0279,
      "step": 2390
    },
    {
      "epoch": 0.4665629860031104,
      "grad_norm": 0.003959623631089926,
      "learning_rate": 9.32737169517885e-06,
      "loss": 0.0265,
      "step": 2400
    },
    {
      "epoch": 0.46850699844479005,
      "grad_norm": 0.01331025455147028,
      "learning_rate": 9.366251944012443e-06,
      "loss": 0.0135,
      "step": 2410
    },
    {
      "epoch": 0.4704510108864697,
      "grad_norm": 0.014022971503436565,
      "learning_rate": 9.405132192846034e-06,
      "loss": 0.0223,
      "step": 2420
    },
    {
      "epoch": 0.4723950233281493,
      "grad_norm": 0.00679352693259716,
      "learning_rate": 9.444012441679627e-06,
      "loss": 0.0264,
      "step": 2430
    },
    {
      "epoch": 0.47433903576982894,
      "grad_norm": 7.222256183624268,
      "learning_rate": 9.48289269051322e-06,
      "loss": 0.0174,
      "step": 2440
    },
    {
      "epoch": 0.4762830482115086,
      "grad_norm": 7.687118053436279,
      "learning_rate": 9.521772939346814e-06,
      "loss": 0.0298,
      "step": 2450
    },
    {
      "epoch": 0.4782270606531882,
      "grad_norm": 0.23562748730182648,
      "learning_rate": 9.560653188180403e-06,
      "loss": 0.019,
      "step": 2460
    },
    {
      "epoch": 0.4801710730948678,
      "grad_norm": 0.006946051027625799,
      "learning_rate": 9.599533437013997e-06,
      "loss": 0.039,
      "step": 2470
    },
    {
      "epoch": 0.4821150855365474,
      "grad_norm": 0.01783539354801178,
      "learning_rate": 9.63841368584759e-06,
      "loss": 0.0202,
      "step": 2480
    },
    {
      "epoch": 0.48405909797822705,
      "grad_norm": 0.12915705144405365,
      "learning_rate": 9.677293934681181e-06,
      "loss": 0.0007,
      "step": 2490
    },
    {
      "epoch": 0.4860031104199067,
      "grad_norm": 0.010382785461843014,
      "learning_rate": 9.716174183514774e-06,
      "loss": 0.0203,
      "step": 2500
    },
    {
      "epoch": 0.4879471228615863,
      "grad_norm": 0.00938539206981659,
      "learning_rate": 9.755054432348368e-06,
      "loss": 0.0257,
      "step": 2510
    },
    {
      "epoch": 0.48989113530326595,
      "grad_norm": 2.512409210205078,
      "learning_rate": 9.793934681181959e-06,
      "loss": 0.0108,
      "step": 2520
    },
    {
      "epoch": 0.4918351477449456,
      "grad_norm": 0.006034349091351032,
      "learning_rate": 9.832814930015552e-06,
      "loss": 0.0086,
      "step": 2530
    },
    {
      "epoch": 0.4937791601866252,
      "grad_norm": 0.04584655538201332,
      "learning_rate": 9.871695178849145e-06,
      "loss": 0.0009,
      "step": 2540
    },
    {
      "epoch": 0.49572317262830484,
      "grad_norm": 0.02710612490773201,
      "learning_rate": 9.910575427682737e-06,
      "loss": 0.0247,
      "step": 2550
    },
    {
      "epoch": 0.4976671850699845,
      "grad_norm": 0.009585932828485966,
      "learning_rate": 9.94945567651633e-06,
      "loss": 0.0025,
      "step": 2560
    },
    {
      "epoch": 0.49961119751166405,
      "grad_norm": 0.01356108020991087,
      "learning_rate": 9.988335925349923e-06,
      "loss": 0.0114,
      "step": 2570
    },
    {
      "epoch": 0.5015552099533437,
      "grad_norm": 0.005554193165153265,
      "learning_rate": 1.0027216174183516e-05,
      "loss": 0.0055,
      "step": 2580
    },
    {
      "epoch": 0.5034992223950233,
      "grad_norm": 27.501087188720703,
      "learning_rate": 1.0066096423017108e-05,
      "loss": 0.0083,
      "step": 2590
    },
    {
      "epoch": 0.505443234836703,
      "grad_norm": 0.004241019021719694,
      "learning_rate": 1.0104976671850701e-05,
      "loss": 0.0082,
      "step": 2600
    },
    {
      "epoch": 0.5073872472783826,
      "grad_norm": 0.02620100788772106,
      "learning_rate": 1.0143856920684292e-05,
      "loss": 0.0356,
      "step": 2610
    },
    {
      "epoch": 0.5093312597200622,
      "grad_norm": 0.005775200668722391,
      "learning_rate": 1.0182737169517884e-05,
      "loss": 0.0218,
      "step": 2620
    },
    {
      "epoch": 0.5112752721617418,
      "grad_norm": 3.4833507537841797,
      "learning_rate": 1.0221617418351477e-05,
      "loss": 0.0013,
      "step": 2630
    },
    {
      "epoch": 0.5132192846034215,
      "grad_norm": 0.013037571683526039,
      "learning_rate": 1.026049766718507e-05,
      "loss": 0.0434,
      "step": 2640
    },
    {
      "epoch": 0.5151632970451011,
      "grad_norm": 0.7968115210533142,
      "learning_rate": 1.0299377916018662e-05,
      "loss": 0.0089,
      "step": 2650
    },
    {
      "epoch": 0.5171073094867807,
      "grad_norm": 0.08522448688745499,
      "learning_rate": 1.0338258164852255e-05,
      "loss": 0.0042,
      "step": 2660
    },
    {
      "epoch": 0.5190513219284604,
      "grad_norm": 0.021536240354180336,
      "learning_rate": 1.0377138413685848e-05,
      "loss": 0.0233,
      "step": 2670
    },
    {
      "epoch": 0.52099533437014,
      "grad_norm": 0.005228884052485228,
      "learning_rate": 1.041601866251944e-05,
      "loss": 0.001,
      "step": 2680
    },
    {
      "epoch": 0.5229393468118196,
      "grad_norm": 0.019379708915948868,
      "learning_rate": 1.0454898911353033e-05,
      "loss": 0.0377,
      "step": 2690
    },
    {
      "epoch": 0.5248833592534993,
      "grad_norm": 0.0045319609344005585,
      "learning_rate": 1.0493779160186626e-05,
      "loss": 0.0015,
      "step": 2700
    },
    {
      "epoch": 0.5268273716951789,
      "grad_norm": 12.361239433288574,
      "learning_rate": 1.0532659409020219e-05,
      "loss": 0.0333,
      "step": 2710
    },
    {
      "epoch": 0.5287713841368584,
      "grad_norm": 0.1437462568283081,
      "learning_rate": 1.057153965785381e-05,
      "loss": 0.0199,
      "step": 2720
    },
    {
      "epoch": 0.5307153965785381,
      "grad_norm": 0.0055350069887936115,
      "learning_rate": 1.0610419906687404e-05,
      "loss": 0.0049,
      "step": 2730
    },
    {
      "epoch": 0.5326594090202177,
      "grad_norm": 0.014726675115525723,
      "learning_rate": 1.0649300155520997e-05,
      "loss": 0.0365,
      "step": 2740
    },
    {
      "epoch": 0.5346034214618973,
      "grad_norm": 0.027028508484363556,
      "learning_rate": 1.0688180404354588e-05,
      "loss": 0.0011,
      "step": 2750
    },
    {
      "epoch": 0.536547433903577,
      "grad_norm": 0.021500620990991592,
      "learning_rate": 1.072706065318818e-05,
      "loss": 0.0132,
      "step": 2760
    },
    {
      "epoch": 0.5384914463452566,
      "grad_norm": 0.006896289996802807,
      "learning_rate": 1.0765940902021773e-05,
      "loss": 0.0143,
      "step": 2770
    },
    {
      "epoch": 0.5404354587869362,
      "grad_norm": 10.470300674438477,
      "learning_rate": 1.0804821150855365e-05,
      "loss": 0.1063,
      "step": 2780
    },
    {
      "epoch": 0.5423794712286159,
      "grad_norm": 0.006703541614115238,
      "learning_rate": 1.0843701399688958e-05,
      "loss": 0.0303,
      "step": 2790
    },
    {
      "epoch": 0.5443234836702955,
      "grad_norm": 0.07210568338632584,
      "learning_rate": 1.0882581648522551e-05,
      "loss": 0.0143,
      "step": 2800
    },
    {
      "epoch": 0.5462674961119751,
      "grad_norm": 0.009608171880245209,
      "learning_rate": 1.0921461897356142e-05,
      "loss": 0.0257,
      "step": 2810
    },
    {
      "epoch": 0.5482115085536547,
      "grad_norm": 0.06766223907470703,
      "learning_rate": 1.0960342146189735e-05,
      "loss": 0.0143,
      "step": 2820
    },
    {
      "epoch": 0.5501555209953344,
      "grad_norm": 0.01388468872755766,
      "learning_rate": 1.0999222395023329e-05,
      "loss": 0.0135,
      "step": 2830
    },
    {
      "epoch": 0.552099533437014,
      "grad_norm": 0.01848430000245571,
      "learning_rate": 1.1038102643856922e-05,
      "loss": 0.0015,
      "step": 2840
    },
    {
      "epoch": 0.5540435458786936,
      "grad_norm": 5.104369163513184,
      "learning_rate": 1.1076982892690513e-05,
      "loss": 0.0056,
      "step": 2850
    },
    {
      "epoch": 0.5559875583203733,
      "grad_norm": 0.03980588912963867,
      "learning_rate": 1.1115863141524106e-05,
      "loss": 0.0005,
      "step": 2860
    },
    {
      "epoch": 0.5579315707620529,
      "grad_norm": 0.06748983263969421,
      "learning_rate": 1.11547433903577e-05,
      "loss": 0.0009,
      "step": 2870
    },
    {
      "epoch": 0.5598755832037325,
      "grad_norm": 0.003026842139661312,
      "learning_rate": 1.1193623639191291e-05,
      "loss": 0.0002,
      "step": 2880
    },
    {
      "epoch": 0.5618195956454122,
      "grad_norm": 0.021432848647236824,
      "learning_rate": 1.1232503888024884e-05,
      "loss": 0.0034,
      "step": 2890
    },
    {
      "epoch": 0.5637636080870918,
      "grad_norm": 0.0036947696935385466,
      "learning_rate": 1.1271384136858477e-05,
      "loss": 0.0006,
      "step": 2900
    },
    {
      "epoch": 0.5657076205287714,
      "grad_norm": 0.028584567829966545,
      "learning_rate": 1.1310264385692067e-05,
      "loss": 0.0071,
      "step": 2910
    },
    {
      "epoch": 0.567651632970451,
      "grad_norm": 0.002956916345283389,
      "learning_rate": 1.134914463452566e-05,
      "loss": 0.0589,
      "step": 2920
    },
    {
      "epoch": 0.5695956454121306,
      "grad_norm": 0.04098431393504143,
      "learning_rate": 1.1388024883359254e-05,
      "loss": 0.0248,
      "step": 2930
    },
    {
      "epoch": 0.5715396578538102,
      "grad_norm": 0.007168944459408522,
      "learning_rate": 1.1426905132192845e-05,
      "loss": 0.0002,
      "step": 2940
    },
    {
      "epoch": 0.5734836702954899,
      "grad_norm": 0.006428251508623362,
      "learning_rate": 1.1465785381026438e-05,
      "loss": 0.0182,
      "step": 2950
    },
    {
      "epoch": 0.5754276827371695,
      "grad_norm": 0.06618211418390274,
      "learning_rate": 1.1504665629860031e-05,
      "loss": 0.0003,
      "step": 2960
    },
    {
      "epoch": 0.5773716951788491,
      "grad_norm": 0.0074208746664226055,
      "learning_rate": 1.1543545878693625e-05,
      "loss": 0.0151,
      "step": 2970
    },
    {
      "epoch": 0.5793157076205288,
      "grad_norm": 0.09390443563461304,
      "learning_rate": 1.1582426127527216e-05,
      "loss": 0.0003,
      "step": 2980
    },
    {
      "epoch": 0.5812597200622084,
      "grad_norm": 0.005231881979852915,
      "learning_rate": 1.162130637636081e-05,
      "loss": 0.0036,
      "step": 2990
    },
    {
      "epoch": 0.583203732503888,
      "grad_norm": 0.6821600198745728,
      "learning_rate": 1.1660186625194402e-05,
      "loss": 0.014,
      "step": 3000
    },
    {
      "epoch": 0.5851477449455676,
      "grad_norm": 0.4162415564060211,
      "learning_rate": 1.1699066874027994e-05,
      "loss": 0.0136,
      "step": 3010
    },
    {
      "epoch": 0.5870917573872473,
      "grad_norm": 0.005693561397492886,
      "learning_rate": 1.1737947122861587e-05,
      "loss": 0.0003,
      "step": 3020
    },
    {
      "epoch": 0.5890357698289269,
      "grad_norm": 0.007755568251013756,
      "learning_rate": 1.177682737169518e-05,
      "loss": 0.0018,
      "step": 3030
    },
    {
      "epoch": 0.5909797822706065,
      "grad_norm": 0.007058868650346994,
      "learning_rate": 1.1815707620528772e-05,
      "loss": 0.0004,
      "step": 3040
    },
    {
      "epoch": 0.5929237947122862,
      "grad_norm": 0.27860233187675476,
      "learning_rate": 1.1854587869362365e-05,
      "loss": 0.0091,
      "step": 3050
    },
    {
      "epoch": 0.5948678071539658,
      "grad_norm": 0.011175982654094696,
      "learning_rate": 1.1893468118195958e-05,
      "loss": 0.0003,
      "step": 3060
    },
    {
      "epoch": 0.5968118195956454,
      "grad_norm": 13.834203720092773,
      "learning_rate": 1.1932348367029548e-05,
      "loss": 0.0025,
      "step": 3070
    },
    {
      "epoch": 0.5987558320373251,
      "grad_norm": 0.003917235881090164,
      "learning_rate": 1.1971228615863141e-05,
      "loss": 0.0006,
      "step": 3080
    },
    {
      "epoch": 0.6006998444790047,
      "grad_norm": 0.003371238010004163,
      "learning_rate": 1.2010108864696734e-05,
      "loss": 0.0225,
      "step": 3090
    },
    {
      "epoch": 0.6026438569206843,
      "grad_norm": 2.329458236694336,
      "learning_rate": 1.2048989113530327e-05,
      "loss": 0.0006,
      "step": 3100
    },
    {
      "epoch": 0.604587869362364,
      "grad_norm": 0.0030801137909293175,
      "learning_rate": 1.2087869362363919e-05,
      "loss": 0.0207,
      "step": 3110
    },
    {
      "epoch": 0.6065318818040435,
      "grad_norm": 1.6871610879898071,
      "learning_rate": 1.2126749611197512e-05,
      "loss": 0.0007,
      "step": 3120
    },
    {
      "epoch": 0.6084758942457231,
      "grad_norm": 0.0029788261745125055,
      "learning_rate": 1.2165629860031105e-05,
      "loss": 0.0002,
      "step": 3130
    },
    {
      "epoch": 0.6104199066874028,
      "grad_norm": 0.002276460640132427,
      "learning_rate": 1.2204510108864697e-05,
      "loss": 0.0002,
      "step": 3140
    },
    {
      "epoch": 0.6123639191290824,
      "grad_norm": 0.00485824141651392,
      "learning_rate": 1.224339035769829e-05,
      "loss": 0.0557,
      "step": 3150
    },
    {
      "epoch": 0.614307931570762,
      "grad_norm": 0.034741103649139404,
      "learning_rate": 1.2282270606531883e-05,
      "loss": 0.0003,
      "step": 3160
    },
    {
      "epoch": 0.6162519440124417,
      "grad_norm": 0.003450347576290369,
      "learning_rate": 1.2321150855365474e-05,
      "loss": 0.035,
      "step": 3170
    },
    {
      "epoch": 0.6181959564541213,
      "grad_norm": 0.08682538568973541,
      "learning_rate": 1.2360031104199068e-05,
      "loss": 0.0003,
      "step": 3180
    },
    {
      "epoch": 0.6201399688958009,
      "grad_norm": 0.04439293593168259,
      "learning_rate": 1.239891135303266e-05,
      "loss": 0.029,
      "step": 3190
    },
    {
      "epoch": 0.6220839813374806,
      "grad_norm": 0.015489395707845688,
      "learning_rate": 1.2437791601866252e-05,
      "loss": 0.01,
      "step": 3200
    },
    {
      "epoch": 0.6240279937791602,
      "grad_norm": 0.014543781988322735,
      "learning_rate": 1.2476671850699845e-05,
      "loss": 0.0005,
      "step": 3210
    },
    {
      "epoch": 0.6259720062208398,
      "grad_norm": 0.052050650119781494,
      "learning_rate": 1.2515552099533437e-05,
      "loss": 0.0038,
      "step": 3220
    },
    {
      "epoch": 0.6279160186625194,
      "grad_norm": 0.002150815911591053,
      "learning_rate": 1.255443234836703e-05,
      "loss": 0.0244,
      "step": 3230
    },
    {
      "epoch": 0.6298600311041991,
      "grad_norm": 0.0031738393008708954,
      "learning_rate": 1.2593312597200621e-05,
      "loss": 0.0123,
      "step": 3240
    },
    {
      "epoch": 0.6318040435458787,
      "grad_norm": 0.015128822065889835,
      "learning_rate": 1.2632192846034215e-05,
      "loss": 0.0279,
      "step": 3250
    },
    {
      "epoch": 0.6337480559875583,
      "grad_norm": 0.039034802466630936,
      "learning_rate": 1.2671073094867808e-05,
      "loss": 0.0335,
      "step": 3260
    },
    {
      "epoch": 0.635692068429238,
      "grad_norm": 0.004439068958163261,
      "learning_rate": 1.27099533437014e-05,
      "loss": 0.0131,
      "step": 3270
    },
    {
      "epoch": 0.6376360808709176,
      "grad_norm": 2.8359081745147705,
      "learning_rate": 1.2748833592534992e-05,
      "loss": 0.0491,
      "step": 3280
    },
    {
      "epoch": 0.6395800933125972,
      "grad_norm": 0.023189296945929527,
      "learning_rate": 1.2787713841368586e-05,
      "loss": 0.0003,
      "step": 3290
    },
    {
      "epoch": 0.6415241057542769,
      "grad_norm": 0.007640192285180092,
      "learning_rate": 1.2826594090202177e-05,
      "loss": 0.0004,
      "step": 3300
    },
    {
      "epoch": 0.6434681181959565,
      "grad_norm": 0.005526644177734852,
      "learning_rate": 1.286547433903577e-05,
      "loss": 0.0007,
      "step": 3310
    },
    {
      "epoch": 0.645412130637636,
      "grad_norm": 2.1960391998291016,
      "learning_rate": 1.2904354587869363e-05,
      "loss": 0.0714,
      "step": 3320
    },
    {
      "epoch": 0.6473561430793157,
      "grad_norm": 0.8002752661705017,
      "learning_rate": 1.2943234836702955e-05,
      "loss": 0.0016,
      "step": 3330
    },
    {
      "epoch": 0.6493001555209953,
      "grad_norm": 0.005716840736567974,
      "learning_rate": 1.2982115085536548e-05,
      "loss": 0.0005,
      "step": 3340
    },
    {
      "epoch": 0.6512441679626749,
      "grad_norm": 0.04715130105614662,
      "learning_rate": 1.3020995334370141e-05,
      "loss": 0.0017,
      "step": 3350
    },
    {
      "epoch": 0.6531881804043546,
      "grad_norm": 0.0038276410195976496,
      "learning_rate": 1.3059875583203734e-05,
      "loss": 0.0063,
      "step": 3360
    },
    {
      "epoch": 0.6551321928460342,
      "grad_norm": 0.5459360480308533,
      "learning_rate": 1.3098755832037324e-05,
      "loss": 0.0056,
      "step": 3370
    },
    {
      "epoch": 0.6570762052877138,
      "grad_norm": 0.014019843190908432,
      "learning_rate": 1.3137636080870917e-05,
      "loss": 0.0278,
      "step": 3380
    },
    {
      "epoch": 0.6590202177293935,
      "grad_norm": 0.028081340715289116,
      "learning_rate": 1.317651632970451e-05,
      "loss": 0.0371,
      "step": 3390
    },
    {
      "epoch": 0.6609642301710731,
      "grad_norm": 0.41903796792030334,
      "learning_rate": 1.3215396578538102e-05,
      "loss": 0.0009,
      "step": 3400
    },
    {
      "epoch": 0.6629082426127527,
      "grad_norm": 0.00742353918030858,
      "learning_rate": 1.3254276827371695e-05,
      "loss": 0.0005,
      "step": 3410
    },
    {
      "epoch": 0.6648522550544324,
      "grad_norm": 0.012086332775652409,
      "learning_rate": 1.3293157076205288e-05,
      "loss": 0.0006,
      "step": 3420
    },
    {
      "epoch": 0.666796267496112,
      "grad_norm": 0.005330717656761408,
      "learning_rate": 1.333203732503888e-05,
      "loss": 0.0794,
      "step": 3430
    },
    {
      "epoch": 0.6687402799377916,
      "grad_norm": 0.019552413374185562,
      "learning_rate": 1.3370917573872473e-05,
      "loss": 0.0084,
      "step": 3440
    },
    {
      "epoch": 0.6706842923794712,
      "grad_norm": 0.020986059680581093,
      "learning_rate": 1.3409797822706066e-05,
      "loss": 0.0065,
      "step": 3450
    },
    {
      "epoch": 0.6726283048211509,
      "grad_norm": 0.009735099971294403,
      "learning_rate": 1.3448678071539658e-05,
      "loss": 0.0011,
      "step": 3460
    },
    {
      "epoch": 0.6745723172628305,
      "grad_norm": 0.03235100209712982,
      "learning_rate": 1.348755832037325e-05,
      "loss": 0.0235,
      "step": 3470
    },
    {
      "epoch": 0.6765163297045101,
      "grad_norm": 0.003382007358595729,
      "learning_rate": 1.3526438569206844e-05,
      "loss": 0.0158,
      "step": 3480
    },
    {
      "epoch": 0.6784603421461898,
      "grad_norm": 0.006352799478918314,
      "learning_rate": 1.3565318818040437e-05,
      "loss": 0.1376,
      "step": 3490
    },
    {
      "epoch": 0.6804043545878694,
      "grad_norm": 0.008497003465890884,
      "learning_rate": 1.3604199066874029e-05,
      "loss": 0.0008,
      "step": 3500
    },
    {
      "epoch": 0.682348367029549,
      "grad_norm": 0.004875691141933203,
      "learning_rate": 1.3643079315707622e-05,
      "loss": 0.0198,
      "step": 3510
    },
    {
      "epoch": 0.6842923794712286,
      "grad_norm": 0.6588085293769836,
      "learning_rate": 1.3681959564541213e-05,
      "loss": 0.0269,
      "step": 3520
    },
    {
      "epoch": 0.6862363919129082,
      "grad_norm": 0.014175835996866226,
      "learning_rate": 1.3720839813374805e-05,
      "loss": 0.0271,
      "step": 3530
    },
    {
      "epoch": 0.6881804043545878,
      "grad_norm": 0.21733781695365906,
      "learning_rate": 1.3759720062208398e-05,
      "loss": 0.0004,
      "step": 3540
    },
    {
      "epoch": 0.6901244167962675,
      "grad_norm": 0.004579124506562948,
      "learning_rate": 1.3798600311041991e-05,
      "loss": 0.0003,
      "step": 3550
    },
    {
      "epoch": 0.6920684292379471,
      "grad_norm": 0.005084945820271969,
      "learning_rate": 1.3837480559875583e-05,
      "loss": 0.0029,
      "step": 3560
    },
    {
      "epoch": 0.6940124416796267,
      "grad_norm": 0.0030598279554396868,
      "learning_rate": 1.3876360808709176e-05,
      "loss": 0.0002,
      "step": 3570
    },
    {
      "epoch": 0.6959564541213064,
      "grad_norm": 0.007990873418748379,
      "learning_rate": 1.3915241057542769e-05,
      "loss": 0.0002,
      "step": 3580
    },
    {
      "epoch": 0.697900466562986,
      "grad_norm": 0.0025247973389923573,
      "learning_rate": 1.395412130637636e-05,
      "loss": 0.0003,
      "step": 3590
    },
    {
      "epoch": 0.6998444790046656,
      "grad_norm": 0.0034099025651812553,
      "learning_rate": 1.3993001555209954e-05,
      "loss": 0.0002,
      "step": 3600
    },
    {
      "epoch": 0.7017884914463453,
      "grad_norm": 21.98039436340332,
      "learning_rate": 1.4031881804043547e-05,
      "loss": 0.05,
      "step": 3610
    },
    {
      "epoch": 0.7037325038880249,
      "grad_norm": 0.004600364714860916,
      "learning_rate": 1.407076205287714e-05,
      "loss": 0.0002,
      "step": 3620
    },
    {
      "epoch": 0.7056765163297045,
      "grad_norm": 0.007446938659995794,
      "learning_rate": 1.4109642301710731e-05,
      "loss": 0.0002,
      "step": 3630
    },
    {
      "epoch": 0.7076205287713841,
      "grad_norm": 0.021356359124183655,
      "learning_rate": 1.4148522550544325e-05,
      "loss": 0.0003,
      "step": 3640
    },
    {
      "epoch": 0.7095645412130638,
      "grad_norm": 0.0061182077042758465,
      "learning_rate": 1.4187402799377918e-05,
      "loss": 0.0224,
      "step": 3650
    },
    {
      "epoch": 0.7115085536547434,
      "grad_norm": 1.2817373275756836,
      "learning_rate": 1.422628304821151e-05,
      "loss": 0.0203,
      "step": 3660
    },
    {
      "epoch": 0.713452566096423,
      "grad_norm": 0.0029058768413960934,
      "learning_rate": 1.42651632970451e-05,
      "loss": 0.0037,
      "step": 3670
    },
    {
      "epoch": 0.7153965785381027,
      "grad_norm": 0.13025414943695068,
      "learning_rate": 1.4304043545878694e-05,
      "loss": 0.0133,
      "step": 3680
    },
    {
      "epoch": 0.7173405909797823,
      "grad_norm": 0.011323723942041397,
      "learning_rate": 1.4342923794712285e-05,
      "loss": 0.002,
      "step": 3690
    },
    {
      "epoch": 0.7192846034214619,
      "grad_norm": 0.002941759303212166,
      "learning_rate": 1.4381804043545878e-05,
      "loss": 0.0004,
      "step": 3700
    },
    {
      "epoch": 0.7212286158631416,
      "grad_norm": 0.005263593513518572,
      "learning_rate": 1.4420684292379472e-05,
      "loss": 0.0021,
      "step": 3710
    },
    {
      "epoch": 0.7231726283048211,
      "grad_norm": 0.0017224138136953115,
      "learning_rate": 1.4459564541213063e-05,
      "loss": 0.0553,
      "step": 3720
    },
    {
      "epoch": 0.7251166407465007,
      "grad_norm": 0.0028436207212507725,
      "learning_rate": 1.4498444790046656e-05,
      "loss": 0.0001,
      "step": 3730
    },
    {
      "epoch": 0.7270606531881804,
      "grad_norm": 0.22969777882099152,
      "learning_rate": 1.453732503888025e-05,
      "loss": 0.0038,
      "step": 3740
    },
    {
      "epoch": 0.72900466562986,
      "grad_norm": 0.03697529062628746,
      "learning_rate": 1.4576205287713843e-05,
      "loss": 0.0283,
      "step": 3750
    },
    {
      "epoch": 0.7309486780715396,
      "grad_norm": 0.002947133267298341,
      "learning_rate": 1.4615085536547434e-05,
      "loss": 0.0002,
      "step": 3760
    },
    {
      "epoch": 0.7328926905132193,
      "grad_norm": 0.0025192920584231615,
      "learning_rate": 1.4653965785381027e-05,
      "loss": 0.0026,
      "step": 3770
    },
    {
      "epoch": 0.7348367029548989,
      "grad_norm": 0.0028914788272231817,
      "learning_rate": 1.469284603421462e-05,
      "loss": 0.0159,
      "step": 3780
    },
    {
      "epoch": 0.7367807153965785,
      "grad_norm": 0.002212707418948412,
      "learning_rate": 1.4731726283048212e-05,
      "loss": 0.0177,
      "step": 3790
    },
    {
      "epoch": 0.7387247278382582,
      "grad_norm": 0.0022091332357376814,
      "learning_rate": 1.4770606531881805e-05,
      "loss": 0.0214,
      "step": 3800
    },
    {
      "epoch": 0.7406687402799378,
      "grad_norm": 0.002324131317436695,
      "learning_rate": 1.4809486780715398e-05,
      "loss": 0.0007,
      "step": 3810
    },
    {
      "epoch": 0.7426127527216174,
      "grad_norm": 0.0019809782970696688,
      "learning_rate": 1.4848367029548988e-05,
      "loss": 0.0002,
      "step": 3820
    },
    {
      "epoch": 0.744556765163297,
      "grad_norm": 0.008530612103641033,
      "learning_rate": 1.4887247278382581e-05,
      "loss": 0.0179,
      "step": 3830
    },
    {
      "epoch": 0.7465007776049767,
      "grad_norm": 0.0028558066114783287,
      "learning_rate": 1.4926127527216174e-05,
      "loss": 0.0002,
      "step": 3840
    },
    {
      "epoch": 0.7484447900466563,
      "grad_norm": 0.9969313144683838,
      "learning_rate": 1.4965007776049766e-05,
      "loss": 0.0197,
      "step": 3850
    },
    {
      "epoch": 0.750388802488336,
      "grad_norm": 0.007000060752034187,
      "learning_rate": 1.500388802488336e-05,
      "loss": 0.0005,
      "step": 3860
    },
    {
      "epoch": 0.7523328149300156,
      "grad_norm": 0.0022716911043971777,
      "learning_rate": 1.5042768273716954e-05,
      "loss": 0.0148,
      "step": 3870
    },
    {
      "epoch": 0.7542768273716952,
      "grad_norm": 0.0030531161464750767,
      "learning_rate": 1.5081648522550547e-05,
      "loss": 0.0071,
      "step": 3880
    },
    {
      "epoch": 0.7562208398133748,
      "grad_norm": 0.011736943386495113,
      "learning_rate": 1.5120528771384135e-05,
      "loss": 0.0177,
      "step": 3890
    },
    {
      "epoch": 0.7581648522550545,
      "grad_norm": 0.0038855874445289373,
      "learning_rate": 1.5159409020217728e-05,
      "loss": 0.0007,
      "step": 3900
    },
    {
      "epoch": 0.7601088646967341,
      "grad_norm": 0.003578194184228778,
      "learning_rate": 1.5198289269051321e-05,
      "loss": 0.0077,
      "step": 3910
    },
    {
      "epoch": 0.7620528771384136,
      "grad_norm": 0.005917124450206757,
      "learning_rate": 1.5237169517884913e-05,
      "loss": 0.0002,
      "step": 3920
    },
    {
      "epoch": 0.7639968895800933,
      "grad_norm": 0.0035889192949980497,
      "learning_rate": 1.5276049766718508e-05,
      "loss": 0.0006,
      "step": 3930
    },
    {
      "epoch": 0.7659409020217729,
      "grad_norm": 0.0019021687330678105,
      "learning_rate": 1.5314930015552098e-05,
      "loss": 0.0305,
      "step": 3940
    },
    {
      "epoch": 0.7678849144634525,
      "grad_norm": 0.00492286030203104,
      "learning_rate": 1.535381026438569e-05,
      "loss": 0.0021,
      "step": 3950
    },
    {
      "epoch": 0.7698289269051322,
      "grad_norm": 0.01134421769529581,
      "learning_rate": 1.5392690513219284e-05,
      "loss": 0.0811,
      "step": 3960
    },
    {
      "epoch": 0.7717729393468118,
      "grad_norm": 0.02187502197921276,
      "learning_rate": 1.5431570762052877e-05,
      "loss": 0.0006,
      "step": 3970
    },
    {
      "epoch": 0.7737169517884914,
      "grad_norm": 0.009251716546714306,
      "learning_rate": 1.547045101088647e-05,
      "loss": 0.0013,
      "step": 3980
    },
    {
      "epoch": 0.7756609642301711,
      "grad_norm": 0.018397120758891106,
      "learning_rate": 1.5509331259720063e-05,
      "loss": 0.0023,
      "step": 3990
    },
    {
      "epoch": 0.7776049766718507,
      "grad_norm": 0.006358726881444454,
      "learning_rate": 1.5548211508553653e-05,
      "loss": 0.065,
      "step": 4000
    },
    {
      "epoch": 0.7795489891135303,
      "grad_norm": 0.06567707657814026,
      "learning_rate": 1.5587091757387246e-05,
      "loss": 0.0089,
      "step": 4010
    },
    {
      "epoch": 0.78149300155521,
      "grad_norm": 15.919232368469238,
      "learning_rate": 1.562597200622084e-05,
      "loss": 0.0062,
      "step": 4020
    },
    {
      "epoch": 0.7834370139968896,
      "grad_norm": 0.0034882626496255398,
      "learning_rate": 1.5664852255054433e-05,
      "loss": 0.0159,
      "step": 4030
    },
    {
      "epoch": 0.7853810264385692,
      "grad_norm": 6.528926372528076,
      "learning_rate": 1.5703732503888026e-05,
      "loss": 0.0007,
      "step": 4040
    },
    {
      "epoch": 0.7873250388802489,
      "grad_norm": 2.203984498977661,
      "learning_rate": 1.574261275272162e-05,
      "loss": 0.0853,
      "step": 4050
    },
    {
      "epoch": 0.7892690513219285,
      "grad_norm": 12.96924877166748,
      "learning_rate": 1.5781493001555212e-05,
      "loss": 0.0117,
      "step": 4060
    },
    {
      "epoch": 0.7912130637636081,
      "grad_norm": 0.08025886118412018,
      "learning_rate": 1.5820373250388802e-05,
      "loss": 0.0169,
      "step": 4070
    },
    {
      "epoch": 0.7931570762052877,
      "grad_norm": 0.11119522154331207,
      "learning_rate": 1.5859253499222395e-05,
      "loss": 0.01,
      "step": 4080
    },
    {
      "epoch": 0.7951010886469674,
      "grad_norm": 0.004800771828740835,
      "learning_rate": 1.589813374805599e-05,
      "loss": 0.0165,
      "step": 4090
    },
    {
      "epoch": 0.797045101088647,
      "grad_norm": 0.003933451138436794,
      "learning_rate": 1.593701399688958e-05,
      "loss": 0.0063,
      "step": 4100
    },
    {
      "epoch": 0.7989891135303266,
      "grad_norm": 0.00926373340189457,
      "learning_rate": 1.5975894245723175e-05,
      "loss": 0.0358,
      "step": 4110
    },
    {
      "epoch": 0.8009331259720062,
      "grad_norm": 5.432887077331543,
      "learning_rate": 1.6014774494556768e-05,
      "loss": 0.0044,
      "step": 4120
    },
    {
      "epoch": 0.8028771384136858,
      "grad_norm": 0.00346443266607821,
      "learning_rate": 1.6053654743390358e-05,
      "loss": 0.0005,
      "step": 4130
    },
    {
      "epoch": 0.8048211508553654,
      "grad_norm": 0.002351330826058984,
      "learning_rate": 1.609253499222395e-05,
      "loss": 0.0001,
      "step": 4140
    },
    {
      "epoch": 0.8067651632970451,
      "grad_norm": 0.0035697724670171738,
      "learning_rate": 1.6131415241057544e-05,
      "loss": 0.036,
      "step": 4150
    },
    {
      "epoch": 0.8087091757387247,
      "grad_norm": 0.0024043808225542307,
      "learning_rate": 1.6170295489891137e-05,
      "loss": 0.0103,
      "step": 4160
    },
    {
      "epoch": 0.8106531881804043,
      "grad_norm": 0.0031464931089431047,
      "learning_rate": 1.620917573872473e-05,
      "loss": 0.0003,
      "step": 4170
    },
    {
      "epoch": 0.812597200622084,
      "grad_norm": 0.011662162840366364,
      "learning_rate": 1.6248055987558323e-05,
      "loss": 0.0064,
      "step": 4180
    },
    {
      "epoch": 0.8145412130637636,
      "grad_norm": 0.20819386839866638,
      "learning_rate": 1.6286936236391917e-05,
      "loss": 0.0003,
      "step": 4190
    },
    {
      "epoch": 0.8164852255054432,
      "grad_norm": 0.0036322809755802155,
      "learning_rate": 1.6325816485225503e-05,
      "loss": 0.0002,
      "step": 4200
    },
    {
      "epoch": 0.8184292379471229,
      "grad_norm": 0.005325020290911198,
      "learning_rate": 1.6364696734059096e-05,
      "loss": 0.008,
      "step": 4210
    },
    {
      "epoch": 0.8203732503888025,
      "grad_norm": 0.0024199821054935455,
      "learning_rate": 1.640357698289269e-05,
      "loss": 0.0659,
      "step": 4220
    },
    {
      "epoch": 0.8223172628304821,
      "grad_norm": 0.004230621736496687,
      "learning_rate": 1.6442457231726283e-05,
      "loss": 0.0004,
      "step": 4230
    },
    {
      "epoch": 0.8242612752721618,
      "grad_norm": 0.005098759196698666,
      "learning_rate": 1.6481337480559876e-05,
      "loss": 0.0003,
      "step": 4240
    },
    {
      "epoch": 0.8262052877138414,
      "grad_norm": 0.08657269924879074,
      "learning_rate": 1.652021772939347e-05,
      "loss": 0.0031,
      "step": 4250
    },
    {
      "epoch": 0.828149300155521,
      "grad_norm": 0.0032005831599235535,
      "learning_rate": 1.655909797822706e-05,
      "loss": 0.0003,
      "step": 4260
    },
    {
      "epoch": 0.8300933125972006,
      "grad_norm": 0.0023850437719374895,
      "learning_rate": 1.6597978227060652e-05,
      "loss": 0.0075,
      "step": 4270
    },
    {
      "epoch": 0.8320373250388803,
      "grad_norm": 0.005191922653466463,
      "learning_rate": 1.6636858475894245e-05,
      "loss": 0.0002,
      "step": 4280
    },
    {
      "epoch": 0.8339813374805599,
      "grad_norm": 0.0021835099905729294,
      "learning_rate": 1.6675738724727838e-05,
      "loss": 0.0116,
      "step": 4290
    },
    {
      "epoch": 0.8359253499222395,
      "grad_norm": 2.4288008213043213,
      "learning_rate": 1.671461897356143e-05,
      "loss": 0.0836,
      "step": 4300
    },
    {
      "epoch": 0.8378693623639192,
      "grad_norm": 0.09286371618509293,
      "learning_rate": 1.6753499222395025e-05,
      "loss": 0.0019,
      "step": 4310
    },
    {
      "epoch": 0.8398133748055988,
      "grad_norm": 0.005511851981282234,
      "learning_rate": 1.6792379471228618e-05,
      "loss": 0.0003,
      "step": 4320
    },
    {
      "epoch": 0.8417573872472783,
      "grad_norm": 0.014807717874646187,
      "learning_rate": 1.6831259720062207e-05,
      "loss": 0.0006,
      "step": 4330
    },
    {
      "epoch": 0.843701399688958,
      "grad_norm": 0.07942982017993927,
      "learning_rate": 1.68701399688958e-05,
      "loss": 0.0004,
      "step": 4340
    },
    {
      "epoch": 0.8456454121306376,
      "grad_norm": 0.00168401759583503,
      "learning_rate": 1.6909020217729394e-05,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.8475894245723172,
      "grad_norm": 0.001951775630004704,
      "learning_rate": 1.6947900466562987e-05,
      "loss": 0.0002,
      "step": 4360
    },
    {
      "epoch": 0.8495334370139969,
      "grad_norm": 0.005864215083420277,
      "learning_rate": 1.698678071539658e-05,
      "loss": 0.0361,
      "step": 4370
    },
    {
      "epoch": 0.8514774494556765,
      "grad_norm": 0.006188840139657259,
      "learning_rate": 1.7025660964230173e-05,
      "loss": 0.012,
      "step": 4380
    },
    {
      "epoch": 0.8534214618973561,
      "grad_norm": 0.010136331431567669,
      "learning_rate": 1.7064541213063763e-05,
      "loss": 0.0002,
      "step": 4390
    },
    {
      "epoch": 0.8553654743390358,
      "grad_norm": 7.869561672210693,
      "learning_rate": 1.7103421461897356e-05,
      "loss": 0.0146,
      "step": 4400
    },
    {
      "epoch": 0.8573094867807154,
      "grad_norm": 0.002329979557543993,
      "learning_rate": 1.714230171073095e-05,
      "loss": 0.003,
      "step": 4410
    },
    {
      "epoch": 0.859253499222395,
      "grad_norm": 0.0015801402041688561,
      "learning_rate": 1.7181181959564543e-05,
      "loss": 0.0148,
      "step": 4420
    },
    {
      "epoch": 0.8611975116640747,
      "grad_norm": 0.0035790628753602505,
      "learning_rate": 1.7220062208398136e-05,
      "loss": 0.0104,
      "step": 4430
    },
    {
      "epoch": 0.8631415241057543,
      "grad_norm": 0.002755615394562483,
      "learning_rate": 1.725894245723173e-05,
      "loss": 0.0004,
      "step": 4440
    },
    {
      "epoch": 0.8650855365474339,
      "grad_norm": 0.006340604275465012,
      "learning_rate": 1.7297822706065322e-05,
      "loss": 0.0729,
      "step": 4450
    },
    {
      "epoch": 0.8670295489891136,
      "grad_norm": 0.011699185706675053,
      "learning_rate": 1.7336702954898912e-05,
      "loss": 0.0163,
      "step": 4460
    },
    {
      "epoch": 0.8689735614307932,
      "grad_norm": 0.023465972393751144,
      "learning_rate": 1.7375583203732505e-05,
      "loss": 0.003,
      "step": 4470
    },
    {
      "epoch": 0.8709175738724728,
      "grad_norm": 0.003683876944705844,
      "learning_rate": 1.7414463452566098e-05,
      "loss": 0.0002,
      "step": 4480
    },
    {
      "epoch": 0.8728615863141524,
      "grad_norm": 0.0033989818766713142,
      "learning_rate": 1.745334370139969e-05,
      "loss": 0.0002,
      "step": 4490
    },
    {
      "epoch": 0.8748055987558321,
      "grad_norm": 0.0027439433615654707,
      "learning_rate": 1.749222395023328e-05,
      "loss": 0.0439,
      "step": 4500
    },
    {
      "epoch": 0.8767496111975117,
      "grad_norm": 0.003682471811771393,
      "learning_rate": 1.7531104199066874e-05,
      "loss": 0.0391,
      "step": 4510
    },
    {
      "epoch": 0.8786936236391913,
      "grad_norm": 11.391883850097656,
      "learning_rate": 1.7569984447900464e-05,
      "loss": 0.0059,
      "step": 4520
    },
    {
      "epoch": 0.8806376360808709,
      "grad_norm": 0.005233895033597946,
      "learning_rate": 1.7608864696734057e-05,
      "loss": 0.0009,
      "step": 4530
    },
    {
      "epoch": 0.8825816485225505,
      "grad_norm": 0.508576512336731,
      "learning_rate": 1.764774494556765e-05,
      "loss": 0.0004,
      "step": 4540
    },
    {
      "epoch": 0.8845256609642301,
      "grad_norm": 0.006974864285439253,
      "learning_rate": 1.7686625194401244e-05,
      "loss": 0.0004,
      "step": 4550
    },
    {
      "epoch": 0.8864696734059098,
      "grad_norm": 0.002022148109972477,
      "learning_rate": 1.7725505443234837e-05,
      "loss": 0.0007,
      "step": 4560
    },
    {
      "epoch": 0.8884136858475894,
      "grad_norm": 0.003595256945118308,
      "learning_rate": 1.776438569206843e-05,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 0.890357698289269,
      "grad_norm": 0.001032492145895958,
      "learning_rate": 1.7803265940902023e-05,
      "loss": 0.0001,
      "step": 4580
    },
    {
      "epoch": 0.8923017107309487,
      "grad_norm": 0.0013849237002432346,
      "learning_rate": 1.7842146189735613e-05,
      "loss": 0.0002,
      "step": 4590
    },
    {
      "epoch": 0.8942457231726283,
      "grad_norm": 0.0025816471315920353,
      "learning_rate": 1.7881026438569206e-05,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 0.8961897356143079,
      "grad_norm": 0.017618386074900627,
      "learning_rate": 1.79199066874028e-05,
      "loss": 0.0138,
      "step": 4610
    },
    {
      "epoch": 0.8981337480559876,
      "grad_norm": 0.00257207197137177,
      "learning_rate": 1.7958786936236392e-05,
      "loss": 0.0393,
      "step": 4620
    },
    {
      "epoch": 0.9000777604976672,
      "grad_norm": 0.006197394337505102,
      "learning_rate": 1.7997667185069986e-05,
      "loss": 0.0017,
      "step": 4630
    },
    {
      "epoch": 0.9020217729393468,
      "grad_norm": 21.674978256225586,
      "learning_rate": 1.803654743390358e-05,
      "loss": 0.0215,
      "step": 4640
    },
    {
      "epoch": 0.9039657853810265,
      "grad_norm": 0.003161507658660412,
      "learning_rate": 1.807542768273717e-05,
      "loss": 0.0061,
      "step": 4650
    },
    {
      "epoch": 0.9059097978227061,
      "grad_norm": 0.001615464105270803,
      "learning_rate": 1.8114307931570762e-05,
      "loss": 0.0074,
      "step": 4660
    },
    {
      "epoch": 0.9078538102643857,
      "grad_norm": 0.0028198841027915478,
      "learning_rate": 1.8153188180404355e-05,
      "loss": 0.0004,
      "step": 4670
    },
    {
      "epoch": 0.9097978227060654,
      "grad_norm": 11.963775634765625,
      "learning_rate": 1.8192068429237948e-05,
      "loss": 0.0084,
      "step": 4680
    },
    {
      "epoch": 0.911741835147745,
      "grad_norm": 0.0010337975108996034,
      "learning_rate": 1.823094867807154e-05,
      "loss": 0.0295,
      "step": 4690
    },
    {
      "epoch": 0.9136858475894246,
      "grad_norm": 0.001250388566404581,
      "learning_rate": 1.8269828926905134e-05,
      "loss": 0.0324,
      "step": 4700
    },
    {
      "epoch": 0.9156298600311042,
      "grad_norm": 0.0071917688474059105,
      "learning_rate": 1.8308709175738728e-05,
      "loss": 0.0237,
      "step": 4710
    },
    {
      "epoch": 0.9175738724727839,
      "grad_norm": 0.0033228034153580666,
      "learning_rate": 1.8347589424572317e-05,
      "loss": 0.0055,
      "step": 4720
    },
    {
      "epoch": 0.9195178849144634,
      "grad_norm": 0.004006719216704369,
      "learning_rate": 1.838646967340591e-05,
      "loss": 0.0194,
      "step": 4730
    },
    {
      "epoch": 0.921461897356143,
      "grad_norm": 0.0026066608261317015,
      "learning_rate": 1.8425349922239504e-05,
      "loss": 0.0002,
      "step": 4740
    },
    {
      "epoch": 0.9234059097978227,
      "grad_norm": 7.8628458976745605,
      "learning_rate": 1.8464230171073097e-05,
      "loss": 0.0368,
      "step": 4750
    },
    {
      "epoch": 0.9253499222395023,
      "grad_norm": 0.7364726662635803,
      "learning_rate": 1.850311041990669e-05,
      "loss": 0.011,
      "step": 4760
    },
    {
      "epoch": 0.9272939346811819,
      "grad_norm": 0.002551560988649726,
      "learning_rate": 1.8541990668740283e-05,
      "loss": 0.0035,
      "step": 4770
    },
    {
      "epoch": 0.9292379471228616,
      "grad_norm": 0.004463352728635073,
      "learning_rate": 1.8580870917573873e-05,
      "loss": 0.0075,
      "step": 4780
    },
    {
      "epoch": 0.9311819595645412,
      "grad_norm": 0.002846632618457079,
      "learning_rate": 1.8619751166407466e-05,
      "loss": 0.019,
      "step": 4790
    },
    {
      "epoch": 0.9331259720062208,
      "grad_norm": 0.0015929352957755327,
      "learning_rate": 1.8658631415241056e-05,
      "loss": 0.0001,
      "step": 4800
    },
    {
      "epoch": 0.9350699844479005,
      "grad_norm": 0.015496442094445229,
      "learning_rate": 1.869751166407465e-05,
      "loss": 0.0072,
      "step": 4810
    },
    {
      "epoch": 0.9370139968895801,
      "grad_norm": 0.003001112723723054,
      "learning_rate": 1.8736391912908242e-05,
      "loss": 0.0342,
      "step": 4820
    },
    {
      "epoch": 0.9389580093312597,
      "grad_norm": 0.0019043090287595987,
      "learning_rate": 1.8775272161741835e-05,
      "loss": 0.0002,
      "step": 4830
    },
    {
      "epoch": 0.9409020217729394,
      "grad_norm": 0.0017153947846964002,
      "learning_rate": 1.881415241057543e-05,
      "loss": 0.0005,
      "step": 4840
    },
    {
      "epoch": 0.942846034214619,
      "grad_norm": 0.19743995368480682,
      "learning_rate": 1.885303265940902e-05,
      "loss": 0.033,
      "step": 4850
    },
    {
      "epoch": 0.9447900466562986,
      "grad_norm": 0.013341164216399193,
      "learning_rate": 1.889191290824261e-05,
      "loss": 0.0021,
      "step": 4860
    },
    {
      "epoch": 0.9467340590979783,
      "grad_norm": 0.006365006323903799,
      "learning_rate": 1.8930793157076205e-05,
      "loss": 0.0053,
      "step": 4870
    },
    {
      "epoch": 0.9486780715396579,
      "grad_norm": 6.880667209625244,
      "learning_rate": 1.8969673405909798e-05,
      "loss": 0.0181,
      "step": 4880
    },
    {
      "epoch": 0.9506220839813375,
      "grad_norm": 12.858870506286621,
      "learning_rate": 1.900855365474339e-05,
      "loss": 0.0014,
      "step": 4890
    },
    {
      "epoch": 0.9525660964230172,
      "grad_norm": 0.6182809472084045,
      "learning_rate": 1.9047433903576984e-05,
      "loss": 0.0135,
      "step": 4900
    },
    {
      "epoch": 0.9545101088646968,
      "grad_norm": 0.0013629522873088717,
      "learning_rate": 1.9086314152410574e-05,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 0.9564541213063764,
      "grad_norm": 0.0012543905759230256,
      "learning_rate": 1.9125194401244167e-05,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 0.9583981337480559,
      "grad_norm": 0.0018570878310129046,
      "learning_rate": 1.916407465007776e-05,
      "loss": 0.004,
      "step": 4930
    },
    {
      "epoch": 0.9603421461897356,
      "grad_norm": 0.0022955015301704407,
      "learning_rate": 1.9202954898911354e-05,
      "loss": 0.0001,
      "step": 4940
    },
    {
      "epoch": 0.9622861586314152,
      "grad_norm": 0.0012434767559170723,
      "learning_rate": 1.9241835147744947e-05,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 0.9642301710730948,
      "grad_norm": 0.0011874150950461626,
      "learning_rate": 1.928071539657854e-05,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 0.9661741835147745,
      "grad_norm": 0.0027707223780453205,
      "learning_rate": 1.9319595645412133e-05,
      "loss": 0.002,
      "step": 4970
    },
    {
      "epoch": 0.9681181959564541,
      "grad_norm": 0.018340790644288063,
      "learning_rate": 1.9358475894245723e-05,
      "loss": 0.0018,
      "step": 4980
    },
    {
      "epoch": 0.9700622083981337,
      "grad_norm": 0.01687263697385788,
      "learning_rate": 1.9397356143079316e-05,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 0.9720062208398134,
      "grad_norm": 1.8601347208023071,
      "learning_rate": 1.943623639191291e-05,
      "loss": 0.0286,
      "step": 5000
    },
    {
      "epoch": 0.973950233281493,
      "grad_norm": 0.013424661010503769,
      "learning_rate": 1.9475116640746502e-05,
      "loss": 0.0169,
      "step": 5010
    },
    {
      "epoch": 0.9758942457231726,
      "grad_norm": 0.017611976712942123,
      "learning_rate": 1.9513996889580095e-05,
      "loss": 0.001,
      "step": 5020
    },
    {
      "epoch": 0.9778382581648523,
      "grad_norm": 0.007210161071270704,
      "learning_rate": 1.955287713841369e-05,
      "loss": 0.0004,
      "step": 5030
    },
    {
      "epoch": 0.9797822706065319,
      "grad_norm": 0.003210261929780245,
      "learning_rate": 1.959175738724728e-05,
      "loss": 0.0002,
      "step": 5040
    },
    {
      "epoch": 0.9817262830482115,
      "grad_norm": 0.06611726433038712,
      "learning_rate": 1.963063763608087e-05,
      "loss": 0.0738,
      "step": 5050
    },
    {
      "epoch": 0.9836702954898912,
      "grad_norm": 0.01552268210798502,
      "learning_rate": 1.9669517884914465e-05,
      "loss": 0.0004,
      "step": 5060
    },
    {
      "epoch": 0.9856143079315708,
      "grad_norm": 0.0037954782601445913,
      "learning_rate": 1.9708398133748058e-05,
      "loss": 0.0003,
      "step": 5070
    },
    {
      "epoch": 0.9875583203732504,
      "grad_norm": 0.002490932121872902,
      "learning_rate": 1.974727838258165e-05,
      "loss": 0.0002,
      "step": 5080
    },
    {
      "epoch": 0.98950233281493,
      "grad_norm": 0.005215741693973541,
      "learning_rate": 1.9786158631415244e-05,
      "loss": 0.0049,
      "step": 5090
    },
    {
      "epoch": 0.9914463452566097,
      "grad_norm": 0.003206634661182761,
      "learning_rate": 1.9825038880248834e-05,
      "loss": 0.0001,
      "step": 5100
    },
    {
      "epoch": 0.9933903576982893,
      "grad_norm": 0.09121741354465485,
      "learning_rate": 1.9863919129082424e-05,
      "loss": 0.0002,
      "step": 5110
    },
    {
      "epoch": 0.995334370139969,
      "grad_norm": 0.0019504562951624393,
      "learning_rate": 1.9902799377916017e-05,
      "loss": 0.0009,
      "step": 5120
    },
    {
      "epoch": 0.9972783825816485,
      "grad_norm": 0.003406327683478594,
      "learning_rate": 1.994167962674961e-05,
      "loss": 0.0746,
      "step": 5130
    },
    {
      "epoch": 0.9992223950233281,
      "grad_norm": 0.03047923371195793,
      "learning_rate": 1.9980559875583203e-05,
      "loss": 0.0101,
      "step": 5140
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.9954898258863016,
      "eval_loss": 0.006690565031021833,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.9954898258863016,
          "precision": 0.9952810402684564,
          "recall": 0.9956986991187579,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.9954898258863016,
          "precision": 0.9952810402684564,
          "recall": 0.9956986991187579,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.9954898258863016,
          "precision": 0.9952810402684564,
          "recall": 0.9956986991187579,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9954898258863016,
          "precision": 0.9952810402684564,
          "recall": 0.9956986991187579,
          "support": 9532
        }
      },
      "eval_runtime": 74.8559,
      "eval_samples_per_second": 102.423,
      "eval_steps_per_second": 12.811,
      "step": 5144
    },
    {
      "epoch": 1.0011664074650077,
      "grad_norm": 0.0458744652569294,
      "learning_rate": 2.0019440124416797e-05,
      "loss": 0.0015,
      "step": 5150
    },
    {
      "epoch": 1.0031104199066874,
      "grad_norm": 2.457324266433716,
      "learning_rate": 2.005832037325039e-05,
      "loss": 0.0269,
      "step": 5160
    },
    {
      "epoch": 1.005054432348367,
      "grad_norm": 0.018645936623215675,
      "learning_rate": 2.009720062208398e-05,
      "loss": 0.0375,
      "step": 5170
    },
    {
      "epoch": 1.0069984447900466,
      "grad_norm": 0.003995521925389767,
      "learning_rate": 2.0136080870917573e-05,
      "loss": 0.0146,
      "step": 5180
    },
    {
      "epoch": 1.0089424572317263,
      "grad_norm": 0.05931743234395981,
      "learning_rate": 2.0174961119751166e-05,
      "loss": 0.0005,
      "step": 5190
    },
    {
      "epoch": 1.010886469673406,
      "grad_norm": 0.012071785517036915,
      "learning_rate": 2.021384136858476e-05,
      "loss": 0.0126,
      "step": 5200
    },
    {
      "epoch": 1.0128304821150855,
      "grad_norm": 0.0023865133989602327,
      "learning_rate": 2.0252721617418352e-05,
      "loss": 0.0167,
      "step": 5210
    },
    {
      "epoch": 1.0147744945567652,
      "grad_norm": 0.0026006815023720264,
      "learning_rate": 2.0291601866251945e-05,
      "loss": 0.0101,
      "step": 5220
    },
    {
      "epoch": 1.0167185069984448,
      "grad_norm": 0.0028433187399059534,
      "learning_rate": 2.033048211508554e-05,
      "loss": 0.0127,
      "step": 5230
    },
    {
      "epoch": 1.0186625194401244,
      "grad_norm": 0.0017278469167649746,
      "learning_rate": 2.0369362363919128e-05,
      "loss": 0.0157,
      "step": 5240
    },
    {
      "epoch": 1.020606531881804,
      "grad_norm": 0.004674133844673634,
      "learning_rate": 2.040824261275272e-05,
      "loss": 0.0002,
      "step": 5250
    },
    {
      "epoch": 1.0225505443234837,
      "grad_norm": 0.0019392521353438497,
      "learning_rate": 2.0447122861586315e-05,
      "loss": 0.0118,
      "step": 5260
    },
    {
      "epoch": 1.0244945567651633,
      "grad_norm": 0.0018859485862776637,
      "learning_rate": 2.0486003110419908e-05,
      "loss": 0.0081,
      "step": 5270
    },
    {
      "epoch": 1.026438569206843,
      "grad_norm": 0.0163943599909544,
      "learning_rate": 2.05248833592535e-05,
      "loss": 0.0005,
      "step": 5280
    },
    {
      "epoch": 1.0283825816485226,
      "grad_norm": 0.01840718649327755,
      "learning_rate": 2.0563763608087094e-05,
      "loss": 0.0538,
      "step": 5290
    },
    {
      "epoch": 1.0303265940902022,
      "grad_norm": 0.002089430345222354,
      "learning_rate": 2.0602643856920684e-05,
      "loss": 0.0019,
      "step": 5300
    },
    {
      "epoch": 1.0322706065318819,
      "grad_norm": 0.0022959865164011717,
      "learning_rate": 2.0641524105754277e-05,
      "loss": 0.0001,
      "step": 5310
    },
    {
      "epoch": 1.0342146189735615,
      "grad_norm": 0.22604355216026306,
      "learning_rate": 2.068040435458787e-05,
      "loss": 0.0012,
      "step": 5320
    },
    {
      "epoch": 1.0361586314152411,
      "grad_norm": 0.005338502116501331,
      "learning_rate": 2.0719284603421463e-05,
      "loss": 0.0155,
      "step": 5330
    },
    {
      "epoch": 1.0381026438569207,
      "grad_norm": 15.322227478027344,
      "learning_rate": 2.0758164852255057e-05,
      "loss": 0.0115,
      "step": 5340
    },
    {
      "epoch": 1.0400466562986004,
      "grad_norm": 0.0020358506590127945,
      "learning_rate": 2.079704510108865e-05,
      "loss": 0.0121,
      "step": 5350
    },
    {
      "epoch": 1.04199066874028,
      "grad_norm": 0.006606276147067547,
      "learning_rate": 2.0835925349922243e-05,
      "loss": 0.0001,
      "step": 5360
    },
    {
      "epoch": 1.0439346811819596,
      "grad_norm": 0.0026851643342524767,
      "learning_rate": 2.0874805598755833e-05,
      "loss": 0.0211,
      "step": 5370
    },
    {
      "epoch": 1.0458786936236393,
      "grad_norm": 0.057708125561475754,
      "learning_rate": 2.0913685847589426e-05,
      "loss": 0.0104,
      "step": 5380
    },
    {
      "epoch": 1.047822706065319,
      "grad_norm": 0.00245787319727242,
      "learning_rate": 2.095256609642302e-05,
      "loss": 0.0016,
      "step": 5390
    },
    {
      "epoch": 1.0497667185069985,
      "grad_norm": 0.0013241692213341594,
      "learning_rate": 2.099144634525661e-05,
      "loss": 0.0004,
      "step": 5400
    },
    {
      "epoch": 1.0517107309486782,
      "grad_norm": 0.030806448310613632,
      "learning_rate": 2.1030326594090202e-05,
      "loss": 0.0001,
      "step": 5410
    },
    {
      "epoch": 1.0536547433903576,
      "grad_norm": 0.0011293637799099088,
      "learning_rate": 2.1069206842923795e-05,
      "loss": 0.0262,
      "step": 5420
    },
    {
      "epoch": 1.0555987558320372,
      "grad_norm": 0.1338757425546646,
      "learning_rate": 2.1108087091757385e-05,
      "loss": 0.0011,
      "step": 5430
    },
    {
      "epoch": 1.0575427682737168,
      "grad_norm": 0.0014449002919718623,
      "learning_rate": 2.1146967340590978e-05,
      "loss": 0.0014,
      "step": 5440
    },
    {
      "epoch": 1.0594867807153965,
      "grad_norm": 0.0013218114618211985,
      "learning_rate": 2.118584758942457e-05,
      "loss": 0.0001,
      "step": 5450
    },
    {
      "epoch": 1.0614307931570761,
      "grad_norm": 0.0029617019463330507,
      "learning_rate": 2.1224727838258164e-05,
      "loss": 0.0001,
      "step": 5460
    },
    {
      "epoch": 1.0633748055987557,
      "grad_norm": 0.004761057905852795,
      "learning_rate": 2.1263608087091758e-05,
      "loss": 0.0001,
      "step": 5470
    },
    {
      "epoch": 1.0653188180404354,
      "grad_norm": 0.0015117315342649817,
      "learning_rate": 2.130248833592535e-05,
      "loss": 0.0114,
      "step": 5480
    },
    {
      "epoch": 1.067262830482115,
      "grad_norm": 0.00115824188105762,
      "learning_rate": 2.1341368584758944e-05,
      "loss": 0.0001,
      "step": 5490
    },
    {
      "epoch": 1.0692068429237946,
      "grad_norm": 0.001452753902412951,
      "learning_rate": 2.1380248833592534e-05,
      "loss": 0.0006,
      "step": 5500
    },
    {
      "epoch": 1.0711508553654743,
      "grad_norm": 0.0018201234051957726,
      "learning_rate": 2.1419129082426127e-05,
      "loss": 0.0008,
      "step": 5510
    },
    {
      "epoch": 1.073094867807154,
      "grad_norm": 1.2381489276885986,
      "learning_rate": 2.145800933125972e-05,
      "loss": 0.0003,
      "step": 5520
    },
    {
      "epoch": 1.0750388802488335,
      "grad_norm": 0.0024254426825791597,
      "learning_rate": 2.1496889580093313e-05,
      "loss": 0.0001,
      "step": 5530
    },
    {
      "epoch": 1.0769828926905132,
      "grad_norm": 0.0011852758470922709,
      "learning_rate": 2.1535769828926906e-05,
      "loss": 0.0001,
      "step": 5540
    },
    {
      "epoch": 1.0789269051321928,
      "grad_norm": 0.0012455072719603777,
      "learning_rate": 2.15746500777605e-05,
      "loss": 0.0017,
      "step": 5550
    },
    {
      "epoch": 1.0808709175738724,
      "grad_norm": 0.0013883985811844468,
      "learning_rate": 2.161353032659409e-05,
      "loss": 0.0234,
      "step": 5560
    },
    {
      "epoch": 1.082814930015552,
      "grad_norm": 0.012607376091182232,
      "learning_rate": 2.1652410575427683e-05,
      "loss": 0.0125,
      "step": 5570
    },
    {
      "epoch": 1.0847589424572317,
      "grad_norm": 0.005892126355320215,
      "learning_rate": 2.1691290824261276e-05,
      "loss": 0.0177,
      "step": 5580
    },
    {
      "epoch": 1.0867029548989113,
      "grad_norm": 0.03863164409995079,
      "learning_rate": 2.173017107309487e-05,
      "loss": 0.0002,
      "step": 5590
    },
    {
      "epoch": 1.088646967340591,
      "grad_norm": 0.030004214495420456,
      "learning_rate": 2.1769051321928462e-05,
      "loss": 0.0028,
      "step": 5600
    },
    {
      "epoch": 1.0905909797822706,
      "grad_norm": 0.0019265894079580903,
      "learning_rate": 2.1807931570762055e-05,
      "loss": 0.0002,
      "step": 5610
    },
    {
      "epoch": 1.0925349922239502,
      "grad_norm": 0.0021678840275853872,
      "learning_rate": 2.184681181959565e-05,
      "loss": 0.0157,
      "step": 5620
    },
    {
      "epoch": 1.0944790046656299,
      "grad_norm": 0.0018429202027618885,
      "learning_rate": 2.1885692068429238e-05,
      "loss": 0.0222,
      "step": 5630
    },
    {
      "epoch": 1.0964230171073095,
      "grad_norm": 0.6583259701728821,
      "learning_rate": 2.192457231726283e-05,
      "loss": 0.0057,
      "step": 5640
    },
    {
      "epoch": 1.0983670295489891,
      "grad_norm": 0.00107272167224437,
      "learning_rate": 2.1963452566096424e-05,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 1.1003110419906688,
      "grad_norm": 0.001873415894806385,
      "learning_rate": 2.2002332814930018e-05,
      "loss": 0.0029,
      "step": 5660
    },
    {
      "epoch": 1.1022550544323484,
      "grad_norm": 0.0017159590497612953,
      "learning_rate": 2.204121306376361e-05,
      "loss": 0.0017,
      "step": 5670
    },
    {
      "epoch": 1.104199066874028,
      "grad_norm": 0.18324455618858337,
      "learning_rate": 2.2080093312597204e-05,
      "loss": 0.0076,
      "step": 5680
    },
    {
      "epoch": 1.1061430793157077,
      "grad_norm": 38.66514205932617,
      "learning_rate": 2.2118973561430794e-05,
      "loss": 0.0259,
      "step": 5690
    },
    {
      "epoch": 1.1080870917573873,
      "grad_norm": 0.003332137828692794,
      "learning_rate": 2.2157853810264384e-05,
      "loss": 0.0094,
      "step": 5700
    },
    {
      "epoch": 1.110031104199067,
      "grad_norm": 0.012849453836679459,
      "learning_rate": 2.2196734059097977e-05,
      "loss": 0.0244,
      "step": 5710
    },
    {
      "epoch": 1.1119751166407466,
      "grad_norm": 0.003477057907730341,
      "learning_rate": 2.223561430793157e-05,
      "loss": 0.009,
      "step": 5720
    },
    {
      "epoch": 1.1139191290824262,
      "grad_norm": 0.0018578408053144813,
      "learning_rate": 2.2274494556765163e-05,
      "loss": 0.002,
      "step": 5730
    },
    {
      "epoch": 1.1158631415241058,
      "grad_norm": 0.0012879655696451664,
      "learning_rate": 2.2313374805598756e-05,
      "loss": 0.005,
      "step": 5740
    },
    {
      "epoch": 1.1178071539657854,
      "grad_norm": 0.0022840506862848997,
      "learning_rate": 2.235225505443235e-05,
      "loss": 0.0001,
      "step": 5750
    },
    {
      "epoch": 1.119751166407465,
      "grad_norm": 0.009352501481771469,
      "learning_rate": 2.239113530326594e-05,
      "loss": 0.0001,
      "step": 5760
    },
    {
      "epoch": 1.1216951788491447,
      "grad_norm": 0.0011352298315614462,
      "learning_rate": 2.2430015552099532e-05,
      "loss": 0.0015,
      "step": 5770
    },
    {
      "epoch": 1.1236391912908243,
      "grad_norm": 0.0008119149715639651,
      "learning_rate": 2.2468895800933126e-05,
      "loss": 0.0586,
      "step": 5780
    },
    {
      "epoch": 1.125583203732504,
      "grad_norm": 0.0012469056528061628,
      "learning_rate": 2.250777604976672e-05,
      "loss": 0.0202,
      "step": 5790
    },
    {
      "epoch": 1.1275272161741836,
      "grad_norm": 0.0012699681101366878,
      "learning_rate": 2.2546656298600312e-05,
      "loss": 0.0115,
      "step": 5800
    },
    {
      "epoch": 1.1294712286158632,
      "grad_norm": 0.03954869881272316,
      "learning_rate": 2.2585536547433905e-05,
      "loss": 0.0003,
      "step": 5810
    },
    {
      "epoch": 1.1314152410575429,
      "grad_norm": 0.0021458531264215708,
      "learning_rate": 2.2624416796267495e-05,
      "loss": 0.0059,
      "step": 5820
    },
    {
      "epoch": 1.1333592534992225,
      "grad_norm": 0.0009066876373253763,
      "learning_rate": 2.2663297045101088e-05,
      "loss": 0.0003,
      "step": 5830
    },
    {
      "epoch": 1.1353032659409021,
      "grad_norm": 0.0009015807881951332,
      "learning_rate": 2.270217729393468e-05,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 1.1372472783825818,
      "grad_norm": 3.30871844291687,
      "learning_rate": 2.2741057542768274e-05,
      "loss": 0.0002,
      "step": 5850
    },
    {
      "epoch": 1.1391912908242612,
      "grad_norm": 0.0009693179163150489,
      "learning_rate": 2.2779937791601867e-05,
      "loss": 0.0075,
      "step": 5860
    },
    {
      "epoch": 1.1411353032659408,
      "grad_norm": 0.0023996569216251373,
      "learning_rate": 2.281881804043546e-05,
      "loss": 0.0113,
      "step": 5870
    },
    {
      "epoch": 1.1430793157076204,
      "grad_norm": 0.0010505304671823978,
      "learning_rate": 2.2857698289269054e-05,
      "loss": 0.0017,
      "step": 5880
    },
    {
      "epoch": 1.1450233281493,
      "grad_norm": 0.0423799492418766,
      "learning_rate": 2.2896578538102644e-05,
      "loss": 0.0001,
      "step": 5890
    },
    {
      "epoch": 1.1469673405909797,
      "grad_norm": 0.001119186170399189,
      "learning_rate": 2.2935458786936237e-05,
      "loss": 0.0003,
      "step": 5900
    },
    {
      "epoch": 1.1489113530326593,
      "grad_norm": 0.009643546305596828,
      "learning_rate": 2.297433903576983e-05,
      "loss": 0.0001,
      "step": 5910
    },
    {
      "epoch": 1.150855365474339,
      "grad_norm": 0.0009901749435812235,
      "learning_rate": 2.3013219284603423e-05,
      "loss": 0.0003,
      "step": 5920
    },
    {
      "epoch": 1.1527993779160186,
      "grad_norm": 0.0005964841111563146,
      "learning_rate": 2.3052099533437016e-05,
      "loss": 0.0001,
      "step": 5930
    },
    {
      "epoch": 1.1547433903576982,
      "grad_norm": 0.0006362614221870899,
      "learning_rate": 2.309097978227061e-05,
      "loss": 0.0001,
      "step": 5940
    },
    {
      "epoch": 1.1566874027993779,
      "grad_norm": 0.0006415420793928206,
      "learning_rate": 2.31298600311042e-05,
      "loss": 0.0119,
      "step": 5950
    },
    {
      "epoch": 1.1586314152410575,
      "grad_norm": 0.0033107013441622257,
      "learning_rate": 2.3168740279937792e-05,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 1.1605754276827371,
      "grad_norm": 0.004205287434160709,
      "learning_rate": 2.3207620528771386e-05,
      "loss": 0.0011,
      "step": 5970
    },
    {
      "epoch": 1.1625194401244168,
      "grad_norm": 0.0012773387134075165,
      "learning_rate": 2.324650077760498e-05,
      "loss": 0.0001,
      "step": 5980
    },
    {
      "epoch": 1.1644634525660964,
      "grad_norm": 0.001466644462198019,
      "learning_rate": 2.3285381026438572e-05,
      "loss": 0.0338,
      "step": 5990
    },
    {
      "epoch": 1.166407465007776,
      "grad_norm": 0.012500111944973469,
      "learning_rate": 2.3324261275272162e-05,
      "loss": 0.0165,
      "step": 6000
    },
    {
      "epoch": 1.1683514774494557,
      "grad_norm": 0.002915716264396906,
      "learning_rate": 2.3363141524105755e-05,
      "loss": 0.0003,
      "step": 6010
    },
    {
      "epoch": 1.1702954898911353,
      "grad_norm": 0.0007395278080366552,
      "learning_rate": 2.3402021772939345e-05,
      "loss": 0.0291,
      "step": 6020
    },
    {
      "epoch": 1.172239502332815,
      "grad_norm": 0.0009896097471937537,
      "learning_rate": 2.3440902021772938e-05,
      "loss": 0.0036,
      "step": 6030
    },
    {
      "epoch": 1.1741835147744946,
      "grad_norm": 0.0013891780981794,
      "learning_rate": 2.347978227060653e-05,
      "loss": 0.0001,
      "step": 6040
    },
    {
      "epoch": 1.1761275272161742,
      "grad_norm": 1.3213931322097778,
      "learning_rate": 2.3518662519440124e-05,
      "loss": 0.0224,
      "step": 6050
    },
    {
      "epoch": 1.1780715396578538,
      "grad_norm": 0.040680889040231705,
      "learning_rate": 2.3557542768273717e-05,
      "loss": 0.0002,
      "step": 6060
    },
    {
      "epoch": 1.1800155520995335,
      "grad_norm": 0.007929333485662937,
      "learning_rate": 2.359642301710731e-05,
      "loss": 0.0027,
      "step": 6070
    },
    {
      "epoch": 1.181959564541213,
      "grad_norm": 0.00424854876473546,
      "learning_rate": 2.36353032659409e-05,
      "loss": 0.0002,
      "step": 6080
    },
    {
      "epoch": 1.1839035769828927,
      "grad_norm": 0.0024263521190732718,
      "learning_rate": 2.3674183514774493e-05,
      "loss": 0.0001,
      "step": 6090
    },
    {
      "epoch": 1.1858475894245724,
      "grad_norm": 0.005629853345453739,
      "learning_rate": 2.3713063763608087e-05,
      "loss": 0.0405,
      "step": 6100
    },
    {
      "epoch": 1.187791601866252,
      "grad_norm": 0.05732132866978645,
      "learning_rate": 2.375194401244168e-05,
      "loss": 0.0138,
      "step": 6110
    },
    {
      "epoch": 1.1897356143079316,
      "grad_norm": 0.019897952675819397,
      "learning_rate": 2.3790824261275273e-05,
      "loss": 0.0066,
      "step": 6120
    },
    {
      "epoch": 1.1916796267496113,
      "grad_norm": 9.201031684875488,
      "learning_rate": 2.3829704510108866e-05,
      "loss": 0.0143,
      "step": 6130
    },
    {
      "epoch": 1.1936236391912909,
      "grad_norm": 0.0021740521769970655,
      "learning_rate": 2.386858475894246e-05,
      "loss": 0.0201,
      "step": 6140
    },
    {
      "epoch": 1.1955676516329705,
      "grad_norm": 0.001570349675603211,
      "learning_rate": 2.390746500777605e-05,
      "loss": 0.0001,
      "step": 6150
    },
    {
      "epoch": 1.1975116640746502,
      "grad_norm": 0.0011364645324647427,
      "learning_rate": 2.3946345256609642e-05,
      "loss": 0.0131,
      "step": 6160
    },
    {
      "epoch": 1.1994556765163298,
      "grad_norm": 0.0016303716693073511,
      "learning_rate": 2.3985225505443235e-05,
      "loss": 0.0025,
      "step": 6170
    },
    {
      "epoch": 1.2013996889580094,
      "grad_norm": 0.01797892339527607,
      "learning_rate": 2.402410575427683e-05,
      "loss": 0.0567,
      "step": 6180
    },
    {
      "epoch": 1.203343701399689,
      "grad_norm": 0.004294995684176683,
      "learning_rate": 2.4062986003110422e-05,
      "loss": 0.0002,
      "step": 6190
    },
    {
      "epoch": 1.2052877138413687,
      "grad_norm": 0.0018333476036787033,
      "learning_rate": 2.4101866251944015e-05,
      "loss": 0.0021,
      "step": 6200
    },
    {
      "epoch": 1.207231726283048,
      "grad_norm": 0.01398258563131094,
      "learning_rate": 2.4140746500777605e-05,
      "loss": 0.0002,
      "step": 6210
    },
    {
      "epoch": 1.2091757387247277,
      "grad_norm": 7.087997913360596,
      "learning_rate": 2.4179626749611198e-05,
      "loss": 0.0057,
      "step": 6220
    },
    {
      "epoch": 1.2111197511664074,
      "grad_norm": 0.0012556258589029312,
      "learning_rate": 2.421850699844479e-05,
      "loss": 0.0004,
      "step": 6230
    },
    {
      "epoch": 1.213063763608087,
      "grad_norm": 0.0059280251152813435,
      "learning_rate": 2.4257387247278384e-05,
      "loss": 0.0094,
      "step": 6240
    },
    {
      "epoch": 1.2150077760497666,
      "grad_norm": 1.151078701019287,
      "learning_rate": 2.4296267496111977e-05,
      "loss": 0.0002,
      "step": 6250
    },
    {
      "epoch": 1.2169517884914463,
      "grad_norm": 0.0010691105853766203,
      "learning_rate": 2.433514774494557e-05,
      "loss": 0.0001,
      "step": 6260
    },
    {
      "epoch": 1.2188958009331259,
      "grad_norm": 0.001020025578327477,
      "learning_rate": 2.4374027993779164e-05,
      "loss": 0.0052,
      "step": 6270
    },
    {
      "epoch": 1.2208398133748055,
      "grad_norm": 2.440328359603882,
      "learning_rate": 2.4412908242612753e-05,
      "loss": 0.0031,
      "step": 6280
    },
    {
      "epoch": 1.2227838258164851,
      "grad_norm": 0.0009967094520106912,
      "learning_rate": 2.4451788491446347e-05,
      "loss": 0.0001,
      "step": 6290
    },
    {
      "epoch": 1.2247278382581648,
      "grad_norm": 0.0009550349786877632,
      "learning_rate": 2.449066874027994e-05,
      "loss": 0.0001,
      "step": 6300
    },
    {
      "epoch": 1.2266718506998444,
      "grad_norm": 0.001222454709932208,
      "learning_rate": 2.452954898911353e-05,
      "loss": 0.0101,
      "step": 6310
    },
    {
      "epoch": 1.228615863141524,
      "grad_norm": 0.005370879080146551,
      "learning_rate": 2.4568429237947123e-05,
      "loss": 0.0623,
      "step": 6320
    },
    {
      "epoch": 1.2305598755832037,
      "grad_norm": 0.006366703659296036,
      "learning_rate": 2.4607309486780716e-05,
      "loss": 0.0008,
      "step": 6330
    },
    {
      "epoch": 1.2325038880248833,
      "grad_norm": 0.011917885392904282,
      "learning_rate": 2.4646189735614306e-05,
      "loss": 0.0302,
      "step": 6340
    },
    {
      "epoch": 1.234447900466563,
      "grad_norm": 0.0023779571056365967,
      "learning_rate": 2.46850699844479e-05,
      "loss": 0.0114,
      "step": 6350
    },
    {
      "epoch": 1.2363919129082426,
      "grad_norm": 0.0054600415751338005,
      "learning_rate": 2.4723950233281492e-05,
      "loss": 0.0002,
      "step": 6360
    },
    {
      "epoch": 1.2383359253499222,
      "grad_norm": 0.04320230707526207,
      "learning_rate": 2.4762830482115085e-05,
      "loss": 0.0194,
      "step": 6370
    },
    {
      "epoch": 1.2402799377916018,
      "grad_norm": 4.6546149253845215,
      "learning_rate": 2.480171073094868e-05,
      "loss": 0.0327,
      "step": 6380
    },
    {
      "epoch": 1.2422239502332815,
      "grad_norm": 0.0017463116673752666,
      "learning_rate": 2.484059097978227e-05,
      "loss": 0.0077,
      "step": 6390
    },
    {
      "epoch": 1.244167962674961,
      "grad_norm": 0.0017704031197354198,
      "learning_rate": 2.4879471228615865e-05,
      "loss": 0.003,
      "step": 6400
    },
    {
      "epoch": 1.2461119751166407,
      "grad_norm": 0.0052171191200613976,
      "learning_rate": 2.4918351477449455e-05,
      "loss": 0.0002,
      "step": 6410
    },
    {
      "epoch": 1.2480559875583204,
      "grad_norm": 0.003435736522078514,
      "learning_rate": 2.4957231726283048e-05,
      "loss": 0.0001,
      "step": 6420
    },
    {
      "epoch": 1.25,
      "grad_norm": 51.10558319091797,
      "learning_rate": 2.499611197511664e-05,
      "loss": 0.0488,
      "step": 6430
    },
    {
      "epoch": 1.2519440124416796,
      "grad_norm": 0.00116797408554703,
      "learning_rate": 2.5034992223950234e-05,
      "loss": 0.0001,
      "step": 6440
    },
    {
      "epoch": 1.2538880248833593,
      "grad_norm": 0.0021114167757332325,
      "learning_rate": 2.5073872472783827e-05,
      "loss": 0.007,
      "step": 6450
    },
    {
      "epoch": 1.255832037325039,
      "grad_norm": 0.002984429942443967,
      "learning_rate": 2.511275272161742e-05,
      "loss": 0.0002,
      "step": 6460
    },
    {
      "epoch": 1.2577760497667185,
      "grad_norm": 0.017057692632079124,
      "learning_rate": 2.515163297045101e-05,
      "loss": 0.0056,
      "step": 6470
    },
    {
      "epoch": 1.2597200622083982,
      "grad_norm": 0.0026945441495627165,
      "learning_rate": 2.5190513219284603e-05,
      "loss": 0.0002,
      "step": 6480
    },
    {
      "epoch": 1.2616640746500778,
      "grad_norm": 0.0010212190682068467,
      "learning_rate": 2.5229393468118196e-05,
      "loss": 0.001,
      "step": 6490
    },
    {
      "epoch": 1.2636080870917574,
      "grad_norm": 0.00132271449547261,
      "learning_rate": 2.526827371695179e-05,
      "loss": 0.0002,
      "step": 6500
    },
    {
      "epoch": 1.265552099533437,
      "grad_norm": 0.0013007366796955466,
      "learning_rate": 2.5307153965785383e-05,
      "loss": 0.03,
      "step": 6510
    },
    {
      "epoch": 1.2674961119751167,
      "grad_norm": 0.0036023748107254505,
      "learning_rate": 2.5346034214618976e-05,
      "loss": 0.0001,
      "step": 6520
    },
    {
      "epoch": 1.2694401244167963,
      "grad_norm": 0.002906866604462266,
      "learning_rate": 2.538491446345257e-05,
      "loss": 0.0001,
      "step": 6530
    },
    {
      "epoch": 1.271384136858476,
      "grad_norm": 0.0029709823429584503,
      "learning_rate": 2.542379471228616e-05,
      "loss": 0.0001,
      "step": 6540
    },
    {
      "epoch": 1.2733281493001556,
      "grad_norm": 0.0018562889890745282,
      "learning_rate": 2.5462674961119752e-05,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 1.2752721617418352,
      "grad_norm": 0.0021354875061661005,
      "learning_rate": 2.5501555209953345e-05,
      "loss": 0.015,
      "step": 6560
    },
    {
      "epoch": 1.2772161741835149,
      "grad_norm": 0.0017886271234601736,
      "learning_rate": 2.554043545878694e-05,
      "loss": 0.0055,
      "step": 6570
    },
    {
      "epoch": 1.2791601866251945,
      "grad_norm": 8.769561767578125,
      "learning_rate": 2.557931570762053e-05,
      "loss": 0.0374,
      "step": 6580
    },
    {
      "epoch": 1.2811041990668741,
      "grad_norm": 35.79735565185547,
      "learning_rate": 2.5618195956454125e-05,
      "loss": 0.004,
      "step": 6590
    },
    {
      "epoch": 1.2830482115085537,
      "grad_norm": 0.0050565330311656,
      "learning_rate": 2.5657076205287715e-05,
      "loss": 0.0321,
      "step": 6600
    },
    {
      "epoch": 1.2849922239502334,
      "grad_norm": 14.591537475585938,
      "learning_rate": 2.5695956454121304e-05,
      "loss": 0.0384,
      "step": 6610
    },
    {
      "epoch": 1.286936236391913,
      "grad_norm": 0.01449680794030428,
      "learning_rate": 2.5734836702954898e-05,
      "loss": 0.0176,
      "step": 6620
    },
    {
      "epoch": 1.2888802488335926,
      "grad_norm": 0.013508693315088749,
      "learning_rate": 2.577371695178849e-05,
      "loss": 0.0106,
      "step": 6630
    },
    {
      "epoch": 1.2908242612752723,
      "grad_norm": 0.004061567131429911,
      "learning_rate": 2.5812597200622084e-05,
      "loss": 0.0004,
      "step": 6640
    },
    {
      "epoch": 1.292768273716952,
      "grad_norm": 0.002496827393770218,
      "learning_rate": 2.5851477449455677e-05,
      "loss": 0.0019,
      "step": 6650
    },
    {
      "epoch": 1.2947122861586315,
      "grad_norm": 0.015877239406108856,
      "learning_rate": 2.589035769828927e-05,
      "loss": 0.0002,
      "step": 6660
    },
    {
      "epoch": 1.2966562986003112,
      "grad_norm": 0.004021042492240667,
      "learning_rate": 2.592923794712286e-05,
      "loss": 0.017,
      "step": 6670
    },
    {
      "epoch": 1.2986003110419908,
      "grad_norm": 0.030747735872864723,
      "learning_rate": 2.5968118195956453e-05,
      "loss": 0.0007,
      "step": 6680
    },
    {
      "epoch": 1.3005443234836702,
      "grad_norm": 0.01106099784374237,
      "learning_rate": 2.6006998444790046e-05,
      "loss": 0.0316,
      "step": 6690
    },
    {
      "epoch": 1.3024883359253498,
      "grad_norm": 0.1581832766532898,
      "learning_rate": 2.604587869362364e-05,
      "loss": 0.0023,
      "step": 6700
    },
    {
      "epoch": 1.3044323483670295,
      "grad_norm": 1.3924477100372314,
      "learning_rate": 2.6084758942457233e-05,
      "loss": 0.0625,
      "step": 6710
    },
    {
      "epoch": 1.3063763608087091,
      "grad_norm": 0.004213582258671522,
      "learning_rate": 2.6123639191290826e-05,
      "loss": 0.0157,
      "step": 6720
    },
    {
      "epoch": 1.3083203732503887,
      "grad_norm": 0.0038444316014647484,
      "learning_rate": 2.6162519440124416e-05,
      "loss": 0.0084,
      "step": 6730
    },
    {
      "epoch": 1.3102643856920684,
      "grad_norm": 0.0049329036846756935,
      "learning_rate": 2.620139968895801e-05,
      "loss": 0.0002,
      "step": 6740
    },
    {
      "epoch": 1.312208398133748,
      "grad_norm": 0.004489219281822443,
      "learning_rate": 2.6240279937791602e-05,
      "loss": 0.0284,
      "step": 6750
    },
    {
      "epoch": 1.3141524105754276,
      "grad_norm": 0.016707120463252068,
      "learning_rate": 2.6279160186625195e-05,
      "loss": 0.033,
      "step": 6760
    },
    {
      "epoch": 1.3160964230171073,
      "grad_norm": 0.014798414893448353,
      "learning_rate": 2.6318040435458788e-05,
      "loss": 0.0009,
      "step": 6770
    },
    {
      "epoch": 1.318040435458787,
      "grad_norm": 0.08781739324331284,
      "learning_rate": 2.635692068429238e-05,
      "loss": 0.0201,
      "step": 6780
    },
    {
      "epoch": 1.3199844479004665,
      "grad_norm": 0.005079327616840601,
      "learning_rate": 2.6395800933125975e-05,
      "loss": 0.0007,
      "step": 6790
    },
    {
      "epoch": 1.3219284603421462,
      "grad_norm": 0.0015196176245808601,
      "learning_rate": 2.6434681181959564e-05,
      "loss": 0.0003,
      "step": 6800
    },
    {
      "epoch": 1.3238724727838258,
      "grad_norm": 0.0016973635647445917,
      "learning_rate": 2.6473561430793158e-05,
      "loss": 0.0001,
      "step": 6810
    },
    {
      "epoch": 1.3258164852255054,
      "grad_norm": 0.8416303992271423,
      "learning_rate": 2.651244167962675e-05,
      "loss": 0.0023,
      "step": 6820
    },
    {
      "epoch": 1.327760497667185,
      "grad_norm": 0.003558920230716467,
      "learning_rate": 2.6551321928460344e-05,
      "loss": 0.0152,
      "step": 6830
    },
    {
      "epoch": 1.3297045101088647,
      "grad_norm": 0.0024994900450110435,
      "learning_rate": 2.6590202177293937e-05,
      "loss": 0.0757,
      "step": 6840
    },
    {
      "epoch": 1.3316485225505443,
      "grad_norm": 0.007932240143418312,
      "learning_rate": 2.662908242612753e-05,
      "loss": 0.011,
      "step": 6850
    },
    {
      "epoch": 1.333592534992224,
      "grad_norm": 0.6741877794265747,
      "learning_rate": 2.666796267496112e-05,
      "loss": 0.0095,
      "step": 6860
    },
    {
      "epoch": 1.3355365474339036,
      "grad_norm": 26.912389755249023,
      "learning_rate": 2.6706842923794713e-05,
      "loss": 0.0107,
      "step": 6870
    },
    {
      "epoch": 1.3374805598755832,
      "grad_norm": 0.004408429376780987,
      "learning_rate": 2.6745723172628306e-05,
      "loss": 0.0001,
      "step": 6880
    },
    {
      "epoch": 1.3394245723172629,
      "grad_norm": 0.0016372252721339464,
      "learning_rate": 2.67846034214619e-05,
      "loss": 0.036,
      "step": 6890
    },
    {
      "epoch": 1.3413685847589425,
      "grad_norm": 0.014640111476182938,
      "learning_rate": 2.6823483670295493e-05,
      "loss": 0.0229,
      "step": 6900
    },
    {
      "epoch": 1.3433125972006221,
      "grad_norm": 0.29657986760139465,
      "learning_rate": 2.6862363919129082e-05,
      "loss": 0.0384,
      "step": 6910
    },
    {
      "epoch": 1.3452566096423018,
      "grad_norm": 0.14211466908454895,
      "learning_rate": 2.6901244167962676e-05,
      "loss": 0.0007,
      "step": 6920
    },
    {
      "epoch": 1.3472006220839814,
      "grad_norm": 0.001595151610672474,
      "learning_rate": 2.6940124416796265e-05,
      "loss": 0.0023,
      "step": 6930
    },
    {
      "epoch": 1.349144634525661,
      "grad_norm": 0.0012459632707759738,
      "learning_rate": 2.697900466562986e-05,
      "loss": 0.0011,
      "step": 6940
    },
    {
      "epoch": 1.3510886469673407,
      "grad_norm": 0.002722707111388445,
      "learning_rate": 2.7017884914463452e-05,
      "loss": 0.0971,
      "step": 6950
    },
    {
      "epoch": 1.3530326594090203,
      "grad_norm": 0.00761850131675601,
      "learning_rate": 2.7056765163297045e-05,
      "loss": 0.0116,
      "step": 6960
    },
    {
      "epoch": 1.3549766718507,
      "grad_norm": 0.007192716933786869,
      "learning_rate": 2.7095645412130638e-05,
      "loss": 0.0127,
      "step": 6970
    },
    {
      "epoch": 1.3569206842923796,
      "grad_norm": 0.23878304660320282,
      "learning_rate": 2.713452566096423e-05,
      "loss": 0.0175,
      "step": 6980
    },
    {
      "epoch": 1.358864696734059,
      "grad_norm": 0.019510680809617043,
      "learning_rate": 2.717340590979782e-05,
      "loss": 0.003,
      "step": 6990
    },
    {
      "epoch": 1.3608087091757386,
      "grad_norm": 0.011247404851019382,
      "learning_rate": 2.7212286158631414e-05,
      "loss": 0.0005,
      "step": 7000
    },
    {
      "epoch": 1.3627527216174182,
      "grad_norm": 0.0023346138186752796,
      "learning_rate": 2.7251166407465007e-05,
      "loss": 0.0031,
      "step": 7010
    },
    {
      "epoch": 1.3646967340590979,
      "grad_norm": 0.003618965158239007,
      "learning_rate": 2.72900466562986e-05,
      "loss": 0.044,
      "step": 7020
    },
    {
      "epoch": 1.3666407465007775,
      "grad_norm": 0.004322972148656845,
      "learning_rate": 2.7328926905132194e-05,
      "loss": 0.0002,
      "step": 7030
    },
    {
      "epoch": 1.3685847589424571,
      "grad_norm": 8.916881561279297,
      "learning_rate": 2.7367807153965787e-05,
      "loss": 0.0983,
      "step": 7040
    },
    {
      "epoch": 1.3705287713841368,
      "grad_norm": 1.3472625017166138,
      "learning_rate": 2.740668740279938e-05,
      "loss": 0.0044,
      "step": 7050
    },
    {
      "epoch": 1.3724727838258164,
      "grad_norm": 1.8707295656204224,
      "learning_rate": 2.744556765163297e-05,
      "loss": 0.0309,
      "step": 7060
    },
    {
      "epoch": 1.374416796267496,
      "grad_norm": 0.006297808140516281,
      "learning_rate": 2.7484447900466563e-05,
      "loss": 0.0082,
      "step": 7070
    },
    {
      "epoch": 1.3763608087091757,
      "grad_norm": 0.006148843560367823,
      "learning_rate": 2.7523328149300156e-05,
      "loss": 0.0219,
      "step": 7080
    },
    {
      "epoch": 1.3783048211508553,
      "grad_norm": 0.001878475770354271,
      "learning_rate": 2.756220839813375e-05,
      "loss": 0.0029,
      "step": 7090
    },
    {
      "epoch": 1.380248833592535,
      "grad_norm": 0.009094096720218658,
      "learning_rate": 2.7601088646967343e-05,
      "loss": 0.0105,
      "step": 7100
    },
    {
      "epoch": 1.3821928460342146,
      "grad_norm": 0.007168415002524853,
      "learning_rate": 2.7639968895800936e-05,
      "loss": 0.0209,
      "step": 7110
    },
    {
      "epoch": 1.3841368584758942,
      "grad_norm": 1.9926228523254395,
      "learning_rate": 2.7678849144634525e-05,
      "loss": 0.0069,
      "step": 7120
    },
    {
      "epoch": 1.3860808709175738,
      "grad_norm": 0.003125301096588373,
      "learning_rate": 2.771772939346812e-05,
      "loss": 0.0133,
      "step": 7130
    },
    {
      "epoch": 1.3880248833592534,
      "grad_norm": 0.06773697584867477,
      "learning_rate": 2.7756609642301712e-05,
      "loss": 0.0127,
      "step": 7140
    },
    {
      "epoch": 1.389968895800933,
      "grad_norm": 0.0017142592696473002,
      "learning_rate": 2.7795489891135305e-05,
      "loss": 0.0272,
      "step": 7150
    },
    {
      "epoch": 1.3919129082426127,
      "grad_norm": 0.0017599714919924736,
      "learning_rate": 2.7834370139968898e-05,
      "loss": 0.0003,
      "step": 7160
    },
    {
      "epoch": 1.3938569206842923,
      "grad_norm": 0.012892092578113079,
      "learning_rate": 2.787325038880249e-05,
      "loss": 0.0353,
      "step": 7170
    },
    {
      "epoch": 1.395800933125972,
      "grad_norm": 0.01663762889802456,
      "learning_rate": 2.7912130637636085e-05,
      "loss": 0.0181,
      "step": 7180
    },
    {
      "epoch": 1.3977449455676516,
      "grad_norm": 0.0981915220618248,
      "learning_rate": 2.7951010886469674e-05,
      "loss": 0.0005,
      "step": 7190
    },
    {
      "epoch": 1.3996889580093312,
      "grad_norm": 0.003962966147810221,
      "learning_rate": 2.7989891135303267e-05,
      "loss": 0.0002,
      "step": 7200
    },
    {
      "epoch": 1.4016329704510109,
      "grad_norm": 0.0013696464011445642,
      "learning_rate": 2.8028771384136857e-05,
      "loss": 0.0002,
      "step": 7210
    },
    {
      "epoch": 1.4035769828926905,
      "grad_norm": 0.0018047350458800793,
      "learning_rate": 2.806765163297045e-05,
      "loss": 0.0017,
      "step": 7220
    },
    {
      "epoch": 1.4055209953343701,
      "grad_norm": 0.0025396819692105055,
      "learning_rate": 2.8106531881804044e-05,
      "loss": 0.0238,
      "step": 7230
    },
    {
      "epoch": 1.4074650077760498,
      "grad_norm": 0.001448676805011928,
      "learning_rate": 2.8145412130637637e-05,
      "loss": 0.0001,
      "step": 7240
    },
    {
      "epoch": 1.4094090202177294,
      "grad_norm": 0.001099434681236744,
      "learning_rate": 2.8184292379471227e-05,
      "loss": 0.0002,
      "step": 7250
    },
    {
      "epoch": 1.411353032659409,
      "grad_norm": 0.001174618024379015,
      "learning_rate": 2.822317262830482e-05,
      "loss": 0.0001,
      "step": 7260
    },
    {
      "epoch": 1.4132970451010887,
      "grad_norm": 0.9643954038619995,
      "learning_rate": 2.8262052877138413e-05,
      "loss": 0.0016,
      "step": 7270
    },
    {
      "epoch": 1.4152410575427683,
      "grad_norm": 6.478182792663574,
      "learning_rate": 2.8300933125972006e-05,
      "loss": 0.0615,
      "step": 7280
    },
    {
      "epoch": 1.417185069984448,
      "grad_norm": 0.003265614388510585,
      "learning_rate": 2.83398133748056e-05,
      "loss": 0.0001,
      "step": 7290
    },
    {
      "epoch": 1.4191290824261276,
      "grad_norm": 0.001410057651810348,
      "learning_rate": 2.8378693623639192e-05,
      "loss": 0.0056,
      "step": 7300
    },
    {
      "epoch": 1.4210730948678072,
      "grad_norm": 0.0025135227479040623,
      "learning_rate": 2.8417573872472786e-05,
      "loss": 0.0116,
      "step": 7310
    },
    {
      "epoch": 1.4230171073094868,
      "grad_norm": 0.11769141256809235,
      "learning_rate": 2.8456454121306375e-05,
      "loss": 0.0068,
      "step": 7320
    },
    {
      "epoch": 1.4249611197511665,
      "grad_norm": 0.012023511342704296,
      "learning_rate": 2.849533437013997e-05,
      "loss": 0.0132,
      "step": 7330
    },
    {
      "epoch": 1.426905132192846,
      "grad_norm": 0.008784420788288116,
      "learning_rate": 2.853421461897356e-05,
      "loss": 0.0057,
      "step": 7340
    },
    {
      "epoch": 1.4288491446345257,
      "grad_norm": 0.001656650216318667,
      "learning_rate": 2.8573094867807155e-05,
      "loss": 0.0002,
      "step": 7350
    },
    {
      "epoch": 1.4307931570762054,
      "grad_norm": 0.0021679867058992386,
      "learning_rate": 2.8611975116640748e-05,
      "loss": 0.0142,
      "step": 7360
    },
    {
      "epoch": 1.432737169517885,
      "grad_norm": 0.000806918425951153,
      "learning_rate": 2.865085536547434e-05,
      "loss": 0.0003,
      "step": 7370
    },
    {
      "epoch": 1.4346811819595646,
      "grad_norm": 1.8403335809707642,
      "learning_rate": 2.868973561430793e-05,
      "loss": 0.005,
      "step": 7380
    },
    {
      "epoch": 1.4366251944012443,
      "grad_norm": 0.001903848024085164,
      "learning_rate": 2.8728615863141524e-05,
      "loss": 0.0001,
      "step": 7390
    },
    {
      "epoch": 1.4385692068429239,
      "grad_norm": 0.0009066188358701766,
      "learning_rate": 2.8767496111975117e-05,
      "loss": 0.0006,
      "step": 7400
    },
    {
      "epoch": 1.4405132192846035,
      "grad_norm": 0.0010536493500694633,
      "learning_rate": 2.880637636080871e-05,
      "loss": 0.0001,
      "step": 7410
    },
    {
      "epoch": 1.4424572317262832,
      "grad_norm": 0.0011292870622128248,
      "learning_rate": 2.8845256609642304e-05,
      "loss": 0.0001,
      "step": 7420
    },
    {
      "epoch": 1.4444012441679628,
      "grad_norm": 0.0007029184489510953,
      "learning_rate": 2.8884136858475897e-05,
      "loss": 0.0003,
      "step": 7430
    },
    {
      "epoch": 1.4463452566096424,
      "grad_norm": 0.0007571801543235779,
      "learning_rate": 2.892301710730949e-05,
      "loss": 0.0,
      "step": 7440
    },
    {
      "epoch": 1.448289269051322,
      "grad_norm": 0.0007810097304172814,
      "learning_rate": 2.896189735614308e-05,
      "loss": 0.0,
      "step": 7450
    },
    {
      "epoch": 1.4502332814930017,
      "grad_norm": 0.0006966658402234316,
      "learning_rate": 2.9000777604976673e-05,
      "loss": 0.0,
      "step": 7460
    },
    {
      "epoch": 1.4521772939346813,
      "grad_norm": 0.0008037423249334097,
      "learning_rate": 2.9039657853810266e-05,
      "loss": 0.0132,
      "step": 7470
    },
    {
      "epoch": 1.454121306376361,
      "grad_norm": 0.001045495504513383,
      "learning_rate": 2.907853810264386e-05,
      "loss": 0.0693,
      "step": 7480
    },
    {
      "epoch": 1.4560653188180404,
      "grad_norm": 0.0031679815147072077,
      "learning_rate": 2.9117418351477452e-05,
      "loss": 0.0002,
      "step": 7490
    },
    {
      "epoch": 1.45800933125972,
      "grad_norm": 0.0010773979593068361,
      "learning_rate": 2.9156298600311046e-05,
      "loss": 0.0096,
      "step": 7500
    },
    {
      "epoch": 1.4599533437013996,
      "grad_norm": 0.015537039376795292,
      "learning_rate": 2.9195178849144632e-05,
      "loss": 0.0248,
      "step": 7510
    },
    {
      "epoch": 1.4618973561430793,
      "grad_norm": 0.002993602305650711,
      "learning_rate": 2.9234059097978225e-05,
      "loss": 0.0088,
      "step": 7520
    },
    {
      "epoch": 1.4638413685847589,
      "grad_norm": 0.002665448933839798,
      "learning_rate": 2.927293934681182e-05,
      "loss": 0.0282,
      "step": 7530
    },
    {
      "epoch": 1.4657853810264385,
      "grad_norm": 0.015939651057124138,
      "learning_rate": 2.931181959564541e-05,
      "loss": 0.0452,
      "step": 7540
    },
    {
      "epoch": 1.4677293934681181,
      "grad_norm": 0.007415315136313438,
      "learning_rate": 2.9350699844479005e-05,
      "loss": 0.0002,
      "step": 7550
    },
    {
      "epoch": 1.4696734059097978,
      "grad_norm": 0.0028250310570001602,
      "learning_rate": 2.9389580093312598e-05,
      "loss": 0.0275,
      "step": 7560
    },
    {
      "epoch": 1.4716174183514774,
      "grad_norm": 0.0025350425858050585,
      "learning_rate": 2.942846034214619e-05,
      "loss": 0.0008,
      "step": 7570
    },
    {
      "epoch": 1.473561430793157,
      "grad_norm": 0.001623413641937077,
      "learning_rate": 2.946734059097978e-05,
      "loss": 0.0002,
      "step": 7580
    },
    {
      "epoch": 1.4755054432348367,
      "grad_norm": 0.0007995013729669154,
      "learning_rate": 2.9506220839813374e-05,
      "loss": 0.0001,
      "step": 7590
    },
    {
      "epoch": 1.4774494556765163,
      "grad_norm": 0.010670686140656471,
      "learning_rate": 2.9545101088646967e-05,
      "loss": 0.0001,
      "step": 7600
    },
    {
      "epoch": 1.479393468118196,
      "grad_norm": 0.0012719221413135529,
      "learning_rate": 2.958398133748056e-05,
      "loss": 0.0151,
      "step": 7610
    },
    {
      "epoch": 1.4813374805598756,
      "grad_norm": 0.0013494001468643546,
      "learning_rate": 2.9622861586314153e-05,
      "loss": 0.0001,
      "step": 7620
    },
    {
      "epoch": 1.4832814930015552,
      "grad_norm": 0.0062351045198738575,
      "learning_rate": 2.9661741835147747e-05,
      "loss": 0.0015,
      "step": 7630
    },
    {
      "epoch": 1.4852255054432348,
      "grad_norm": 0.0012720207450911403,
      "learning_rate": 2.9700622083981336e-05,
      "loss": 0.0003,
      "step": 7640
    },
    {
      "epoch": 1.4871695178849145,
      "grad_norm": 0.002672903472557664,
      "learning_rate": 2.973950233281493e-05,
      "loss": 0.0175,
      "step": 7650
    },
    {
      "epoch": 1.489113530326594,
      "grad_norm": 0.02233325131237507,
      "learning_rate": 2.9778382581648523e-05,
      "loss": 0.0006,
      "step": 7660
    },
    {
      "epoch": 1.4910575427682737,
      "grad_norm": 10.613255500793457,
      "learning_rate": 2.9817262830482116e-05,
      "loss": 0.0096,
      "step": 7670
    },
    {
      "epoch": 1.4930015552099534,
      "grad_norm": 0.001646764692850411,
      "learning_rate": 2.985614307931571e-05,
      "loss": 0.0036,
      "step": 7680
    },
    {
      "epoch": 1.494945567651633,
      "grad_norm": 0.0019034920260310173,
      "learning_rate": 2.9895023328149302e-05,
      "loss": 0.0072,
      "step": 7690
    },
    {
      "epoch": 1.4968895800933126,
      "grad_norm": 0.0011143154697492719,
      "learning_rate": 2.9933903576982895e-05,
      "loss": 0.0001,
      "step": 7700
    },
    {
      "epoch": 1.4988335925349923,
      "grad_norm": 0.0012370697222650051,
      "learning_rate": 2.9972783825816485e-05,
      "loss": 0.0001,
      "step": 7710
    },
    {
      "epoch": 1.500777604976672,
      "grad_norm": 0.0009396409150213003,
      "learning_rate": 2.9998703991705547e-05,
      "loss": 0.0001,
      "step": 7720
    },
    {
      "epoch": 1.5027216174183515,
      "grad_norm": 0.02832518331706524,
      "learning_rate": 2.999438396405737e-05,
      "loss": 0.0365,
      "step": 7730
    },
    {
      "epoch": 1.504665629860031,
      "grad_norm": 0.0008577287080697715,
      "learning_rate": 2.9990063936409192e-05,
      "loss": 0.0001,
      "step": 7740
    },
    {
      "epoch": 1.5066096423017106,
      "grad_norm": 0.0014596437104046345,
      "learning_rate": 2.9985743908761016e-05,
      "loss": 0.0179,
      "step": 7750
    },
    {
      "epoch": 1.5085536547433902,
      "grad_norm": 39.386234283447266,
      "learning_rate": 2.998142388111284e-05,
      "loss": 0.0109,
      "step": 7760
    },
    {
      "epoch": 1.5104976671850698,
      "grad_norm": 0.005846462678164244,
      "learning_rate": 2.997710385346466e-05,
      "loss": 0.0009,
      "step": 7770
    },
    {
      "epoch": 1.5124416796267495,
      "grad_norm": 0.0018588819075375795,
      "learning_rate": 2.9972783825816485e-05,
      "loss": 0.0032,
      "step": 7780
    },
    {
      "epoch": 1.514385692068429,
      "grad_norm": 0.002239413093775511,
      "learning_rate": 2.996846379816831e-05,
      "loss": 0.0001,
      "step": 7790
    },
    {
      "epoch": 1.5163297045101087,
      "grad_norm": 0.0011638017604127526,
      "learning_rate": 2.996414377052013e-05,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 1.5182737169517884,
      "grad_norm": 18.63947868347168,
      "learning_rate": 2.9959823742871954e-05,
      "loss": 0.0052,
      "step": 7810
    },
    {
      "epoch": 1.520217729393468,
      "grad_norm": 0.014101382344961166,
      "learning_rate": 2.9955503715223778e-05,
      "loss": 0.0471,
      "step": 7820
    },
    {
      "epoch": 1.5221617418351476,
      "grad_norm": 0.02027866430580616,
      "learning_rate": 2.9951183687575602e-05,
      "loss": 0.001,
      "step": 7830
    },
    {
      "epoch": 1.5241057542768273,
      "grad_norm": 0.0047232117503881454,
      "learning_rate": 2.9946863659927426e-05,
      "loss": 0.0064,
      "step": 7840
    },
    {
      "epoch": 1.526049766718507,
      "grad_norm": 0.015294939279556274,
      "learning_rate": 2.9942543632279247e-05,
      "loss": 0.0129,
      "step": 7850
    },
    {
      "epoch": 1.5279937791601865,
      "grad_norm": 0.0008230223320424557,
      "learning_rate": 2.993822360463107e-05,
      "loss": 0.0243,
      "step": 7860
    },
    {
      "epoch": 1.5299377916018662,
      "grad_norm": 0.04764721915125847,
      "learning_rate": 2.9933903576982895e-05,
      "loss": 0.0567,
      "step": 7870
    },
    {
      "epoch": 1.5318818040435458,
      "grad_norm": 0.003404731396585703,
      "learning_rate": 2.9929583549334716e-05,
      "loss": 0.0227,
      "step": 7880
    },
    {
      "epoch": 1.5338258164852254,
      "grad_norm": 0.5539817810058594,
      "learning_rate": 2.992526352168654e-05,
      "loss": 0.017,
      "step": 7890
    },
    {
      "epoch": 1.535769828926905,
      "grad_norm": 0.0011623993050307035,
      "learning_rate": 2.9920943494038364e-05,
      "loss": 0.0215,
      "step": 7900
    },
    {
      "epoch": 1.5377138413685847,
      "grad_norm": 0.0013018115423619747,
      "learning_rate": 2.9916623466390185e-05,
      "loss": 0.0014,
      "step": 7910
    },
    {
      "epoch": 1.5396578538102643,
      "grad_norm": 0.0010532517917454243,
      "learning_rate": 2.991230343874201e-05,
      "loss": 0.0146,
      "step": 7920
    },
    {
      "epoch": 1.541601866251944,
      "grad_norm": 0.05340532958507538,
      "learning_rate": 2.9907983411093833e-05,
      "loss": 0.0017,
      "step": 7930
    },
    {
      "epoch": 1.5435458786936236,
      "grad_norm": 0.02178044430911541,
      "learning_rate": 2.9903663383445654e-05,
      "loss": 0.0066,
      "step": 7940
    },
    {
      "epoch": 1.5454898911353032,
      "grad_norm": 0.0014174956595525146,
      "learning_rate": 2.9899343355797478e-05,
      "loss": 0.0001,
      "step": 7950
    },
    {
      "epoch": 1.5474339035769828,
      "grad_norm": 0.033541712909936905,
      "learning_rate": 2.9895023328149302e-05,
      "loss": 0.0436,
      "step": 7960
    },
    {
      "epoch": 1.5493779160186625,
      "grad_norm": 12.018339157104492,
      "learning_rate": 2.9890703300501123e-05,
      "loss": 0.0376,
      "step": 7970
    },
    {
      "epoch": 1.5513219284603421,
      "grad_norm": 0.0017640406731516123,
      "learning_rate": 2.9886383272852947e-05,
      "loss": 0.0001,
      "step": 7980
    },
    {
      "epoch": 1.5532659409020217,
      "grad_norm": 0.002575480379164219,
      "learning_rate": 2.988206324520477e-05,
      "loss": 0.0291,
      "step": 7990
    },
    {
      "epoch": 1.5552099533437014,
      "grad_norm": 14.862662315368652,
      "learning_rate": 2.9877743217556592e-05,
      "loss": 0.0165,
      "step": 8000
    },
    {
      "epoch": 1.557153965785381,
      "grad_norm": 0.002863093977794051,
      "learning_rate": 2.9873423189908416e-05,
      "loss": 0.0005,
      "step": 8010
    },
    {
      "epoch": 1.5590979782270606,
      "grad_norm": 0.003024906851351261,
      "learning_rate": 2.986910316226024e-05,
      "loss": 0.0006,
      "step": 8020
    },
    {
      "epoch": 1.5610419906687403,
      "grad_norm": 0.0034223422408103943,
      "learning_rate": 2.986478313461206e-05,
      "loss": 0.0166,
      "step": 8030
    },
    {
      "epoch": 1.56298600311042,
      "grad_norm": 0.005583798047155142,
      "learning_rate": 2.986046310696389e-05,
      "loss": 0.0001,
      "step": 8040
    },
    {
      "epoch": 1.5649300155520995,
      "grad_norm": 0.0031083710491657257,
      "learning_rate": 2.985614307931571e-05,
      "loss": 0.0007,
      "step": 8050
    },
    {
      "epoch": 1.5668740279937792,
      "grad_norm": 0.0009118134621530771,
      "learning_rate": 2.985182305166753e-05,
      "loss": 0.0001,
      "step": 8060
    },
    {
      "epoch": 1.5688180404354588,
      "grad_norm": 0.0011637568240985274,
      "learning_rate": 2.9847503024019357e-05,
      "loss": 0.0001,
      "step": 8070
    },
    {
      "epoch": 1.5707620528771384,
      "grad_norm": 0.0010630462784320116,
      "learning_rate": 2.9843182996371178e-05,
      "loss": 0.0001,
      "step": 8080
    },
    {
      "epoch": 1.572706065318818,
      "grad_norm": 0.0008194936090148985,
      "learning_rate": 2.9838862968723e-05,
      "loss": 0.0038,
      "step": 8090
    },
    {
      "epoch": 1.5746500777604977,
      "grad_norm": 0.0018401540582999587,
      "learning_rate": 2.9834542941074826e-05,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 1.5765940902021773,
      "grad_norm": 0.0006624037050642073,
      "learning_rate": 2.9830222913426647e-05,
      "loss": 0.0001,
      "step": 8110
    },
    {
      "epoch": 1.578538102643857,
      "grad_norm": 0.0006979329045861959,
      "learning_rate": 2.9825902885778468e-05,
      "loss": 0.0,
      "step": 8120
    },
    {
      "epoch": 1.5804821150855366,
      "grad_norm": 0.000963904254604131,
      "learning_rate": 2.9821582858130295e-05,
      "loss": 0.0523,
      "step": 8130
    },
    {
      "epoch": 1.5824261275272162,
      "grad_norm": 0.006487914361059666,
      "learning_rate": 2.9817262830482116e-05,
      "loss": 0.0002,
      "step": 8140
    },
    {
      "epoch": 1.5843701399688959,
      "grad_norm": 0.021366305649280548,
      "learning_rate": 2.9812942802833937e-05,
      "loss": 0.0005,
      "step": 8150
    },
    {
      "epoch": 1.5863141524105755,
      "grad_norm": 12.161214828491211,
      "learning_rate": 2.9808622775185764e-05,
      "loss": 0.053,
      "step": 8160
    },
    {
      "epoch": 1.5882581648522551,
      "grad_norm": 5.526641845703125,
      "learning_rate": 2.9804302747537585e-05,
      "loss": 0.0196,
      "step": 8170
    },
    {
      "epoch": 1.5902021772939348,
      "grad_norm": 0.005953221116214991,
      "learning_rate": 2.9799982719889406e-05,
      "loss": 0.0151,
      "step": 8180
    },
    {
      "epoch": 1.5921461897356144,
      "grad_norm": 0.003091066377237439,
      "learning_rate": 2.9795662692241233e-05,
      "loss": 0.0005,
      "step": 8190
    },
    {
      "epoch": 1.594090202177294,
      "grad_norm": 0.0024297807831317186,
      "learning_rate": 2.9791342664593054e-05,
      "loss": 0.0233,
      "step": 8200
    },
    {
      "epoch": 1.5960342146189737,
      "grad_norm": 3.4239206314086914,
      "learning_rate": 2.9787022636944875e-05,
      "loss": 0.0104,
      "step": 8210
    },
    {
      "epoch": 1.5979782270606533,
      "grad_norm": 0.016275784000754356,
      "learning_rate": 2.9782702609296702e-05,
      "loss": 0.0045,
      "step": 8220
    },
    {
      "epoch": 1.599922239502333,
      "grad_norm": 0.10700423270463943,
      "learning_rate": 2.9778382581648523e-05,
      "loss": 0.0039,
      "step": 8230
    },
    {
      "epoch": 1.6018662519440126,
      "grad_norm": 0.0045142569579184055,
      "learning_rate": 2.9774062554000347e-05,
      "loss": 0.0004,
      "step": 8240
    },
    {
      "epoch": 1.6038102643856922,
      "grad_norm": 0.08794759958982468,
      "learning_rate": 2.976974252635217e-05,
      "loss": 0.0003,
      "step": 8250
    },
    {
      "epoch": 1.6057542768273718,
      "grad_norm": 0.0012953606201335788,
      "learning_rate": 2.976542249870399e-05,
      "loss": 0.0408,
      "step": 8260
    },
    {
      "epoch": 1.6076982892690515,
      "grad_norm": 0.001378749031573534,
      "learning_rate": 2.9761102471055816e-05,
      "loss": 0.0001,
      "step": 8270
    },
    {
      "epoch": 1.609642301710731,
      "grad_norm": 0.0014750781701877713,
      "learning_rate": 2.975678244340764e-05,
      "loss": 0.0001,
      "step": 8280
    },
    {
      "epoch": 1.6115863141524107,
      "grad_norm": 0.0012670742580667138,
      "learning_rate": 2.975246241575946e-05,
      "loss": 0.0072,
      "step": 8290
    },
    {
      "epoch": 1.6135303265940903,
      "grad_norm": 0.004819737281650305,
      "learning_rate": 2.9748142388111285e-05,
      "loss": 0.0001,
      "step": 8300
    },
    {
      "epoch": 1.61547433903577,
      "grad_norm": 0.001276182010769844,
      "learning_rate": 2.974382236046311e-05,
      "loss": 0.0001,
      "step": 8310
    },
    {
      "epoch": 1.6174183514774496,
      "grad_norm": 0.0014988972106948495,
      "learning_rate": 2.973950233281493e-05,
      "loss": 0.0005,
      "step": 8320
    },
    {
      "epoch": 1.6193623639191292,
      "grad_norm": 0.0010216424707323313,
      "learning_rate": 2.9735182305166754e-05,
      "loss": 0.0046,
      "step": 8330
    },
    {
      "epoch": 1.6213063763608087,
      "grad_norm": 0.0012611841084435582,
      "learning_rate": 2.9730862277518578e-05,
      "loss": 0.0001,
      "step": 8340
    },
    {
      "epoch": 1.6232503888024883,
      "grad_norm": 0.0010824856581166387,
      "learning_rate": 2.97265422498704e-05,
      "loss": 0.0001,
      "step": 8350
    },
    {
      "epoch": 1.625194401244168,
      "grad_norm": 0.0009621154167689383,
      "learning_rate": 2.9722222222222223e-05,
      "loss": 0.0018,
      "step": 8360
    },
    {
      "epoch": 1.6271384136858476,
      "grad_norm": 0.0019928470719605684,
      "learning_rate": 2.9717902194574047e-05,
      "loss": 0.0052,
      "step": 8370
    },
    {
      "epoch": 1.6290824261275272,
      "grad_norm": 18.437503814697266,
      "learning_rate": 2.9713582166925867e-05,
      "loss": 0.002,
      "step": 8380
    },
    {
      "epoch": 1.6310264385692068,
      "grad_norm": 0.0009276857017539442,
      "learning_rate": 2.970926213927769e-05,
      "loss": 0.0004,
      "step": 8390
    },
    {
      "epoch": 1.6329704510108864,
      "grad_norm": 0.0009183913934975863,
      "learning_rate": 2.9704942111629516e-05,
      "loss": 0.0216,
      "step": 8400
    },
    {
      "epoch": 1.634914463452566,
      "grad_norm": 0.0016282133292406797,
      "learning_rate": 2.9700622083981336e-05,
      "loss": 0.0001,
      "step": 8410
    },
    {
      "epoch": 1.6368584758942457,
      "grad_norm": 0.0019524176605045795,
      "learning_rate": 2.969630205633316e-05,
      "loss": 0.0001,
      "step": 8420
    },
    {
      "epoch": 1.6388024883359253,
      "grad_norm": 0.002019183011725545,
      "learning_rate": 2.9691982028684985e-05,
      "loss": 0.0001,
      "step": 8430
    },
    {
      "epoch": 1.640746500777605,
      "grad_norm": 0.00317769474349916,
      "learning_rate": 2.968766200103681e-05,
      "loss": 0.001,
      "step": 8440
    },
    {
      "epoch": 1.6426905132192846,
      "grad_norm": 0.001222296617925167,
      "learning_rate": 2.968334197338863e-05,
      "loss": 0.0076,
      "step": 8450
    },
    {
      "epoch": 1.6446345256609642,
      "grad_norm": 0.033434875309467316,
      "learning_rate": 2.9679021945740454e-05,
      "loss": 0.0001,
      "step": 8460
    },
    {
      "epoch": 1.6465785381026439,
      "grad_norm": 0.002151245018467307,
      "learning_rate": 2.9674701918092278e-05,
      "loss": 0.0041,
      "step": 8470
    },
    {
      "epoch": 1.6485225505443235,
      "grad_norm": 0.0008376147015951574,
      "learning_rate": 2.96703818904441e-05,
      "loss": 0.0001,
      "step": 8480
    },
    {
      "epoch": 1.6504665629860031,
      "grad_norm": 0.04512331634759903,
      "learning_rate": 2.9666061862795923e-05,
      "loss": 0.0001,
      "step": 8490
    },
    {
      "epoch": 1.6524105754276828,
      "grad_norm": 0.0008552329381927848,
      "learning_rate": 2.9661741835147747e-05,
      "loss": 0.0003,
      "step": 8500
    },
    {
      "epoch": 1.6543545878693624,
      "grad_norm": 0.0013863389613106847,
      "learning_rate": 2.9657421807499567e-05,
      "loss": 0.0001,
      "step": 8510
    },
    {
      "epoch": 1.656298600311042,
      "grad_norm": 0.0007919337367638946,
      "learning_rate": 2.965310177985139e-05,
      "loss": 0.0001,
      "step": 8520
    },
    {
      "epoch": 1.6582426127527217,
      "grad_norm": 0.0009343202691525221,
      "learning_rate": 2.9648781752203216e-05,
      "loss": 0.0001,
      "step": 8530
    },
    {
      "epoch": 1.660186625194401,
      "grad_norm": 0.000815332168713212,
      "learning_rate": 2.9644461724555036e-05,
      "loss": 0.0001,
      "step": 8540
    },
    {
      "epoch": 1.6621306376360807,
      "grad_norm": 0.0007604468846693635,
      "learning_rate": 2.964014169690686e-05,
      "loss": 0.0011,
      "step": 8550
    },
    {
      "epoch": 1.6640746500777603,
      "grad_norm": 0.11954148858785629,
      "learning_rate": 2.9635821669258685e-05,
      "loss": 0.0002,
      "step": 8560
    },
    {
      "epoch": 1.66601866251944,
      "grad_norm": 0.000810064550023526,
      "learning_rate": 2.9631501641610505e-05,
      "loss": 0.0002,
      "step": 8570
    },
    {
      "epoch": 1.6679626749611196,
      "grad_norm": 1.853833794593811,
      "learning_rate": 2.962718161396233e-05,
      "loss": 0.0054,
      "step": 8580
    },
    {
      "epoch": 1.6699066874027992,
      "grad_norm": 0.0008914170903153718,
      "learning_rate": 2.9622861586314153e-05,
      "loss": 0.0,
      "step": 8590
    },
    {
      "epoch": 1.6718506998444789,
      "grad_norm": 0.0010259868577122688,
      "learning_rate": 2.9618541558665974e-05,
      "loss": 0.0001,
      "step": 8600
    },
    {
      "epoch": 1.6737947122861585,
      "grad_norm": 0.015319205820560455,
      "learning_rate": 2.9614221531017798e-05,
      "loss": 0.0001,
      "step": 8610
    },
    {
      "epoch": 1.6757387247278381,
      "grad_norm": 0.0007141063106246293,
      "learning_rate": 2.9609901503369622e-05,
      "loss": 0.0005,
      "step": 8620
    },
    {
      "epoch": 1.6776827371695178,
      "grad_norm": 0.0009568295790813863,
      "learning_rate": 2.9605581475721443e-05,
      "loss": 0.0,
      "step": 8630
    },
    {
      "epoch": 1.6796267496111974,
      "grad_norm": 0.0007769477088004351,
      "learning_rate": 2.960126144807327e-05,
      "loss": 0.0,
      "step": 8640
    },
    {
      "epoch": 1.681570762052877,
      "grad_norm": 0.0007324957405216992,
      "learning_rate": 2.959694142042509e-05,
      "loss": 0.0,
      "step": 8650
    },
    {
      "epoch": 1.6835147744945567,
      "grad_norm": 0.0006796508096158504,
      "learning_rate": 2.9592621392776912e-05,
      "loss": 0.0,
      "step": 8660
    },
    {
      "epoch": 1.6854587869362363,
      "grad_norm": 0.0007386516081169248,
      "learning_rate": 2.958830136512874e-05,
      "loss": 0.0243,
      "step": 8670
    },
    {
      "epoch": 1.687402799377916,
      "grad_norm": 0.0010550159495323896,
      "learning_rate": 2.958398133748056e-05,
      "loss": 0.0095,
      "step": 8680
    },
    {
      "epoch": 1.6893468118195956,
      "grad_norm": 0.010789713822305202,
      "learning_rate": 2.957966130983238e-05,
      "loss": 0.0013,
      "step": 8690
    },
    {
      "epoch": 1.6912908242612752,
      "grad_norm": 0.38929617404937744,
      "learning_rate": 2.957534128218421e-05,
      "loss": 0.0749,
      "step": 8700
    },
    {
      "epoch": 1.6932348367029548,
      "grad_norm": 0.0019032976124435663,
      "learning_rate": 2.957102125453603e-05,
      "loss": 0.0013,
      "step": 8710
    },
    {
      "epoch": 1.6951788491446345,
      "grad_norm": 0.0018249494023621082,
      "learning_rate": 2.9566701226887853e-05,
      "loss": 0.043,
      "step": 8720
    },
    {
      "epoch": 1.697122861586314,
      "grad_norm": 0.00955251231789589,
      "learning_rate": 2.9562381199239677e-05,
      "loss": 0.0029,
      "step": 8730
    },
    {
      "epoch": 1.6990668740279937,
      "grad_norm": 0.008265997283160686,
      "learning_rate": 2.9558061171591498e-05,
      "loss": 0.0021,
      "step": 8740
    },
    {
      "epoch": 1.7010108864696734,
      "grad_norm": 1.0608373880386353,
      "learning_rate": 2.9553741143943322e-05,
      "loss": 0.0002,
      "step": 8750
    },
    {
      "epoch": 1.702954898911353,
      "grad_norm": 0.0021560057066380978,
      "learning_rate": 2.9549421116295146e-05,
      "loss": 0.0001,
      "step": 8760
    },
    {
      "epoch": 1.7048989113530326,
      "grad_norm": 0.0032317806035280228,
      "learning_rate": 2.9545101088646967e-05,
      "loss": 0.0001,
      "step": 8770
    },
    {
      "epoch": 1.7068429237947123,
      "grad_norm": 0.0011988487094640732,
      "learning_rate": 2.954078106099879e-05,
      "loss": 0.062,
      "step": 8780
    },
    {
      "epoch": 1.7087869362363919,
      "grad_norm": 0.0006385993910953403,
      "learning_rate": 2.9536461033350615e-05,
      "loss": 0.0001,
      "step": 8790
    },
    {
      "epoch": 1.7107309486780715,
      "grad_norm": 0.0007667450117878616,
      "learning_rate": 2.9532141005702436e-05,
      "loss": 0.0108,
      "step": 8800
    },
    {
      "epoch": 1.7126749611197511,
      "grad_norm": 0.0012029932113364339,
      "learning_rate": 2.952782097805426e-05,
      "loss": 0.0001,
      "step": 8810
    },
    {
      "epoch": 1.7146189735614308,
      "grad_norm": 0.0007023398648016155,
      "learning_rate": 2.9523500950406084e-05,
      "loss": 0.0001,
      "step": 8820
    },
    {
      "epoch": 1.7165629860031104,
      "grad_norm": 5.452078819274902,
      "learning_rate": 2.9519180922757905e-05,
      "loss": 0.0271,
      "step": 8830
    },
    {
      "epoch": 1.71850699844479,
      "grad_norm": 0.008384241722524166,
      "learning_rate": 2.9514860895109733e-05,
      "loss": 0.0004,
      "step": 8840
    },
    {
      "epoch": 1.7204510108864697,
      "grad_norm": 0.0013940625358372927,
      "learning_rate": 2.9510540867461553e-05,
      "loss": 0.0098,
      "step": 8850
    },
    {
      "epoch": 1.7223950233281493,
      "grad_norm": 0.0009378822287544608,
      "learning_rate": 2.9506220839813374e-05,
      "loss": 0.0001,
      "step": 8860
    },
    {
      "epoch": 1.724339035769829,
      "grad_norm": 0.0007642863201908767,
      "learning_rate": 2.95019008121652e-05,
      "loss": 0.002,
      "step": 8870
    },
    {
      "epoch": 1.7262830482115086,
      "grad_norm": 0.08251123875379562,
      "learning_rate": 2.9497580784517022e-05,
      "loss": 0.0001,
      "step": 8880
    },
    {
      "epoch": 1.7282270606531882,
      "grad_norm": 0.005127447657287121,
      "learning_rate": 2.9493260756868843e-05,
      "loss": 0.018,
      "step": 8890
    },
    {
      "epoch": 1.7301710730948678,
      "grad_norm": 0.0009721557144075632,
      "learning_rate": 2.948894072922067e-05,
      "loss": 0.008,
      "step": 8900
    },
    {
      "epoch": 1.7321150855365475,
      "grad_norm": 0.0010346906492486596,
      "learning_rate": 2.948462070157249e-05,
      "loss": 0.0012,
      "step": 8910
    },
    {
      "epoch": 1.734059097978227,
      "grad_norm": 0.0018847088795155287,
      "learning_rate": 2.9480300673924312e-05,
      "loss": 0.0086,
      "step": 8920
    },
    {
      "epoch": 1.7360031104199067,
      "grad_norm": 0.057046372443437576,
      "learning_rate": 2.947598064627614e-05,
      "loss": 0.0057,
      "step": 8930
    },
    {
      "epoch": 1.7379471228615864,
      "grad_norm": 0.04322431981563568,
      "learning_rate": 2.947166061862796e-05,
      "loss": 0.0001,
      "step": 8940
    },
    {
      "epoch": 1.739891135303266,
      "grad_norm": 0.0019863536581397057,
      "learning_rate": 2.946734059097978e-05,
      "loss": 0.0002,
      "step": 8950
    },
    {
      "epoch": 1.7418351477449456,
      "grad_norm": 0.017093578353524208,
      "learning_rate": 2.9463020563331608e-05,
      "loss": 0.0977,
      "step": 8960
    },
    {
      "epoch": 1.7437791601866253,
      "grad_norm": 0.02727513015270233,
      "learning_rate": 2.945870053568343e-05,
      "loss": 0.0012,
      "step": 8970
    },
    {
      "epoch": 1.745723172628305,
      "grad_norm": 0.006449267268180847,
      "learning_rate": 2.945438050803525e-05,
      "loss": 0.0201,
      "step": 8980
    },
    {
      "epoch": 1.7476671850699845,
      "grad_norm": 0.08538231998682022,
      "learning_rate": 2.9450060480387077e-05,
      "loss": 0.0002,
      "step": 8990
    },
    {
      "epoch": 1.7496111975116642,
      "grad_norm": 0.005225903354585171,
      "learning_rate": 2.9445740452738898e-05,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 1.7515552099533438,
      "grad_norm": 0.0018054167740046978,
      "learning_rate": 2.9441420425090722e-05,
      "loss": 0.0021,
      "step": 9010
    },
    {
      "epoch": 1.7534992223950234,
      "grad_norm": 0.0014182109152898192,
      "learning_rate": 2.9437100397442546e-05,
      "loss": 0.0099,
      "step": 9020
    },
    {
      "epoch": 1.755443234836703,
      "grad_norm": 0.001105387695133686,
      "learning_rate": 2.9432780369794367e-05,
      "loss": 0.0001,
      "step": 9030
    },
    {
      "epoch": 1.7573872472783827,
      "grad_norm": 0.0011511192424222827,
      "learning_rate": 2.942846034214619e-05,
      "loss": 0.0001,
      "step": 9040
    },
    {
      "epoch": 1.7593312597200623,
      "grad_norm": 0.0014078491367399693,
      "learning_rate": 2.9424140314498015e-05,
      "loss": 0.0055,
      "step": 9050
    },
    {
      "epoch": 1.761275272161742,
      "grad_norm": 0.0012667011469602585,
      "learning_rate": 2.9419820286849836e-05,
      "loss": 0.0279,
      "step": 9060
    },
    {
      "epoch": 1.7632192846034216,
      "grad_norm": 0.11959037184715271,
      "learning_rate": 2.941550025920166e-05,
      "loss": 0.0235,
      "step": 9070
    },
    {
      "epoch": 1.7651632970451012,
      "grad_norm": 0.010547627694904804,
      "learning_rate": 2.9411180231553484e-05,
      "loss": 0.0249,
      "step": 9080
    },
    {
      "epoch": 1.7671073094867809,
      "grad_norm": 0.026492953300476074,
      "learning_rate": 2.9406860203905305e-05,
      "loss": 0.021,
      "step": 9090
    },
    {
      "epoch": 1.7690513219284605,
      "grad_norm": 0.0015884112799540162,
      "learning_rate": 2.940254017625713e-05,
      "loss": 0.0009,
      "step": 9100
    },
    {
      "epoch": 1.7709953343701401,
      "grad_norm": 0.004498918540775776,
      "learning_rate": 2.9398220148608953e-05,
      "loss": 0.0002,
      "step": 9110
    },
    {
      "epoch": 1.7729393468118197,
      "grad_norm": 0.004561418667435646,
      "learning_rate": 2.9393900120960774e-05,
      "loss": 0.0011,
      "step": 9120
    },
    {
      "epoch": 1.7748833592534994,
      "grad_norm": 0.004665757529437542,
      "learning_rate": 2.9389580093312598e-05,
      "loss": 0.0232,
      "step": 9130
    },
    {
      "epoch": 1.776827371695179,
      "grad_norm": 0.017896778881549835,
      "learning_rate": 2.9385260065664422e-05,
      "loss": 0.0305,
      "step": 9140
    },
    {
      "epoch": 1.7787713841368584,
      "grad_norm": 0.015585907734930515,
      "learning_rate": 2.9380940038016243e-05,
      "loss": 0.001,
      "step": 9150
    },
    {
      "epoch": 1.780715396578538,
      "grad_norm": 0.3444080948829651,
      "learning_rate": 2.9376620010368067e-05,
      "loss": 0.0192,
      "step": 9160
    },
    {
      "epoch": 1.7826594090202177,
      "grad_norm": 0.0011046600993722677,
      "learning_rate": 2.937229998271989e-05,
      "loss": 0.0002,
      "step": 9170
    },
    {
      "epoch": 1.7846034214618973,
      "grad_norm": 0.004030613694339991,
      "learning_rate": 2.936797995507171e-05,
      "loss": 0.0002,
      "step": 9180
    },
    {
      "epoch": 1.786547433903577,
      "grad_norm": 0.0023480774834752083,
      "learning_rate": 2.9363659927423536e-05,
      "loss": 0.0002,
      "step": 9190
    },
    {
      "epoch": 1.7884914463452566,
      "grad_norm": 0.0020668182987719774,
      "learning_rate": 2.935933989977536e-05,
      "loss": 0.0012,
      "step": 9200
    },
    {
      "epoch": 1.7904354587869362,
      "grad_norm": 0.0012558558955788612,
      "learning_rate": 2.9355019872127184e-05,
      "loss": 0.0001,
      "step": 9210
    },
    {
      "epoch": 1.7923794712286159,
      "grad_norm": 0.002561421599239111,
      "learning_rate": 2.9350699844479005e-05,
      "loss": 0.0458,
      "step": 9220
    },
    {
      "epoch": 1.7943234836702955,
      "grad_norm": 0.0017777640605345368,
      "learning_rate": 2.934637981683083e-05,
      "loss": 0.0006,
      "step": 9230
    },
    {
      "epoch": 1.7962674961119751,
      "grad_norm": 0.008459155447781086,
      "learning_rate": 2.9342059789182653e-05,
      "loss": 0.0004,
      "step": 9240
    },
    {
      "epoch": 1.7982115085536547,
      "grad_norm": 0.0011274004355072975,
      "learning_rate": 2.9337739761534474e-05,
      "loss": 0.0294,
      "step": 9250
    },
    {
      "epoch": 1.8001555209953344,
      "grad_norm": 9.316125869750977,
      "learning_rate": 2.9333419733886298e-05,
      "loss": 0.031,
      "step": 9260
    },
    {
      "epoch": 1.802099533437014,
      "grad_norm": 0.002701893448829651,
      "learning_rate": 2.9329099706238122e-05,
      "loss": 0.0002,
      "step": 9270
    },
    {
      "epoch": 1.8040435458786936,
      "grad_norm": 0.0012659328058362007,
      "learning_rate": 2.9324779678589943e-05,
      "loss": 0.0112,
      "step": 9280
    },
    {
      "epoch": 1.8059875583203733,
      "grad_norm": 0.014100397936999798,
      "learning_rate": 2.9320459650941767e-05,
      "loss": 0.0097,
      "step": 9290
    },
    {
      "epoch": 1.807931570762053,
      "grad_norm": 0.001807330991141498,
      "learning_rate": 2.931613962329359e-05,
      "loss": 0.0347,
      "step": 9300
    },
    {
      "epoch": 1.8098755832037325,
      "grad_norm": 0.0011474951170384884,
      "learning_rate": 2.931181959564541e-05,
      "loss": 0.0057,
      "step": 9310
    },
    {
      "epoch": 1.8118195956454122,
      "grad_norm": 0.0027475720271468163,
      "learning_rate": 2.9307499567997236e-05,
      "loss": 0.0356,
      "step": 9320
    },
    {
      "epoch": 1.8137636080870918,
      "grad_norm": 0.004179087933152914,
      "learning_rate": 2.930317954034906e-05,
      "loss": 0.0132,
      "step": 9330
    },
    {
      "epoch": 1.8157076205287714,
      "grad_norm": 0.00751449353992939,
      "learning_rate": 2.929885951270088e-05,
      "loss": 0.0004,
      "step": 9340
    },
    {
      "epoch": 1.8176516329704508,
      "grad_norm": 0.0034483016934245825,
      "learning_rate": 2.9294539485052705e-05,
      "loss": 0.0169,
      "step": 9350
    },
    {
      "epoch": 1.8195956454121305,
      "grad_norm": 0.0010324217146262527,
      "learning_rate": 2.929021945740453e-05,
      "loss": 0.0004,
      "step": 9360
    },
    {
      "epoch": 1.8215396578538101,
      "grad_norm": 0.004607780836522579,
      "learning_rate": 2.928589942975635e-05,
      "loss": 0.0002,
      "step": 9370
    },
    {
      "epoch": 1.8234836702954897,
      "grad_norm": 0.0023008231073617935,
      "learning_rate": 2.9281579402108173e-05,
      "loss": 0.0149,
      "step": 9380
    },
    {
      "epoch": 1.8254276827371694,
      "grad_norm": 0.0034928321838378906,
      "learning_rate": 2.9277259374459998e-05,
      "loss": 0.0001,
      "step": 9390
    },
    {
      "epoch": 1.827371695178849,
      "grad_norm": 0.0013758756686002016,
      "learning_rate": 2.927293934681182e-05,
      "loss": 0.0227,
      "step": 9400
    },
    {
      "epoch": 1.8293157076205286,
      "grad_norm": 0.005391205195337534,
      "learning_rate": 2.9268619319163646e-05,
      "loss": 0.0005,
      "step": 9410
    },
    {
      "epoch": 1.8312597200622083,
      "grad_norm": 60.29899215698242,
      "learning_rate": 2.9264299291515467e-05,
      "loss": 0.0264,
      "step": 9420
    },
    {
      "epoch": 1.833203732503888,
      "grad_norm": 0.004094623029232025,
      "learning_rate": 2.9259979263867287e-05,
      "loss": 0.0013,
      "step": 9430
    },
    {
      "epoch": 1.8351477449455675,
      "grad_norm": 0.0015653996961191297,
      "learning_rate": 2.9255659236219115e-05,
      "loss": 0.0002,
      "step": 9440
    },
    {
      "epoch": 1.8370917573872472,
      "grad_norm": 0.07465380430221558,
      "learning_rate": 2.9251339208570935e-05,
      "loss": 0.0167,
      "step": 9450
    },
    {
      "epoch": 1.8390357698289268,
      "grad_norm": 0.0042722029611468315,
      "learning_rate": 2.9247019180922756e-05,
      "loss": 0.0008,
      "step": 9460
    },
    {
      "epoch": 1.8409797822706064,
      "grad_norm": 0.0020237143617123365,
      "learning_rate": 2.9242699153274584e-05,
      "loss": 0.0113,
      "step": 9470
    },
    {
      "epoch": 1.842923794712286,
      "grad_norm": 0.003949253354221582,
      "learning_rate": 2.9238379125626404e-05,
      "loss": 0.0001,
      "step": 9480
    },
    {
      "epoch": 1.8448678071539657,
      "grad_norm": 0.16337087750434875,
      "learning_rate": 2.9234059097978225e-05,
      "loss": 0.0004,
      "step": 9490
    },
    {
      "epoch": 1.8468118195956453,
      "grad_norm": 0.002179824747145176,
      "learning_rate": 2.9229739070330053e-05,
      "loss": 0.0208,
      "step": 9500
    },
    {
      "epoch": 1.848755832037325,
      "grad_norm": 0.0019118426134809852,
      "learning_rate": 2.9225419042681873e-05,
      "loss": 0.0021,
      "step": 9510
    },
    {
      "epoch": 1.8506998444790046,
      "grad_norm": 0.002191743114963174,
      "learning_rate": 2.9221099015033694e-05,
      "loss": 0.0001,
      "step": 9520
    },
    {
      "epoch": 1.8526438569206842,
      "grad_norm": 0.14335791766643524,
      "learning_rate": 2.921677898738552e-05,
      "loss": 0.0006,
      "step": 9530
    },
    {
      "epoch": 1.8545878693623639,
      "grad_norm": 0.038193948566913605,
      "learning_rate": 2.9212458959737342e-05,
      "loss": 0.0011,
      "step": 9540
    },
    {
      "epoch": 1.8565318818040435,
      "grad_norm": 0.0016961570363491774,
      "learning_rate": 2.9208138932089163e-05,
      "loss": 0.0001,
      "step": 9550
    },
    {
      "epoch": 1.8584758942457231,
      "grad_norm": 0.0015863452572375536,
      "learning_rate": 2.920381890444099e-05,
      "loss": 0.023,
      "step": 9560
    },
    {
      "epoch": 1.8604199066874028,
      "grad_norm": 0.0016048147808760405,
      "learning_rate": 2.919949887679281e-05,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 1.8623639191290824,
      "grad_norm": 30.743812561035156,
      "learning_rate": 2.9195178849144632e-05,
      "loss": 0.0645,
      "step": 9580
    },
    {
      "epoch": 1.864307931570762,
      "grad_norm": 0.40131503343582153,
      "learning_rate": 2.919085882149646e-05,
      "loss": 0.0001,
      "step": 9590
    },
    {
      "epoch": 1.8662519440124417,
      "grad_norm": 0.002041745465248823,
      "learning_rate": 2.918653879384828e-05,
      "loss": 0.0002,
      "step": 9600
    },
    {
      "epoch": 1.8681959564541213,
      "grad_norm": 0.0011783080408349633,
      "learning_rate": 2.9182218766200104e-05,
      "loss": 0.0031,
      "step": 9610
    },
    {
      "epoch": 1.870139968895801,
      "grad_norm": 0.0011245479108765721,
      "learning_rate": 2.917789873855193e-05,
      "loss": 0.0078,
      "step": 9620
    },
    {
      "epoch": 1.8720839813374806,
      "grad_norm": 0.0010872469283640385,
      "learning_rate": 2.917357871090375e-05,
      "loss": 0.0001,
      "step": 9630
    },
    {
      "epoch": 1.8740279937791602,
      "grad_norm": 0.0010124072432518005,
      "learning_rate": 2.9169258683255577e-05,
      "loss": 0.0041,
      "step": 9640
    },
    {
      "epoch": 1.8759720062208398,
      "grad_norm": 0.0008407836430706084,
      "learning_rate": 2.9164938655607397e-05,
      "loss": 0.0001,
      "step": 9650
    },
    {
      "epoch": 1.8779160186625194,
      "grad_norm": 0.0014802338555455208,
      "learning_rate": 2.9160618627959218e-05,
      "loss": 0.0001,
      "step": 9660
    },
    {
      "epoch": 1.879860031104199,
      "grad_norm": 0.0031985114328563213,
      "learning_rate": 2.9156298600311046e-05,
      "loss": 0.0287,
      "step": 9670
    },
    {
      "epoch": 1.8818040435458787,
      "grad_norm": 0.0009847907349467278,
      "learning_rate": 2.9151978572662866e-05,
      "loss": 0.0001,
      "step": 9680
    },
    {
      "epoch": 1.8837480559875583,
      "grad_norm": 0.0008134408853948116,
      "learning_rate": 2.9147658545014687e-05,
      "loss": 0.0273,
      "step": 9690
    },
    {
      "epoch": 1.885692068429238,
      "grad_norm": 0.0009266349370591342,
      "learning_rate": 2.9143338517366515e-05,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 1.8876360808709176,
      "grad_norm": 0.0008846553973853588,
      "learning_rate": 2.9139018489718335e-05,
      "loss": 0.0001,
      "step": 9710
    },
    {
      "epoch": 1.8895800933125972,
      "grad_norm": 0.0008563350420445204,
      "learning_rate": 2.9134698462070156e-05,
      "loss": 0.0001,
      "step": 9720
    },
    {
      "epoch": 1.8915241057542769,
      "grad_norm": 0.001001677825115621,
      "learning_rate": 2.9130378434421983e-05,
      "loss": 0.0005,
      "step": 9730
    },
    {
      "epoch": 1.8934681181959565,
      "grad_norm": 0.000973232090473175,
      "learning_rate": 2.9126058406773804e-05,
      "loss": 0.0001,
      "step": 9740
    },
    {
      "epoch": 1.8954121306376361,
      "grad_norm": 0.0007399447495117784,
      "learning_rate": 2.9121738379125625e-05,
      "loss": 0.0034,
      "step": 9750
    },
    {
      "epoch": 1.8973561430793158,
      "grad_norm": 0.0006530173122882843,
      "learning_rate": 2.9117418351477452e-05,
      "loss": 0.0,
      "step": 9760
    },
    {
      "epoch": 1.8993001555209954,
      "grad_norm": 0.0008109783520922065,
      "learning_rate": 2.9113098323829273e-05,
      "loss": 0.0001,
      "step": 9770
    },
    {
      "epoch": 1.901244167962675,
      "grad_norm": 0.0007864992367103696,
      "learning_rate": 2.9108778296181094e-05,
      "loss": 0.0069,
      "step": 9780
    },
    {
      "epoch": 1.9031881804043547,
      "grad_norm": 0.0008182444144040346,
      "learning_rate": 2.910445826853292e-05,
      "loss": 0.0,
      "step": 9790
    },
    {
      "epoch": 1.9051321928460343,
      "grad_norm": 0.00325506622903049,
      "learning_rate": 2.9100138240884742e-05,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 1.907076205287714,
      "grad_norm": 0.001413267687894404,
      "learning_rate": 2.9095818213236566e-05,
      "loss": 0.0001,
      "step": 9810
    },
    {
      "epoch": 1.9090202177293936,
      "grad_norm": 0.000703334400895983,
      "learning_rate": 2.909149818558839e-05,
      "loss": 0.0127,
      "step": 9820
    },
    {
      "epoch": 1.9109642301710732,
      "grad_norm": 0.0007555088377557695,
      "learning_rate": 2.908717815794021e-05,
      "loss": 0.0,
      "step": 9830
    },
    {
      "epoch": 1.9129082426127528,
      "grad_norm": 0.0007238670950755477,
      "learning_rate": 2.9082858130292035e-05,
      "loss": 0.0178,
      "step": 9840
    },
    {
      "epoch": 1.9148522550544325,
      "grad_norm": 0.00344663648866117,
      "learning_rate": 2.907853810264386e-05,
      "loss": 0.0489,
      "step": 9850
    },
    {
      "epoch": 1.916796267496112,
      "grad_norm": 0.02067992463707924,
      "learning_rate": 2.907421807499568e-05,
      "loss": 0.0004,
      "step": 9860
    },
    {
      "epoch": 1.9187402799377917,
      "grad_norm": 0.008659472689032555,
      "learning_rate": 2.9069898047347504e-05,
      "loss": 0.0003,
      "step": 9870
    },
    {
      "epoch": 1.9206842923794714,
      "grad_norm": 0.0027919297572225332,
      "learning_rate": 2.9065578019699328e-05,
      "loss": 0.0003,
      "step": 9880
    },
    {
      "epoch": 1.922628304821151,
      "grad_norm": 0.003823851002380252,
      "learning_rate": 2.906125799205115e-05,
      "loss": 0.0001,
      "step": 9890
    },
    {
      "epoch": 1.9245723172628306,
      "grad_norm": 0.0018029549391940236,
      "learning_rate": 2.9056937964402973e-05,
      "loss": 0.0001,
      "step": 9900
    },
    {
      "epoch": 1.9265163297045103,
      "grad_norm": 0.0015624656807631254,
      "learning_rate": 2.9052617936754797e-05,
      "loss": 0.0001,
      "step": 9910
    },
    {
      "epoch": 1.9284603421461899,
      "grad_norm": 0.00189402571413666,
      "learning_rate": 2.9048297909106618e-05,
      "loss": 0.0001,
      "step": 9920
    },
    {
      "epoch": 1.9304043545878695,
      "grad_norm": 0.0020381466019898653,
      "learning_rate": 2.9043977881458442e-05,
      "loss": 0.0489,
      "step": 9930
    },
    {
      "epoch": 1.9323483670295492,
      "grad_norm": 0.001074441010132432,
      "learning_rate": 2.9039657853810266e-05,
      "loss": 0.0063,
      "step": 9940
    },
    {
      "epoch": 1.9342923794712286,
      "grad_norm": 0.0015584997599944472,
      "learning_rate": 2.9035337826162087e-05,
      "loss": 0.0002,
      "step": 9950
    },
    {
      "epoch": 1.9362363919129082,
      "grad_norm": 0.0011905813589692116,
      "learning_rate": 2.903101779851391e-05,
      "loss": 0.0065,
      "step": 9960
    },
    {
      "epoch": 1.9381804043545878,
      "grad_norm": 0.0027491350192576647,
      "learning_rate": 2.9026697770865735e-05,
      "loss": 0.0004,
      "step": 9970
    },
    {
      "epoch": 1.9401244167962675,
      "grad_norm": 0.0009474525577388704,
      "learning_rate": 2.9022377743217556e-05,
      "loss": 0.0107,
      "step": 9980
    },
    {
      "epoch": 1.942068429237947,
      "grad_norm": 9.448418617248535,
      "learning_rate": 2.901805771556938e-05,
      "loss": 0.0005,
      "step": 9990
    },
    {
      "epoch": 1.9440124416796267,
      "grad_norm": 0.00385778839699924,
      "learning_rate": 2.9013737687921204e-05,
      "loss": 0.0001,
      "step": 10000
    },
    {
      "epoch": 1.9459564541213064,
      "grad_norm": 0.00457182340323925,
      "learning_rate": 2.9009417660273028e-05,
      "loss": 0.0001,
      "step": 10010
    },
    {
      "epoch": 1.947900466562986,
      "grad_norm": 0.0008598967688158154,
      "learning_rate": 2.900509763262485e-05,
      "loss": 0.0026,
      "step": 10020
    },
    {
      "epoch": 1.9498444790046656,
      "grad_norm": 0.0007912370492704213,
      "learning_rate": 2.9000777604976673e-05,
      "loss": 0.0001,
      "step": 10030
    },
    {
      "epoch": 1.9517884914463453,
      "grad_norm": 0.0010511723812669516,
      "learning_rate": 2.8996457577328497e-05,
      "loss": 0.0001,
      "step": 10040
    },
    {
      "epoch": 1.9537325038880249,
      "grad_norm": 0.0010485542006790638,
      "learning_rate": 2.8992137549680318e-05,
      "loss": 0.0166,
      "step": 10050
    },
    {
      "epoch": 1.9556765163297045,
      "grad_norm": 0.0010819574818015099,
      "learning_rate": 2.8987817522032142e-05,
      "loss": 0.0008,
      "step": 10060
    },
    {
      "epoch": 1.9576205287713841,
      "grad_norm": 0.0014190779766067863,
      "learning_rate": 2.8983497494383966e-05,
      "loss": 0.0001,
      "step": 10070
    },
    {
      "epoch": 1.9595645412130638,
      "grad_norm": 0.004504847340285778,
      "learning_rate": 2.8979177466735787e-05,
      "loss": 0.015,
      "step": 10080
    },
    {
      "epoch": 1.9615085536547434,
      "grad_norm": 0.0017892661271616817,
      "learning_rate": 2.897485743908761e-05,
      "loss": 0.0114,
      "step": 10090
    },
    {
      "epoch": 1.963452566096423,
      "grad_norm": 0.01884867064654827,
      "learning_rate": 2.8970537411439435e-05,
      "loss": 0.0001,
      "step": 10100
    },
    {
      "epoch": 1.9653965785381027,
      "grad_norm": 0.0015688375569880009,
      "learning_rate": 2.8966217383791256e-05,
      "loss": 0.0001,
      "step": 10110
    },
    {
      "epoch": 1.9673405909797823,
      "grad_norm": 0.0017500203102827072,
      "learning_rate": 2.896189735614308e-05,
      "loss": 0.0001,
      "step": 10120
    },
    {
      "epoch": 1.969284603421462,
      "grad_norm": 0.0013638451928272843,
      "learning_rate": 2.8957577328494904e-05,
      "loss": 0.0001,
      "step": 10130
    },
    {
      "epoch": 1.9712286158631416,
      "grad_norm": 18.148807525634766,
      "learning_rate": 2.8953257300846725e-05,
      "loss": 0.0132,
      "step": 10140
    },
    {
      "epoch": 1.973172628304821,
      "grad_norm": 0.0018634599400684237,
      "learning_rate": 2.894893727319855e-05,
      "loss": 0.0022,
      "step": 10150
    },
    {
      "epoch": 1.9751166407465006,
      "grad_norm": 0.00335034285672009,
      "learning_rate": 2.8944617245550373e-05,
      "loss": 0.0165,
      "step": 10160
    },
    {
      "epoch": 1.9770606531881803,
      "grad_norm": 0.0008591998484916985,
      "learning_rate": 2.8940297217902194e-05,
      "loss": 0.045,
      "step": 10170
    },
    {
      "epoch": 1.9790046656298599,
      "grad_norm": 0.014128143899142742,
      "learning_rate": 2.893597719025402e-05,
      "loss": 0.0008,
      "step": 10180
    },
    {
      "epoch": 1.9809486780715395,
      "grad_norm": 0.0009161924244835973,
      "learning_rate": 2.8931657162605842e-05,
      "loss": 0.0001,
      "step": 10190
    },
    {
      "epoch": 1.9828926905132191,
      "grad_norm": 0.0006884635076858103,
      "learning_rate": 2.8927337134957662e-05,
      "loss": 0.0109,
      "step": 10200
    },
    {
      "epoch": 1.9848367029548988,
      "grad_norm": 0.0008211422245949507,
      "learning_rate": 2.892301710730949e-05,
      "loss": 0.0013,
      "step": 10210
    },
    {
      "epoch": 1.9867807153965784,
      "grad_norm": 0.00641527958214283,
      "learning_rate": 2.891869707966131e-05,
      "loss": 0.0137,
      "step": 10220
    },
    {
      "epoch": 1.988724727838258,
      "grad_norm": 0.0013970269355922937,
      "learning_rate": 2.891437705201313e-05,
      "loss": 0.0001,
      "step": 10230
    },
    {
      "epoch": 1.9906687402799377,
      "grad_norm": 0.0007719391142018139,
      "learning_rate": 2.891005702436496e-05,
      "loss": 0.0358,
      "step": 10240
    },
    {
      "epoch": 1.9926127527216173,
      "grad_norm": 0.0034928815439343452,
      "learning_rate": 2.890573699671678e-05,
      "loss": 0.0261,
      "step": 10250
    },
    {
      "epoch": 1.994556765163297,
      "grad_norm": 0.005576343275606632,
      "learning_rate": 2.89014169690686e-05,
      "loss": 0.0003,
      "step": 10260
    },
    {
      "epoch": 1.9965007776049766,
      "grad_norm": 0.02489927038550377,
      "learning_rate": 2.8897096941420428e-05,
      "loss": 0.0019,
      "step": 10270
    },
    {
      "epoch": 1.9984447900466562,
      "grad_norm": 0.004134013783186674,
      "learning_rate": 2.889277691377225e-05,
      "loss": 0.0103,
      "step": 10280
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.9933962264150943,
      "eval_loss": 0.013734651729464531,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.9933962264150943,
          "precision": 0.992563887725178,
          "recall": 0.9942299622324801,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.9933962264150943,
          "precision": 0.992563887725178,
          "recall": 0.9942299622324801,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.9933962264150943,
          "precision": 0.992563887725178,
          "recall": 0.9942299622324801,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9933962264150943,
          "precision": 0.9925638877251781,
          "recall": 0.9942299622324801,
          "support": 9532
        }
      },
      "eval_runtime": 71.6282,
      "eval_samples_per_second": 107.039,
      "eval_steps_per_second": 13.389,
      "step": 10288
    },
    {
      "epoch": 2.000388802488336,
      "grad_norm": 0.007469539530575275,
      "learning_rate": 2.888845688612407e-05,
      "loss": 0.001,
      "step": 10290
    },
    {
      "epoch": 2.0023328149300155,
      "grad_norm": 0.004410746973007917,
      "learning_rate": 2.8884136858475897e-05,
      "loss": 0.0004,
      "step": 10300
    },
    {
      "epoch": 2.004276827371695,
      "grad_norm": 0.004213223233819008,
      "learning_rate": 2.8879816830827718e-05,
      "loss": 0.0415,
      "step": 10310
    },
    {
      "epoch": 2.0062208398133747,
      "grad_norm": 0.0032866091933101416,
      "learning_rate": 2.8875496803179538e-05,
      "loss": 0.0015,
      "step": 10320
    },
    {
      "epoch": 2.0081648522550544,
      "grad_norm": 0.02069026045501232,
      "learning_rate": 2.8871176775531366e-05,
      "loss": 0.0002,
      "step": 10330
    },
    {
      "epoch": 2.010108864696734,
      "grad_norm": 0.0011105436133220792,
      "learning_rate": 2.8866856747883186e-05,
      "loss": 0.038,
      "step": 10340
    },
    {
      "epoch": 2.0120528771384136,
      "grad_norm": 0.014457747340202332,
      "learning_rate": 2.8862536720235007e-05,
      "loss": 0.0002,
      "step": 10350
    },
    {
      "epoch": 2.0139968895800933,
      "grad_norm": 0.0017453908221796155,
      "learning_rate": 2.8858216692586835e-05,
      "loss": 0.0003,
      "step": 10360
    },
    {
      "epoch": 2.015940902021773,
      "grad_norm": 0.002046572044491768,
      "learning_rate": 2.8853896664938655e-05,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 2.0178849144634525,
      "grad_norm": 0.0019036784069612622,
      "learning_rate": 2.884957663729048e-05,
      "loss": 0.0004,
      "step": 10380
    },
    {
      "epoch": 2.019828926905132,
      "grad_norm": 0.0007610937464050949,
      "learning_rate": 2.8845256609642304e-05,
      "loss": 0.0001,
      "step": 10390
    },
    {
      "epoch": 2.021772939346812,
      "grad_norm": 0.0019723596051335335,
      "learning_rate": 2.8840936581994124e-05,
      "loss": 0.0007,
      "step": 10400
    },
    {
      "epoch": 2.0237169517884914,
      "grad_norm": 0.0009078065631911159,
      "learning_rate": 2.883661655434595e-05,
      "loss": 0.0002,
      "step": 10410
    },
    {
      "epoch": 2.025660964230171,
      "grad_norm": 0.0007510589784942567,
      "learning_rate": 2.8832296526697773e-05,
      "loss": 0.0001,
      "step": 10420
    },
    {
      "epoch": 2.0276049766718507,
      "grad_norm": 0.0007030158303678036,
      "learning_rate": 2.8827976499049593e-05,
      "loss": 0.0001,
      "step": 10430
    },
    {
      "epoch": 2.0295489891135303,
      "grad_norm": 0.021205764263868332,
      "learning_rate": 2.8823656471401417e-05,
      "loss": 0.0003,
      "step": 10440
    },
    {
      "epoch": 2.03149300155521,
      "grad_norm": 7.076794147491455,
      "learning_rate": 2.881933644375324e-05,
      "loss": 0.0003,
      "step": 10450
    },
    {
      "epoch": 2.0334370139968896,
      "grad_norm": 0.001429699594154954,
      "learning_rate": 2.8815016416105062e-05,
      "loss": 0.0164,
      "step": 10460
    },
    {
      "epoch": 2.035381026438569,
      "grad_norm": 0.013521445915102959,
      "learning_rate": 2.8810696388456886e-05,
      "loss": 0.0252,
      "step": 10470
    },
    {
      "epoch": 2.037325038880249,
      "grad_norm": 0.004270472098141909,
      "learning_rate": 2.880637636080871e-05,
      "loss": 0.0021,
      "step": 10480
    },
    {
      "epoch": 2.0392690513219285,
      "grad_norm": 0.004300578497350216,
      "learning_rate": 2.880205633316053e-05,
      "loss": 0.0002,
      "step": 10490
    },
    {
      "epoch": 2.041213063763608,
      "grad_norm": 0.04775357246398926,
      "learning_rate": 2.8797736305512355e-05,
      "loss": 0.0011,
      "step": 10500
    },
    {
      "epoch": 2.0431570762052877,
      "grad_norm": 0.0016174971824511886,
      "learning_rate": 2.879341627786418e-05,
      "loss": 0.0002,
      "step": 10510
    },
    {
      "epoch": 2.0451010886469674,
      "grad_norm": 0.0013145040720701218,
      "learning_rate": 2.8789096250216e-05,
      "loss": 0.0001,
      "step": 10520
    },
    {
      "epoch": 2.047045101088647,
      "grad_norm": 0.0061486708000302315,
      "learning_rate": 2.8784776222567828e-05,
      "loss": 0.0001,
      "step": 10530
    },
    {
      "epoch": 2.0489891135303266,
      "grad_norm": 0.001026188605464995,
      "learning_rate": 2.878045619491965e-05,
      "loss": 0.0038,
      "step": 10540
    },
    {
      "epoch": 2.0509331259720063,
      "grad_norm": 0.0032841782085597515,
      "learning_rate": 2.877613616727147e-05,
      "loss": 0.0001,
      "step": 10550
    },
    {
      "epoch": 2.052877138413686,
      "grad_norm": 0.0010106033878400922,
      "learning_rate": 2.8771816139623297e-05,
      "loss": 0.0003,
      "step": 10560
    },
    {
      "epoch": 2.0548211508553655,
      "grad_norm": 0.0013778788270428777,
      "learning_rate": 2.8767496111975117e-05,
      "loss": 0.0173,
      "step": 10570
    },
    {
      "epoch": 2.056765163297045,
      "grad_norm": 0.001294863410294056,
      "learning_rate": 2.876317608432694e-05,
      "loss": 0.0001,
      "step": 10580
    },
    {
      "epoch": 2.058709175738725,
      "grad_norm": 0.0010477417381480336,
      "learning_rate": 2.8758856056678766e-05,
      "loss": 0.0147,
      "step": 10590
    },
    {
      "epoch": 2.0606531881804044,
      "grad_norm": 0.0011931913904845715,
      "learning_rate": 2.8754536029030586e-05,
      "loss": 0.0103,
      "step": 10600
    },
    {
      "epoch": 2.062597200622084,
      "grad_norm": 0.0012062465539202094,
      "learning_rate": 2.875021600138241e-05,
      "loss": 0.0001,
      "step": 10610
    },
    {
      "epoch": 2.0645412130637637,
      "grad_norm": 0.0010728348279371858,
      "learning_rate": 2.8745895973734234e-05,
      "loss": 0.0159,
      "step": 10620
    },
    {
      "epoch": 2.0664852255054433,
      "grad_norm": 0.17300334572792053,
      "learning_rate": 2.8741575946086055e-05,
      "loss": 0.0002,
      "step": 10630
    },
    {
      "epoch": 2.068429237947123,
      "grad_norm": 0.00085045414743945,
      "learning_rate": 2.873725591843788e-05,
      "loss": 0.0001,
      "step": 10640
    },
    {
      "epoch": 2.0703732503888026,
      "grad_norm": 0.0008460297249257565,
      "learning_rate": 2.8732935890789703e-05,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 2.0723172628304822,
      "grad_norm": 0.0009439284331165254,
      "learning_rate": 2.8728615863141524e-05,
      "loss": 0.0001,
      "step": 10660
    },
    {
      "epoch": 2.074261275272162,
      "grad_norm": 0.0012592575512826443,
      "learning_rate": 2.8724295835493348e-05,
      "loss": 0.0429,
      "step": 10670
    },
    {
      "epoch": 2.0762052877138415,
      "grad_norm": 0.005140508059412241,
      "learning_rate": 2.8719975807845172e-05,
      "loss": 0.0002,
      "step": 10680
    },
    {
      "epoch": 2.078149300155521,
      "grad_norm": 4.112555027008057,
      "learning_rate": 2.8715655780196993e-05,
      "loss": 0.0409,
      "step": 10690
    },
    {
      "epoch": 2.0800933125972008,
      "grad_norm": 0.0023711875546723604,
      "learning_rate": 2.8711335752548817e-05,
      "loss": 0.0021,
      "step": 10700
    },
    {
      "epoch": 2.0820373250388804,
      "grad_norm": 0.0012926456984132528,
      "learning_rate": 2.870701572490064e-05,
      "loss": 0.0003,
      "step": 10710
    },
    {
      "epoch": 2.08398133748056,
      "grad_norm": 0.0008558573899790645,
      "learning_rate": 2.8702695697252462e-05,
      "loss": 0.0001,
      "step": 10720
    },
    {
      "epoch": 2.0859253499222397,
      "grad_norm": 0.0013636378571391106,
      "learning_rate": 2.8698375669604286e-05,
      "loss": 0.0001,
      "step": 10730
    },
    {
      "epoch": 2.0878693623639193,
      "grad_norm": 0.0014187891501933336,
      "learning_rate": 2.869405564195611e-05,
      "loss": 0.0001,
      "step": 10740
    },
    {
      "epoch": 2.089813374805599,
      "grad_norm": 0.0010367942741140723,
      "learning_rate": 2.868973561430793e-05,
      "loss": 0.0001,
      "step": 10750
    },
    {
      "epoch": 2.0917573872472786,
      "grad_norm": 0.002032787771895528,
      "learning_rate": 2.8685415586659755e-05,
      "loss": 0.0001,
      "step": 10760
    },
    {
      "epoch": 2.093701399688958,
      "grad_norm": 0.01302303746342659,
      "learning_rate": 2.868109555901158e-05,
      "loss": 0.0237,
      "step": 10770
    },
    {
      "epoch": 2.095645412130638,
      "grad_norm": 0.01732802391052246,
      "learning_rate": 2.8676775531363403e-05,
      "loss": 0.0044,
      "step": 10780
    },
    {
      "epoch": 2.0975894245723175,
      "grad_norm": 0.010343524627387524,
      "learning_rate": 2.8672455503715224e-05,
      "loss": 0.0006,
      "step": 10790
    },
    {
      "epoch": 2.099533437013997,
      "grad_norm": 0.004055419005453587,
      "learning_rate": 2.8668135476067048e-05,
      "loss": 0.0003,
      "step": 10800
    },
    {
      "epoch": 2.1014774494556767,
      "grad_norm": 0.0036534820683300495,
      "learning_rate": 2.8663815448418872e-05,
      "loss": 0.0491,
      "step": 10810
    },
    {
      "epoch": 2.1034214618973563,
      "grad_norm": 0.00351592805236578,
      "learning_rate": 2.8659495420770693e-05,
      "loss": 0.0002,
      "step": 10820
    },
    {
      "epoch": 2.105365474339036,
      "grad_norm": 0.0032609906047582626,
      "learning_rate": 2.8655175393122517e-05,
      "loss": 0.0002,
      "step": 10830
    },
    {
      "epoch": 2.107309486780715,
      "grad_norm": 0.015536467544734478,
      "learning_rate": 2.865085536547434e-05,
      "loss": 0.0252,
      "step": 10840
    },
    {
      "epoch": 2.109253499222395,
      "grad_norm": 0.024007616564631462,
      "learning_rate": 2.8646535337826162e-05,
      "loss": 0.0083,
      "step": 10850
    },
    {
      "epoch": 2.1111975116640744,
      "grad_norm": 0.008768587373197079,
      "learning_rate": 2.8642215310177986e-05,
      "loss": 0.0005,
      "step": 10860
    },
    {
      "epoch": 2.113141524105754,
      "grad_norm": 0.004585801158100367,
      "learning_rate": 2.863789528252981e-05,
      "loss": 0.0062,
      "step": 10870
    },
    {
      "epoch": 2.1150855365474337,
      "grad_norm": 0.004279198590666056,
      "learning_rate": 2.863357525488163e-05,
      "loss": 0.0003,
      "step": 10880
    },
    {
      "epoch": 2.1170295489891133,
      "grad_norm": 0.2417890429496765,
      "learning_rate": 2.8629255227233455e-05,
      "loss": 0.0003,
      "step": 10890
    },
    {
      "epoch": 2.118973561430793,
      "grad_norm": 0.0028483576606959105,
      "learning_rate": 2.862493519958528e-05,
      "loss": 0.0001,
      "step": 10900
    },
    {
      "epoch": 2.1209175738724726,
      "grad_norm": 0.0017055367352440953,
      "learning_rate": 2.86206151719371e-05,
      "loss": 0.0001,
      "step": 10910
    },
    {
      "epoch": 2.1228615863141522,
      "grad_norm": 0.001498559257015586,
      "learning_rate": 2.8616295144288924e-05,
      "loss": 0.0227,
      "step": 10920
    },
    {
      "epoch": 2.124805598755832,
      "grad_norm": 0.0016340099973604083,
      "learning_rate": 2.8611975116640748e-05,
      "loss": 0.0582,
      "step": 10930
    },
    {
      "epoch": 2.1267496111975115,
      "grad_norm": 0.0018621613271534443,
      "learning_rate": 2.860765508899257e-05,
      "loss": 0.0004,
      "step": 10940
    },
    {
      "epoch": 2.128693623639191,
      "grad_norm": 0.0024187066592276096,
      "learning_rate": 2.8603335061344393e-05,
      "loss": 0.0002,
      "step": 10950
    },
    {
      "epoch": 2.1306376360808708,
      "grad_norm": 0.0015551327960565686,
      "learning_rate": 2.8599015033696217e-05,
      "loss": 0.0057,
      "step": 10960
    },
    {
      "epoch": 2.1325816485225504,
      "grad_norm": 0.0017857912462204695,
      "learning_rate": 2.8594695006048038e-05,
      "loss": 0.0001,
      "step": 10970
    },
    {
      "epoch": 2.13452566096423,
      "grad_norm": 19.802759170532227,
      "learning_rate": 2.8590374978399865e-05,
      "loss": 0.0025,
      "step": 10980
    },
    {
      "epoch": 2.1364696734059097,
      "grad_norm": 0.0012826897436752915,
      "learning_rate": 2.8586054950751686e-05,
      "loss": 0.0002,
      "step": 10990
    },
    {
      "epoch": 2.1384136858475893,
      "grad_norm": 0.0015996173024177551,
      "learning_rate": 2.8581734923103507e-05,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 2.140357698289269,
      "grad_norm": 0.00162301876116544,
      "learning_rate": 2.8577414895455334e-05,
      "loss": 0.0001,
      "step": 11010
    },
    {
      "epoch": 2.1423017107309485,
      "grad_norm": 0.0018563949270173907,
      "learning_rate": 2.8573094867807155e-05,
      "loss": 0.0001,
      "step": 11020
    },
    {
      "epoch": 2.144245723172628,
      "grad_norm": 0.0010875249281525612,
      "learning_rate": 2.8568774840158976e-05,
      "loss": 0.0001,
      "step": 11030
    },
    {
      "epoch": 2.146189735614308,
      "grad_norm": 0.0035844845697283745,
      "learning_rate": 2.8564454812510803e-05,
      "loss": 0.0001,
      "step": 11040
    },
    {
      "epoch": 2.1481337480559874,
      "grad_norm": 0.27065640687942505,
      "learning_rate": 2.8560134784862624e-05,
      "loss": 0.0085,
      "step": 11050
    },
    {
      "epoch": 2.150077760497667,
      "grad_norm": 0.000864535802975297,
      "learning_rate": 2.8555814757214444e-05,
      "loss": 0.011,
      "step": 11060
    },
    {
      "epoch": 2.1520217729393467,
      "grad_norm": 0.001384075963869691,
      "learning_rate": 2.8551494729566272e-05,
      "loss": 0.0079,
      "step": 11070
    },
    {
      "epoch": 2.1539657853810263,
      "grad_norm": 0.39816683530807495,
      "learning_rate": 2.8547174701918093e-05,
      "loss": 0.0115,
      "step": 11080
    },
    {
      "epoch": 2.155909797822706,
      "grad_norm": 0.000965333660133183,
      "learning_rate": 2.8542854674269913e-05,
      "loss": 0.0007,
      "step": 11090
    },
    {
      "epoch": 2.1578538102643856,
      "grad_norm": 0.00108096853364259,
      "learning_rate": 2.853853464662174e-05,
      "loss": 0.0001,
      "step": 11100
    },
    {
      "epoch": 2.1597978227060652,
      "grad_norm": 0.0015815795632079244,
      "learning_rate": 2.853421461897356e-05,
      "loss": 0.0418,
      "step": 11110
    },
    {
      "epoch": 2.161741835147745,
      "grad_norm": 0.0034098357427865267,
      "learning_rate": 2.8529894591325382e-05,
      "loss": 0.0033,
      "step": 11120
    },
    {
      "epoch": 2.1636858475894245,
      "grad_norm": 0.006724719423800707,
      "learning_rate": 2.852557456367721e-05,
      "loss": 0.0002,
      "step": 11130
    },
    {
      "epoch": 2.165629860031104,
      "grad_norm": 0.0007516489713452756,
      "learning_rate": 2.852125453602903e-05,
      "loss": 0.0028,
      "step": 11140
    },
    {
      "epoch": 2.1675738724727838,
      "grad_norm": 0.000739040959160775,
      "learning_rate": 2.8516934508380855e-05,
      "loss": 0.019,
      "step": 11150
    },
    {
      "epoch": 2.1695178849144634,
      "grad_norm": 0.001119521795772016,
      "learning_rate": 2.851261448073268e-05,
      "loss": 0.0001,
      "step": 11160
    },
    {
      "epoch": 2.171461897356143,
      "grad_norm": 0.0012605771189555526,
      "learning_rate": 2.85082944530845e-05,
      "loss": 0.0001,
      "step": 11170
    },
    {
      "epoch": 2.1734059097978227,
      "grad_norm": 0.0014978965045884252,
      "learning_rate": 2.8503974425436324e-05,
      "loss": 0.0001,
      "step": 11180
    },
    {
      "epoch": 2.1753499222395023,
      "grad_norm": 0.0007930812425911427,
      "learning_rate": 2.8499654397788148e-05,
      "loss": 0.0001,
      "step": 11190
    },
    {
      "epoch": 2.177293934681182,
      "grad_norm": 0.001523408805951476,
      "learning_rate": 2.849533437013997e-05,
      "loss": 0.0036,
      "step": 11200
    },
    {
      "epoch": 2.1792379471228616,
      "grad_norm": 0.0021660933271050453,
      "learning_rate": 2.8491014342491793e-05,
      "loss": 0.0001,
      "step": 11210
    },
    {
      "epoch": 2.181181959564541,
      "grad_norm": 0.0008388020796701312,
      "learning_rate": 2.8486694314843617e-05,
      "loss": 0.0002,
      "step": 11220
    },
    {
      "epoch": 2.183125972006221,
      "grad_norm": 0.0009428999619558454,
      "learning_rate": 2.8482374287195437e-05,
      "loss": 0.0002,
      "step": 11230
    },
    {
      "epoch": 2.1850699844479005,
      "grad_norm": 0.003790417918935418,
      "learning_rate": 2.847805425954726e-05,
      "loss": 0.0164,
      "step": 11240
    },
    {
      "epoch": 2.18701399688958,
      "grad_norm": 0.000979818869382143,
      "learning_rate": 2.8473734231899086e-05,
      "loss": 0.0148,
      "step": 11250
    },
    {
      "epoch": 2.1889580093312597,
      "grad_norm": 0.002633863128721714,
      "learning_rate": 2.8469414204250906e-05,
      "loss": 0.0002,
      "step": 11260
    },
    {
      "epoch": 2.1909020217729394,
      "grad_norm": 0.39423346519470215,
      "learning_rate": 2.846509417660273e-05,
      "loss": 0.0025,
      "step": 11270
    },
    {
      "epoch": 2.192846034214619,
      "grad_norm": 0.002629798138514161,
      "learning_rate": 2.8460774148954555e-05,
      "loss": 0.0002,
      "step": 11280
    },
    {
      "epoch": 2.1947900466562986,
      "grad_norm": 0.0031639134977012873,
      "learning_rate": 2.8456454121306375e-05,
      "loss": 0.0001,
      "step": 11290
    },
    {
      "epoch": 2.1967340590979783,
      "grad_norm": 8.667635917663574,
      "learning_rate": 2.84521340936582e-05,
      "loss": 0.1094,
      "step": 11300
    },
    {
      "epoch": 2.198678071539658,
      "grad_norm": 0.004470535553991795,
      "learning_rate": 2.8447814066010024e-05,
      "loss": 0.0103,
      "step": 11310
    },
    {
      "epoch": 2.2006220839813375,
      "grad_norm": 0.017069373279809952,
      "learning_rate": 2.8443494038361844e-05,
      "loss": 0.0002,
      "step": 11320
    },
    {
      "epoch": 2.202566096423017,
      "grad_norm": 0.0007710529025644064,
      "learning_rate": 2.843917401071367e-05,
      "loss": 0.0003,
      "step": 11330
    },
    {
      "epoch": 2.204510108864697,
      "grad_norm": 0.006361253093928099,
      "learning_rate": 2.8434853983065492e-05,
      "loss": 0.0005,
      "step": 11340
    },
    {
      "epoch": 2.2064541213063764,
      "grad_norm": 0.005206821020692587,
      "learning_rate": 2.8430533955417317e-05,
      "loss": 0.0002,
      "step": 11350
    },
    {
      "epoch": 2.208398133748056,
      "grad_norm": 1.9541996717453003,
      "learning_rate": 2.8426213927769137e-05,
      "loss": 0.0108,
      "step": 11360
    },
    {
      "epoch": 2.2103421461897357,
      "grad_norm": 0.0016457542078569531,
      "learning_rate": 2.842189390012096e-05,
      "loss": 0.0001,
      "step": 11370
    },
    {
      "epoch": 2.2122861586314153,
      "grad_norm": 0.0009766336297616363,
      "learning_rate": 2.8417573872472786e-05,
      "loss": 0.0021,
      "step": 11380
    },
    {
      "epoch": 2.214230171073095,
      "grad_norm": 0.0023904216941446066,
      "learning_rate": 2.8413253844824606e-05,
      "loss": 0.0001,
      "step": 11390
    },
    {
      "epoch": 2.2161741835147746,
      "grad_norm": 0.0026659045834094286,
      "learning_rate": 2.840893381717643e-05,
      "loss": 0.0003,
      "step": 11400
    },
    {
      "epoch": 2.218118195956454,
      "grad_norm": 0.0024525176268070936,
      "learning_rate": 2.8404613789528254e-05,
      "loss": 0.0001,
      "step": 11410
    },
    {
      "epoch": 2.220062208398134,
      "grad_norm": 0.003542589955031872,
      "learning_rate": 2.8400293761880075e-05,
      "loss": 0.005,
      "step": 11420
    },
    {
      "epoch": 2.2220062208398135,
      "grad_norm": 0.006582578644156456,
      "learning_rate": 2.83959737342319e-05,
      "loss": 0.0001,
      "step": 11430
    },
    {
      "epoch": 2.223950233281493,
      "grad_norm": 0.2901129126548767,
      "learning_rate": 2.8391653706583723e-05,
      "loss": 0.0009,
      "step": 11440
    },
    {
      "epoch": 2.2258942457231727,
      "grad_norm": 0.020269574597477913,
      "learning_rate": 2.8387333678935548e-05,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 2.2278382581648524,
      "grad_norm": 0.0006913490360602736,
      "learning_rate": 2.8383013651287368e-05,
      "loss": 0.0001,
      "step": 11460
    },
    {
      "epoch": 2.229782270606532,
      "grad_norm": 11.342941284179688,
      "learning_rate": 2.8378693623639192e-05,
      "loss": 0.0126,
      "step": 11470
    },
    {
      "epoch": 2.2317262830482116,
      "grad_norm": 0.0011608999921008945,
      "learning_rate": 2.8374373595991016e-05,
      "loss": 0.0001,
      "step": 11480
    },
    {
      "epoch": 2.2336702954898913,
      "grad_norm": 0.0018134089186787605,
      "learning_rate": 2.8370053568342837e-05,
      "loss": 0.005,
      "step": 11490
    },
    {
      "epoch": 2.235614307931571,
      "grad_norm": 0.0022783558815717697,
      "learning_rate": 2.836573354069466e-05,
      "loss": 0.0001,
      "step": 11500
    },
    {
      "epoch": 2.2375583203732505,
      "grad_norm": 0.3494510054588318,
      "learning_rate": 2.8361413513046485e-05,
      "loss": 0.0002,
      "step": 11510
    },
    {
      "epoch": 2.23950233281493,
      "grad_norm": 0.0009451594087295234,
      "learning_rate": 2.8357093485398306e-05,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 2.24144634525661,
      "grad_norm": 0.0007614127825945616,
      "learning_rate": 2.835277345775013e-05,
      "loss": 0.0014,
      "step": 11530
    },
    {
      "epoch": 2.2433903576982894,
      "grad_norm": 0.0037749335169792175,
      "learning_rate": 2.8348453430101954e-05,
      "loss": 0.0002,
      "step": 11540
    },
    {
      "epoch": 2.245334370139969,
      "grad_norm": 0.002532715443521738,
      "learning_rate": 2.834413340245378e-05,
      "loss": 0.031,
      "step": 11550
    },
    {
      "epoch": 2.2472783825816487,
      "grad_norm": 0.0005187036003917456,
      "learning_rate": 2.83398133748056e-05,
      "loss": 0.0,
      "step": 11560
    },
    {
      "epoch": 2.2492223950233283,
      "grad_norm": 0.001591069856658578,
      "learning_rate": 2.8335493347157423e-05,
      "loss": 0.0006,
      "step": 11570
    },
    {
      "epoch": 2.251166407465008,
      "grad_norm": 0.0010649260366335511,
      "learning_rate": 2.8331173319509247e-05,
      "loss": 0.0145,
      "step": 11580
    },
    {
      "epoch": 2.2531104199066876,
      "grad_norm": 0.0009665018878877163,
      "learning_rate": 2.8326853291861068e-05,
      "loss": 0.011,
      "step": 11590
    },
    {
      "epoch": 2.255054432348367,
      "grad_norm": 0.0008320449851453304,
      "learning_rate": 2.8322533264212892e-05,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 2.256998444790047,
      "grad_norm": 0.0005769729614257812,
      "learning_rate": 2.8318213236564716e-05,
      "loss": 0.0001,
      "step": 11610
    },
    {
      "epoch": 2.2589424572317265,
      "grad_norm": 0.0007766562048345804,
      "learning_rate": 2.8313893208916537e-05,
      "loss": 0.0001,
      "step": 11620
    },
    {
      "epoch": 2.260886469673406,
      "grad_norm": 0.5291721820831299,
      "learning_rate": 2.830957318126836e-05,
      "loss": 0.0004,
      "step": 11630
    },
    {
      "epoch": 2.2628304821150858,
      "grad_norm": 0.000589750474318862,
      "learning_rate": 2.8305253153620185e-05,
      "loss": 0.0,
      "step": 11640
    },
    {
      "epoch": 2.2647744945567654,
      "grad_norm": 0.0005734734586440027,
      "learning_rate": 2.8300933125972006e-05,
      "loss": 0.0,
      "step": 11650
    },
    {
      "epoch": 2.266718506998445,
      "grad_norm": 0.0011639278382062912,
      "learning_rate": 2.829661309832383e-05,
      "loss": 0.0,
      "step": 11660
    },
    {
      "epoch": 2.2686625194401246,
      "grad_norm": 0.0005234080017544329,
      "learning_rate": 2.8292293070675654e-05,
      "loss": 0.0,
      "step": 11670
    },
    {
      "epoch": 2.2706065318818043,
      "grad_norm": 0.0019149451982229948,
      "learning_rate": 2.8287973043027475e-05,
      "loss": 0.0126,
      "step": 11680
    },
    {
      "epoch": 2.272550544323484,
      "grad_norm": 0.05418173596262932,
      "learning_rate": 2.82836530153793e-05,
      "loss": 0.0002,
      "step": 11690
    },
    {
      "epoch": 2.2744945567651635,
      "grad_norm": 0.0018953001126646996,
      "learning_rate": 2.8279332987731123e-05,
      "loss": 0.0001,
      "step": 11700
    },
    {
      "epoch": 2.2764385692068427,
      "grad_norm": 0.0009251494193449616,
      "learning_rate": 2.8275012960082944e-05,
      "loss": 0.0,
      "step": 11710
    },
    {
      "epoch": 2.2783825816485224,
      "grad_norm": 0.01950279250741005,
      "learning_rate": 2.8270692932434768e-05,
      "loss": 0.0003,
      "step": 11720
    },
    {
      "epoch": 2.280326594090202,
      "grad_norm": 0.5071706771850586,
      "learning_rate": 2.8266372904786592e-05,
      "loss": 0.0009,
      "step": 11730
    },
    {
      "epoch": 2.2822706065318816,
      "grad_norm": 0.0004616057558450848,
      "learning_rate": 2.8262052877138413e-05,
      "loss": 0.0024,
      "step": 11740
    },
    {
      "epoch": 2.2842146189735613,
      "grad_norm": 3.1530492305755615,
      "learning_rate": 2.825773284949024e-05,
      "loss": 0.0205,
      "step": 11750
    },
    {
      "epoch": 2.286158631415241,
      "grad_norm": 0.0008187570492736995,
      "learning_rate": 2.825341282184206e-05,
      "loss": 0.0001,
      "step": 11760
    },
    {
      "epoch": 2.2881026438569205,
      "grad_norm": 0.0006686580018140376,
      "learning_rate": 2.8249092794193882e-05,
      "loss": 0.0133,
      "step": 11770
    },
    {
      "epoch": 2.2900466562986,
      "grad_norm": 0.006209502462297678,
      "learning_rate": 2.824477276654571e-05,
      "loss": 0.0001,
      "step": 11780
    },
    {
      "epoch": 2.29199066874028,
      "grad_norm": 0.04211506247520447,
      "learning_rate": 2.824045273889753e-05,
      "loss": 0.0015,
      "step": 11790
    },
    {
      "epoch": 2.2939346811819594,
      "grad_norm": 0.0013468783581629395,
      "learning_rate": 2.823613271124935e-05,
      "loss": 0.0399,
      "step": 11800
    },
    {
      "epoch": 2.295878693623639,
      "grad_norm": 0.0023618193808943033,
      "learning_rate": 2.8231812683601178e-05,
      "loss": 0.0001,
      "step": 11810
    },
    {
      "epoch": 2.2978227060653187,
      "grad_norm": 0.002858491148799658,
      "learning_rate": 2.8227492655953e-05,
      "loss": 0.0045,
      "step": 11820
    },
    {
      "epoch": 2.2997667185069983,
      "grad_norm": 0.0038001076318323612,
      "learning_rate": 2.822317262830482e-05,
      "loss": 0.0219,
      "step": 11830
    },
    {
      "epoch": 2.301710730948678,
      "grad_norm": 0.7002921104431152,
      "learning_rate": 2.8218852600656647e-05,
      "loss": 0.002,
      "step": 11840
    },
    {
      "epoch": 2.3036547433903576,
      "grad_norm": 0.001633001142181456,
      "learning_rate": 2.8214532573008468e-05,
      "loss": 0.0248,
      "step": 11850
    },
    {
      "epoch": 2.305598755832037,
      "grad_norm": 0.002056373516097665,
      "learning_rate": 2.821021254536029e-05,
      "loss": 0.0001,
      "step": 11860
    },
    {
      "epoch": 2.307542768273717,
      "grad_norm": 0.004492653999477625,
      "learning_rate": 2.8205892517712116e-05,
      "loss": 0.0153,
      "step": 11870
    },
    {
      "epoch": 2.3094867807153965,
      "grad_norm": 0.0015098225558176637,
      "learning_rate": 2.8201572490063937e-05,
      "loss": 0.0001,
      "step": 11880
    },
    {
      "epoch": 2.311430793157076,
      "grad_norm": 0.001241179066710174,
      "learning_rate": 2.8197252462415758e-05,
      "loss": 0.0001,
      "step": 11890
    },
    {
      "epoch": 2.3133748055987557,
      "grad_norm": 0.0010162910912185907,
      "learning_rate": 2.8192932434767585e-05,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 2.3153188180404354,
      "grad_norm": 0.0012708064168691635,
      "learning_rate": 2.8188612407119406e-05,
      "loss": 0.0029,
      "step": 11910
    },
    {
      "epoch": 2.317262830482115,
      "grad_norm": 0.20842605829238892,
      "learning_rate": 2.8184292379471227e-05,
      "loss": 0.0008,
      "step": 11920
    },
    {
      "epoch": 2.3192068429237946,
      "grad_norm": 0.012278052046895027,
      "learning_rate": 2.8179972351823054e-05,
      "loss": 0.0262,
      "step": 11930
    },
    {
      "epoch": 2.3211508553654743,
      "grad_norm": 1.8119189739227295,
      "learning_rate": 2.8175652324174875e-05,
      "loss": 0.001,
      "step": 11940
    },
    {
      "epoch": 2.323094867807154,
      "grad_norm": 0.002443210920318961,
      "learning_rate": 2.81713322965267e-05,
      "loss": 0.0003,
      "step": 11950
    },
    {
      "epoch": 2.3250388802488335,
      "grad_norm": 0.0009637800976634026,
      "learning_rate": 2.8167012268878523e-05,
      "loss": 0.0025,
      "step": 11960
    },
    {
      "epoch": 2.326982892690513,
      "grad_norm": 0.0009493474499322474,
      "learning_rate": 2.8162692241230344e-05,
      "loss": 0.0001,
      "step": 11970
    },
    {
      "epoch": 2.328926905132193,
      "grad_norm": 0.001335019594989717,
      "learning_rate": 2.8158372213582168e-05,
      "loss": 0.0001,
      "step": 11980
    },
    {
      "epoch": 2.3308709175738724,
      "grad_norm": 0.0007580389501526952,
      "learning_rate": 2.8154052185933992e-05,
      "loss": 0.0001,
      "step": 11990
    },
    {
      "epoch": 2.332814930015552,
      "grad_norm": 0.000811982317827642,
      "learning_rate": 2.8149732158285813e-05,
      "loss": 0.0001,
      "step": 12000
    },
    {
      "epoch": 2.3347589424572317,
      "grad_norm": 0.0015290349256247282,
      "learning_rate": 2.8145412130637637e-05,
      "loss": 0.0401,
      "step": 12010
    },
    {
      "epoch": 2.3367029548989113,
      "grad_norm": 0.011117779649794102,
      "learning_rate": 2.814109210298946e-05,
      "loss": 0.0004,
      "step": 12020
    },
    {
      "epoch": 2.338646967340591,
      "grad_norm": 0.01018819585442543,
      "learning_rate": 2.813677207534128e-05,
      "loss": 0.0004,
      "step": 12030
    },
    {
      "epoch": 2.3405909797822706,
      "grad_norm": 0.004733259789645672,
      "learning_rate": 2.8132452047693106e-05,
      "loss": 0.0002,
      "step": 12040
    },
    {
      "epoch": 2.3425349922239502,
      "grad_norm": 0.03324902802705765,
      "learning_rate": 2.812813202004493e-05,
      "loss": 0.0002,
      "step": 12050
    },
    {
      "epoch": 2.34447900466563,
      "grad_norm": 0.0023895360063761473,
      "learning_rate": 2.812381199239675e-05,
      "loss": 0.0285,
      "step": 12060
    },
    {
      "epoch": 2.3464230171073095,
      "grad_norm": 0.0014894893392920494,
      "learning_rate": 2.8119491964748575e-05,
      "loss": 0.0009,
      "step": 12070
    },
    {
      "epoch": 2.348367029548989,
      "grad_norm": 0.0018756533972918987,
      "learning_rate": 2.81151719371004e-05,
      "loss": 0.0002,
      "step": 12080
    },
    {
      "epoch": 2.3503110419906688,
      "grad_norm": 1.5537828207015991,
      "learning_rate": 2.811085190945222e-05,
      "loss": 0.0271,
      "step": 12090
    },
    {
      "epoch": 2.3522550544323484,
      "grad_norm": 0.0019730010535568,
      "learning_rate": 2.8106531881804044e-05,
      "loss": 0.0375,
      "step": 12100
    },
    {
      "epoch": 2.354199066874028,
      "grad_norm": 0.01621200144290924,
      "learning_rate": 2.8102211854155868e-05,
      "loss": 0.0093,
      "step": 12110
    },
    {
      "epoch": 2.3561430793157077,
      "grad_norm": 0.0010717964032664895,
      "learning_rate": 2.809789182650769e-05,
      "loss": 0.0095,
      "step": 12120
    },
    {
      "epoch": 2.3580870917573873,
      "grad_norm": 0.010640460066497326,
      "learning_rate": 2.8093571798859513e-05,
      "loss": 0.0085,
      "step": 12130
    },
    {
      "epoch": 2.360031104199067,
      "grad_norm": 0.15653356909751892,
      "learning_rate": 2.8089251771211337e-05,
      "loss": 0.0008,
      "step": 12140
    },
    {
      "epoch": 2.3619751166407466,
      "grad_norm": 0.6107942461967468,
      "learning_rate": 2.808493174356316e-05,
      "loss": 0.001,
      "step": 12150
    },
    {
      "epoch": 2.363919129082426,
      "grad_norm": 0.0011478438973426819,
      "learning_rate": 2.808061171591498e-05,
      "loss": 0.0003,
      "step": 12160
    },
    {
      "epoch": 2.365863141524106,
      "grad_norm": 0.0016985307447612286,
      "learning_rate": 2.8076291688266806e-05,
      "loss": 0.0051,
      "step": 12170
    },
    {
      "epoch": 2.3678071539657854,
      "grad_norm": 0.0019074686570093036,
      "learning_rate": 2.807197166061863e-05,
      "loss": 0.0001,
      "step": 12180
    },
    {
      "epoch": 2.369751166407465,
      "grad_norm": 0.001029565348289907,
      "learning_rate": 2.806765163297045e-05,
      "loss": 0.0008,
      "step": 12190
    },
    {
      "epoch": 2.3716951788491447,
      "grad_norm": 0.0011930831242352724,
      "learning_rate": 2.8063331605322275e-05,
      "loss": 0.039,
      "step": 12200
    },
    {
      "epoch": 2.3736391912908243,
      "grad_norm": 0.0022075611632317305,
      "learning_rate": 2.80590115776741e-05,
      "loss": 0.0001,
      "step": 12210
    },
    {
      "epoch": 2.375583203732504,
      "grad_norm": 28.123023986816406,
      "learning_rate": 2.805469155002592e-05,
      "loss": 0.0251,
      "step": 12220
    },
    {
      "epoch": 2.3775272161741836,
      "grad_norm": 0.0009581803460605443,
      "learning_rate": 2.8050371522377743e-05,
      "loss": 0.0001,
      "step": 12230
    },
    {
      "epoch": 2.3794712286158632,
      "grad_norm": 0.0011140881106257439,
      "learning_rate": 2.8046051494729568e-05,
      "loss": 0.016,
      "step": 12240
    },
    {
      "epoch": 2.381415241057543,
      "grad_norm": 0.0006696326308883727,
      "learning_rate": 2.8041731467081388e-05,
      "loss": 0.0001,
      "step": 12250
    },
    {
      "epoch": 2.3833592534992225,
      "grad_norm": 0.02496720664203167,
      "learning_rate": 2.8037411439433212e-05,
      "loss": 0.0001,
      "step": 12260
    },
    {
      "epoch": 2.385303265940902,
      "grad_norm": 0.0005721403867937624,
      "learning_rate": 2.8033091411785037e-05,
      "loss": 0.0001,
      "step": 12270
    },
    {
      "epoch": 2.3872472783825818,
      "grad_norm": 0.002543058479204774,
      "learning_rate": 2.8028771384136857e-05,
      "loss": 0.0001,
      "step": 12280
    },
    {
      "epoch": 2.3891912908242614,
      "grad_norm": 0.0010404817294329405,
      "learning_rate": 2.802445135648868e-05,
      "loss": 0.0047,
      "step": 12290
    },
    {
      "epoch": 2.391135303265941,
      "grad_norm": 0.001411670702509582,
      "learning_rate": 2.8020131328840505e-05,
      "loss": 0.0001,
      "step": 12300
    },
    {
      "epoch": 2.3930793157076207,
      "grad_norm": 0.0008588453638367355,
      "learning_rate": 2.8015811301192326e-05,
      "loss": 0.0115,
      "step": 12310
    },
    {
      "epoch": 2.3950233281493003,
      "grad_norm": 0.001999911852180958,
      "learning_rate": 2.801149127354415e-05,
      "loss": 0.0001,
      "step": 12320
    },
    {
      "epoch": 2.39696734059098,
      "grad_norm": 0.0017060989048331976,
      "learning_rate": 2.8007171245895974e-05,
      "loss": 0.0122,
      "step": 12330
    },
    {
      "epoch": 2.3989113530326596,
      "grad_norm": 0.5399316549301147,
      "learning_rate": 2.80028512182478e-05,
      "loss": 0.0086,
      "step": 12340
    },
    {
      "epoch": 2.400855365474339,
      "grad_norm": 0.004081722814589739,
      "learning_rate": 2.7998531190599623e-05,
      "loss": 0.0179,
      "step": 12350
    },
    {
      "epoch": 2.402799377916019,
      "grad_norm": 0.003003697842359543,
      "learning_rate": 2.7994211162951443e-05,
      "loss": 0.0001,
      "step": 12360
    },
    {
      "epoch": 2.4047433903576985,
      "grad_norm": 0.0005900663090869784,
      "learning_rate": 2.7989891135303267e-05,
      "loss": 0.0004,
      "step": 12370
    },
    {
      "epoch": 2.406687402799378,
      "grad_norm": 0.01749725081026554,
      "learning_rate": 2.798557110765509e-05,
      "loss": 0.0345,
      "step": 12380
    },
    {
      "epoch": 2.4086314152410577,
      "grad_norm": 0.004145714920014143,
      "learning_rate": 2.7981251080006912e-05,
      "loss": 0.0745,
      "step": 12390
    },
    {
      "epoch": 2.4105754276827374,
      "grad_norm": 0.1734885424375534,
      "learning_rate": 2.7976931052358736e-05,
      "loss": 0.0008,
      "step": 12400
    },
    {
      "epoch": 2.4125194401244165,
      "grad_norm": 0.0067440541461110115,
      "learning_rate": 2.797261102471056e-05,
      "loss": 0.0007,
      "step": 12410
    },
    {
      "epoch": 2.414463452566096,
      "grad_norm": 0.42459139227867126,
      "learning_rate": 2.796829099706238e-05,
      "loss": 0.0008,
      "step": 12420
    },
    {
      "epoch": 2.416407465007776,
      "grad_norm": 0.006647177506238222,
      "learning_rate": 2.7963970969414205e-05,
      "loss": 0.0002,
      "step": 12430
    },
    {
      "epoch": 2.4183514774494554,
      "grad_norm": 0.005095825996249914,
      "learning_rate": 2.795965094176603e-05,
      "loss": 0.0169,
      "step": 12440
    },
    {
      "epoch": 2.420295489891135,
      "grad_norm": 0.002107856096699834,
      "learning_rate": 2.795533091411785e-05,
      "loss": 0.005,
      "step": 12450
    },
    {
      "epoch": 2.4222395023328147,
      "grad_norm": 0.07480049133300781,
      "learning_rate": 2.7951010886469674e-05,
      "loss": 0.0003,
      "step": 12460
    },
    {
      "epoch": 2.4241835147744943,
      "grad_norm": 0.0026717050932347775,
      "learning_rate": 2.79466908588215e-05,
      "loss": 0.0001,
      "step": 12470
    },
    {
      "epoch": 2.426127527216174,
      "grad_norm": 0.009723234921693802,
      "learning_rate": 2.794237083117332e-05,
      "loss": 0.0001,
      "step": 12480
    },
    {
      "epoch": 2.4280715396578536,
      "grad_norm": 0.005005499813705683,
      "learning_rate": 2.7938050803525143e-05,
      "loss": 0.0002,
      "step": 12490
    },
    {
      "epoch": 2.4300155520995332,
      "grad_norm": 0.0024060108698904514,
      "learning_rate": 2.7933730775876967e-05,
      "loss": 0.0002,
      "step": 12500
    },
    {
      "epoch": 2.431959564541213,
      "grad_norm": 0.003947010263800621,
      "learning_rate": 2.7929410748228788e-05,
      "loss": 0.0259,
      "step": 12510
    },
    {
      "epoch": 2.4339035769828925,
      "grad_norm": 0.46473848819732666,
      "learning_rate": 2.7925090720580612e-05,
      "loss": 0.0011,
      "step": 12520
    },
    {
      "epoch": 2.435847589424572,
      "grad_norm": 0.007597805466502905,
      "learning_rate": 2.7920770692932436e-05,
      "loss": 0.0219,
      "step": 12530
    },
    {
      "epoch": 2.4377916018662518,
      "grad_norm": 0.03640620410442352,
      "learning_rate": 2.7916450665284257e-05,
      "loss": 0.001,
      "step": 12540
    },
    {
      "epoch": 2.4397356143079314,
      "grad_norm": 7.030187129974365,
      "learning_rate": 2.7912130637636085e-05,
      "loss": 0.0399,
      "step": 12550
    },
    {
      "epoch": 2.441679626749611,
      "grad_norm": 0.0032181518618017435,
      "learning_rate": 2.7907810609987905e-05,
      "loss": 0.0002,
      "step": 12560
    },
    {
      "epoch": 2.4436236391912907,
      "grad_norm": 0.0015374546637758613,
      "learning_rate": 2.7903490582339726e-05,
      "loss": 0.0001,
      "step": 12570
    },
    {
      "epoch": 2.4455676516329703,
      "grad_norm": 0.003062385367229581,
      "learning_rate": 2.7899170554691553e-05,
      "loss": 0.0001,
      "step": 12580
    },
    {
      "epoch": 2.44751166407465,
      "grad_norm": 0.0017206199700012803,
      "learning_rate": 2.7894850527043374e-05,
      "loss": 0.0002,
      "step": 12590
    },
    {
      "epoch": 2.4494556765163296,
      "grad_norm": 0.001892630709335208,
      "learning_rate": 2.7890530499395195e-05,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 2.451399688958009,
      "grad_norm": 0.0028130635619163513,
      "learning_rate": 2.7886210471747022e-05,
      "loss": 0.0001,
      "step": 12610
    },
    {
      "epoch": 2.453343701399689,
      "grad_norm": 0.0011235405690968037,
      "learning_rate": 2.7881890444098843e-05,
      "loss": 0.0003,
      "step": 12620
    },
    {
      "epoch": 2.4552877138413685,
      "grad_norm": 0.0017291710246354342,
      "learning_rate": 2.7877570416450664e-05,
      "loss": 0.0001,
      "step": 12630
    },
    {
      "epoch": 2.457231726283048,
      "grad_norm": 0.01813509315252304,
      "learning_rate": 2.787325038880249e-05,
      "loss": 0.0002,
      "step": 12640
    },
    {
      "epoch": 2.4591757387247277,
      "grad_norm": 0.0008647930226288736,
      "learning_rate": 2.7868930361154312e-05,
      "loss": 0.0001,
      "step": 12650
    },
    {
      "epoch": 2.4611197511664074,
      "grad_norm": 0.0014245776692405343,
      "learning_rate": 2.7864610333506133e-05,
      "loss": 0.0001,
      "step": 12660
    },
    {
      "epoch": 2.463063763608087,
      "grad_norm": 0.0009193874429911375,
      "learning_rate": 2.786029030585796e-05,
      "loss": 0.0096,
      "step": 12670
    },
    {
      "epoch": 2.4650077760497666,
      "grad_norm": 0.0007848148816265166,
      "learning_rate": 2.785597027820978e-05,
      "loss": 0.0001,
      "step": 12680
    },
    {
      "epoch": 2.4669517884914463,
      "grad_norm": 0.0008051169570535421,
      "learning_rate": 2.7851650250561602e-05,
      "loss": 0.0002,
      "step": 12690
    },
    {
      "epoch": 2.468895800933126,
      "grad_norm": 0.0007471180288121104,
      "learning_rate": 2.784733022291343e-05,
      "loss": 0.0099,
      "step": 12700
    },
    {
      "epoch": 2.4708398133748055,
      "grad_norm": 0.0017756135202944279,
      "learning_rate": 2.784301019526525e-05,
      "loss": 0.0002,
      "step": 12710
    },
    {
      "epoch": 2.472783825816485,
      "grad_norm": 0.0008907819865271449,
      "learning_rate": 2.7838690167617074e-05,
      "loss": 0.0247,
      "step": 12720
    },
    {
      "epoch": 2.474727838258165,
      "grad_norm": 0.0007560634985566139,
      "learning_rate": 2.7834370139968898e-05,
      "loss": 0.0001,
      "step": 12730
    },
    {
      "epoch": 2.4766718506998444,
      "grad_norm": 0.0008095584344118834,
      "learning_rate": 2.783005011232072e-05,
      "loss": 0.0068,
      "step": 12740
    },
    {
      "epoch": 2.478615863141524,
      "grad_norm": 0.001176475896500051,
      "learning_rate": 2.7825730084672543e-05,
      "loss": 0.0202,
      "step": 12750
    },
    {
      "epoch": 2.4805598755832037,
      "grad_norm": 0.0017374421004205942,
      "learning_rate": 2.7821410057024367e-05,
      "loss": 0.0001,
      "step": 12760
    },
    {
      "epoch": 2.4825038880248833,
      "grad_norm": 0.005515647120773792,
      "learning_rate": 2.7817090029376188e-05,
      "loss": 0.0001,
      "step": 12770
    },
    {
      "epoch": 2.484447900466563,
      "grad_norm": 0.007635785266757011,
      "learning_rate": 2.7812770001728012e-05,
      "loss": 0.0046,
      "step": 12780
    },
    {
      "epoch": 2.4863919129082426,
      "grad_norm": 0.0013127248967066407,
      "learning_rate": 2.7808449974079836e-05,
      "loss": 0.0001,
      "step": 12790
    },
    {
      "epoch": 2.488335925349922,
      "grad_norm": 0.24258005619049072,
      "learning_rate": 2.7804129946431657e-05,
      "loss": 0.0073,
      "step": 12800
    },
    {
      "epoch": 2.490279937791602,
      "grad_norm": 0.000859006482642144,
      "learning_rate": 2.779980991878348e-05,
      "loss": 0.0004,
      "step": 12810
    },
    {
      "epoch": 2.4922239502332815,
      "grad_norm": 0.0012261306401342154,
      "learning_rate": 2.7795489891135305e-05,
      "loss": 0.0001,
      "step": 12820
    },
    {
      "epoch": 2.494167962674961,
      "grad_norm": 0.0009534734417684376,
      "learning_rate": 2.7791169863487126e-05,
      "loss": 0.0129,
      "step": 12830
    },
    {
      "epoch": 2.4961119751166407,
      "grad_norm": 0.0007541918894276023,
      "learning_rate": 2.778684983583895e-05,
      "loss": 0.0001,
      "step": 12840
    },
    {
      "epoch": 2.4980559875583204,
      "grad_norm": 0.0014009621227160096,
      "learning_rate": 2.7782529808190774e-05,
      "loss": 0.0002,
      "step": 12850
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.0008721538470126688,
      "learning_rate": 2.7778209780542595e-05,
      "loss": 0.0001,
      "step": 12860
    },
    {
      "epoch": 2.5019440124416796,
      "grad_norm": 0.002657137578353286,
      "learning_rate": 2.777388975289442e-05,
      "loss": 0.0001,
      "step": 12870
    },
    {
      "epoch": 2.5038880248833593,
      "grad_norm": 0.0028832212556153536,
      "learning_rate": 2.7769569725246243e-05,
      "loss": 0.0024,
      "step": 12880
    },
    {
      "epoch": 2.505832037325039,
      "grad_norm": 0.001609756494872272,
      "learning_rate": 2.7765249697598064e-05,
      "loss": 0.0003,
      "step": 12890
    },
    {
      "epoch": 2.5077760497667185,
      "grad_norm": 3.4968957901000977,
      "learning_rate": 2.7760929669949888e-05,
      "loss": 0.018,
      "step": 12900
    },
    {
      "epoch": 2.509720062208398,
      "grad_norm": 0.000705594546161592,
      "learning_rate": 2.7756609642301712e-05,
      "loss": 0.0,
      "step": 12910
    },
    {
      "epoch": 2.511664074650078,
      "grad_norm": 0.001463865744881332,
      "learning_rate": 2.7752289614653536e-05,
      "loss": 0.0117,
      "step": 12920
    },
    {
      "epoch": 2.5136080870917574,
      "grad_norm": 0.0005763486842624843,
      "learning_rate": 2.7747969587005357e-05,
      "loss": 0.0,
      "step": 12930
    },
    {
      "epoch": 2.515552099533437,
      "grad_norm": 0.001135059748776257,
      "learning_rate": 2.774364955935718e-05,
      "loss": 0.0105,
      "step": 12940
    },
    {
      "epoch": 2.5174961119751167,
      "grad_norm": 0.0021708926651626825,
      "learning_rate": 2.7739329531709005e-05,
      "loss": 0.0114,
      "step": 12950
    },
    {
      "epoch": 2.5194401244167963,
      "grad_norm": 0.0011323445942252874,
      "learning_rate": 2.7735009504060826e-05,
      "loss": 0.0069,
      "step": 12960
    },
    {
      "epoch": 2.521384136858476,
      "grad_norm": 0.000743710610549897,
      "learning_rate": 2.773068947641265e-05,
      "loss": 0.0243,
      "step": 12970
    },
    {
      "epoch": 2.5233281493001556,
      "grad_norm": 2.465834617614746,
      "learning_rate": 2.7726369448764474e-05,
      "loss": 0.0002,
      "step": 12980
    },
    {
      "epoch": 2.525272161741835,
      "grad_norm": 0.0005758673651143909,
      "learning_rate": 2.7722049421116295e-05,
      "loss": 0.0012,
      "step": 12990
    },
    {
      "epoch": 2.527216174183515,
      "grad_norm": 0.0007528663845732808,
      "learning_rate": 2.771772939346812e-05,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 2.5291601866251945,
      "grad_norm": 0.000874036573804915,
      "learning_rate": 2.7713409365819943e-05,
      "loss": 0.0266,
      "step": 13010
    },
    {
      "epoch": 2.531104199066874,
      "grad_norm": 0.0006905011250637472,
      "learning_rate": 2.7709089338171763e-05,
      "loss": 0.0,
      "step": 13020
    },
    {
      "epoch": 2.5330482115085537,
      "grad_norm": 0.0011327891843393445,
      "learning_rate": 2.7704769310523588e-05,
      "loss": 0.0001,
      "step": 13030
    },
    {
      "epoch": 2.5349922239502334,
      "grad_norm": 0.0007803445332683623,
      "learning_rate": 2.7700449282875412e-05,
      "loss": 0.0006,
      "step": 13040
    },
    {
      "epoch": 2.536936236391913,
      "grad_norm": 0.0007502756780013442,
      "learning_rate": 2.7696129255227232e-05,
      "loss": 0.0,
      "step": 13050
    },
    {
      "epoch": 2.5388802488335926,
      "grad_norm": 0.0005280965124256909,
      "learning_rate": 2.7691809227579057e-05,
      "loss": 0.001,
      "step": 13060
    },
    {
      "epoch": 2.5408242612752723,
      "grad_norm": 0.000741523050237447,
      "learning_rate": 2.768748919993088e-05,
      "loss": 0.0,
      "step": 13070
    },
    {
      "epoch": 2.542768273716952,
      "grad_norm": 0.0009535193676128983,
      "learning_rate": 2.76831691722827e-05,
      "loss": 0.0001,
      "step": 13080
    },
    {
      "epoch": 2.5447122861586315,
      "grad_norm": 0.0007173660560511053,
      "learning_rate": 2.7678849144634525e-05,
      "loss": 0.0,
      "step": 13090
    },
    {
      "epoch": 2.546656298600311,
      "grad_norm": 0.0006806051242165267,
      "learning_rate": 2.767452911698635e-05,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 2.548600311041991,
      "grad_norm": 0.0005082591087557375,
      "learning_rate": 2.767020908933817e-05,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 2.5505443234836704,
      "grad_norm": 0.0007668600883334875,
      "learning_rate": 2.7665889061689998e-05,
      "loss": 0.0,
      "step": 13120
    },
    {
      "epoch": 2.55248833592535,
      "grad_norm": 0.0005803759559057653,
      "learning_rate": 2.766156903404182e-05,
      "loss": 0.0,
      "step": 13130
    },
    {
      "epoch": 2.5544323483670297,
      "grad_norm": 0.0005074408836662769,
      "learning_rate": 2.765724900639364e-05,
      "loss": 0.0001,
      "step": 13140
    },
    {
      "epoch": 2.5563763608087093,
      "grad_norm": 0.0006613074219785631,
      "learning_rate": 2.7652928978745467e-05,
      "loss": 0.0052,
      "step": 13150
    },
    {
      "epoch": 2.558320373250389,
      "grad_norm": 8.341833114624023,
      "learning_rate": 2.7648608951097287e-05,
      "loss": 0.0287,
      "step": 13160
    },
    {
      "epoch": 2.5602643856920686,
      "grad_norm": 0.0006804631557315588,
      "learning_rate": 2.7644288923449108e-05,
      "loss": 0.0003,
      "step": 13170
    },
    {
      "epoch": 2.5622083981337482,
      "grad_norm": 0.0005893999477848411,
      "learning_rate": 2.7639968895800936e-05,
      "loss": 0.0,
      "step": 13180
    },
    {
      "epoch": 2.564152410575428,
      "grad_norm": 0.0007363933837041259,
      "learning_rate": 2.7635648868152756e-05,
      "loss": 0.0,
      "step": 13190
    },
    {
      "epoch": 2.5660964230171075,
      "grad_norm": 0.000635539588984102,
      "learning_rate": 2.7631328840504577e-05,
      "loss": 0.0003,
      "step": 13200
    },
    {
      "epoch": 2.568040435458787,
      "grad_norm": 0.007281692232936621,
      "learning_rate": 2.7627008812856405e-05,
      "loss": 0.0,
      "step": 13210
    },
    {
      "epoch": 2.5699844479004668,
      "grad_norm": 0.0004812142578884959,
      "learning_rate": 2.7622688785208225e-05,
      "loss": 0.0,
      "step": 13220
    },
    {
      "epoch": 2.5719284603421464,
      "grad_norm": 0.0006382415303960443,
      "learning_rate": 2.7618368757560046e-05,
      "loss": 0.0047,
      "step": 13230
    },
    {
      "epoch": 2.573872472783826,
      "grad_norm": 0.0005196962738409638,
      "learning_rate": 2.7614048729911874e-05,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 2.5758164852255057,
      "grad_norm": 0.0488467663526535,
      "learning_rate": 2.7609728702263694e-05,
      "loss": 0.0116,
      "step": 13250
    },
    {
      "epoch": 2.5777604976671853,
      "grad_norm": 0.00048656476428732276,
      "learning_rate": 2.760540867461552e-05,
      "loss": 0.0002,
      "step": 13260
    },
    {
      "epoch": 2.579704510108865,
      "grad_norm": 0.00048064542352221906,
      "learning_rate": 2.7601088646967343e-05,
      "loss": 0.0024,
      "step": 13270
    },
    {
      "epoch": 2.5816485225505446,
      "grad_norm": 0.0008847338031046093,
      "learning_rate": 2.7596768619319163e-05,
      "loss": 0.0042,
      "step": 13280
    },
    {
      "epoch": 2.583592534992224,
      "grad_norm": 0.0004068541165906936,
      "learning_rate": 2.7592448591670987e-05,
      "loss": 0.0096,
      "step": 13290
    },
    {
      "epoch": 2.585536547433904,
      "grad_norm": 0.00048320647329092026,
      "learning_rate": 2.758812856402281e-05,
      "loss": 0.0005,
      "step": 13300
    },
    {
      "epoch": 2.5874805598755835,
      "grad_norm": 0.0006129294633865356,
      "learning_rate": 2.7583808536374632e-05,
      "loss": 0.0,
      "step": 13310
    },
    {
      "epoch": 2.589424572317263,
      "grad_norm": 0.00045749114360660315,
      "learning_rate": 2.757948850872646e-05,
      "loss": 0.0011,
      "step": 13320
    },
    {
      "epoch": 2.5913685847589427,
      "grad_norm": 0.00044158915989100933,
      "learning_rate": 2.757516848107828e-05,
      "loss": 0.0116,
      "step": 13330
    },
    {
      "epoch": 2.5933125972006223,
      "grad_norm": 0.0005084671429358423,
      "learning_rate": 2.75708484534301e-05,
      "loss": 0.0,
      "step": 13340
    },
    {
      "epoch": 2.595256609642302,
      "grad_norm": 0.0005332744913175702,
      "learning_rate": 2.756652842578193e-05,
      "loss": 0.0002,
      "step": 13350
    },
    {
      "epoch": 2.5972006220839816,
      "grad_norm": 0.00048268307000398636,
      "learning_rate": 2.756220839813375e-05,
      "loss": 0.0,
      "step": 13360
    },
    {
      "epoch": 2.599144634525661,
      "grad_norm": 0.0005463861161842942,
      "learning_rate": 2.755788837048557e-05,
      "loss": 0.006,
      "step": 13370
    },
    {
      "epoch": 2.6010886469673404,
      "grad_norm": 0.000598618877120316,
      "learning_rate": 2.7553568342837398e-05,
      "loss": 0.0,
      "step": 13380
    },
    {
      "epoch": 2.60303265940902,
      "grad_norm": 0.0007936781621538103,
      "learning_rate": 2.754924831518922e-05,
      "loss": 0.0005,
      "step": 13390
    },
    {
      "epoch": 2.6049766718506997,
      "grad_norm": 0.0006327600567601621,
      "learning_rate": 2.754492828754104e-05,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 2.6069206842923793,
      "grad_norm": 0.00043199610081501305,
      "learning_rate": 2.7540608259892867e-05,
      "loss": 0.0021,
      "step": 13410
    },
    {
      "epoch": 2.608864696734059,
      "grad_norm": 0.0004486056277528405,
      "learning_rate": 2.7536288232244687e-05,
      "loss": 0.0,
      "step": 13420
    },
    {
      "epoch": 2.6108087091757386,
      "grad_norm": 0.0004481444484554231,
      "learning_rate": 2.7531968204596508e-05,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 2.6127527216174182,
      "grad_norm": 0.00049392762593925,
      "learning_rate": 2.7527648176948335e-05,
      "loss": 0.0,
      "step": 13440
    },
    {
      "epoch": 2.614696734059098,
      "grad_norm": 0.0004270694334991276,
      "learning_rate": 2.7523328149300156e-05,
      "loss": 0.0,
      "step": 13450
    },
    {
      "epoch": 2.6166407465007775,
      "grad_norm": 0.0010546788107603788,
      "learning_rate": 2.7519008121651977e-05,
      "loss": 0.0157,
      "step": 13460
    },
    {
      "epoch": 2.618584758942457,
      "grad_norm": 0.0007115114131011069,
      "learning_rate": 2.7514688094003804e-05,
      "loss": 0.0,
      "step": 13470
    },
    {
      "epoch": 2.6205287713841368,
      "grad_norm": 0.0006298908847384155,
      "learning_rate": 2.7510368066355625e-05,
      "loss": 0.0028,
      "step": 13480
    },
    {
      "epoch": 2.6224727838258164,
      "grad_norm": 0.0007762056775391102,
      "learning_rate": 2.7506048038707446e-05,
      "loss": 0.0,
      "step": 13490
    },
    {
      "epoch": 2.624416796267496,
      "grad_norm": 0.0004266305186320096,
      "learning_rate": 2.7501728011059273e-05,
      "loss": 0.0009,
      "step": 13500
    },
    {
      "epoch": 2.6263608087091757,
      "grad_norm": 0.00044578369124792516,
      "learning_rate": 2.7497407983411094e-05,
      "loss": 0.0,
      "step": 13510
    },
    {
      "epoch": 2.6283048211508553,
      "grad_norm": 0.00040211417945101857,
      "learning_rate": 2.7493087955762918e-05,
      "loss": 0.0031,
      "step": 13520
    },
    {
      "epoch": 2.630248833592535,
      "grad_norm": 0.0004052119911648333,
      "learning_rate": 2.7488767928114742e-05,
      "loss": 0.0,
      "step": 13530
    },
    {
      "epoch": 2.6321928460342146,
      "grad_norm": 0.0003880400618072599,
      "learning_rate": 2.7484447900466563e-05,
      "loss": 0.0,
      "step": 13540
    },
    {
      "epoch": 2.634136858475894,
      "grad_norm": 0.0007715712417848408,
      "learning_rate": 2.7480127872818387e-05,
      "loss": 0.0652,
      "step": 13550
    },
    {
      "epoch": 2.636080870917574,
      "grad_norm": 14.935962677001953,
      "learning_rate": 2.747580784517021e-05,
      "loss": 0.0037,
      "step": 13560
    },
    {
      "epoch": 2.6380248833592534,
      "grad_norm": 0.007958016358315945,
      "learning_rate": 2.7471487817522032e-05,
      "loss": 0.012,
      "step": 13570
    },
    {
      "epoch": 2.639968895800933,
      "grad_norm": 0.005296021234244108,
      "learning_rate": 2.7467167789873856e-05,
      "loss": 0.0774,
      "step": 13580
    },
    {
      "epoch": 2.6419129082426127,
      "grad_norm": 0.002962654922157526,
      "learning_rate": 2.746284776222568e-05,
      "loss": 0.0003,
      "step": 13590
    },
    {
      "epoch": 2.6438569206842923,
      "grad_norm": 0.006802716292440891,
      "learning_rate": 2.74585277345775e-05,
      "loss": 0.0014,
      "step": 13600
    },
    {
      "epoch": 2.645800933125972,
      "grad_norm": 0.006822958588600159,
      "learning_rate": 2.7454207706929325e-05,
      "loss": 0.0161,
      "step": 13610
    },
    {
      "epoch": 2.6477449455676516,
      "grad_norm": 0.027933118864893913,
      "learning_rate": 2.744988767928115e-05,
      "loss": 0.0002,
      "step": 13620
    },
    {
      "epoch": 2.6496889580093312,
      "grad_norm": 0.0030090350192040205,
      "learning_rate": 2.744556765163297e-05,
      "loss": 0.0061,
      "step": 13630
    },
    {
      "epoch": 2.651632970451011,
      "grad_norm": 0.0031424190383404493,
      "learning_rate": 2.7441247623984794e-05,
      "loss": 0.0002,
      "step": 13640
    },
    {
      "epoch": 2.6535769828926905,
      "grad_norm": 0.001717949635349214,
      "learning_rate": 2.7436927596336618e-05,
      "loss": 0.0001,
      "step": 13650
    },
    {
      "epoch": 2.65552099533437,
      "grad_norm": 0.001988660776987672,
      "learning_rate": 2.743260756868844e-05,
      "loss": 0.0377,
      "step": 13660
    },
    {
      "epoch": 2.6574650077760498,
      "grad_norm": 0.004085340071469545,
      "learning_rate": 2.7428287541040263e-05,
      "loss": 0.0004,
      "step": 13670
    },
    {
      "epoch": 2.6594090202177294,
      "grad_norm": 0.0073591782711446285,
      "learning_rate": 2.7423967513392087e-05,
      "loss": 0.0198,
      "step": 13680
    },
    {
      "epoch": 2.661353032659409,
      "grad_norm": 0.0015693573513999581,
      "learning_rate": 2.741964748574391e-05,
      "loss": 0.0001,
      "step": 13690
    },
    {
      "epoch": 2.6632970451010887,
      "grad_norm": 0.0033376303035765886,
      "learning_rate": 2.7415327458095732e-05,
      "loss": 0.0322,
      "step": 13700
    },
    {
      "epoch": 2.6652410575427683,
      "grad_norm": 0.011647652834653854,
      "learning_rate": 2.7411007430447556e-05,
      "loss": 0.0345,
      "step": 13710
    },
    {
      "epoch": 2.667185069984448,
      "grad_norm": 0.0023728646337985992,
      "learning_rate": 2.740668740279938e-05,
      "loss": 0.0005,
      "step": 13720
    },
    {
      "epoch": 2.6691290824261276,
      "grad_norm": 0.008379158563911915,
      "learning_rate": 2.74023673751512e-05,
      "loss": 0.0003,
      "step": 13730
    },
    {
      "epoch": 2.671073094867807,
      "grad_norm": 13.759020805358887,
      "learning_rate": 2.7398047347503025e-05,
      "loss": 0.0015,
      "step": 13740
    },
    {
      "epoch": 2.673017107309487,
      "grad_norm": 0.002875436097383499,
      "learning_rate": 2.739372731985485e-05,
      "loss": 0.0218,
      "step": 13750
    },
    {
      "epoch": 2.6749611197511665,
      "grad_norm": 0.021687382832169533,
      "learning_rate": 2.738940729220667e-05,
      "loss": 0.0044,
      "step": 13760
    },
    {
      "epoch": 2.676905132192846,
      "grad_norm": 0.02536921389400959,
      "learning_rate": 2.7385087264558494e-05,
      "loss": 0.0006,
      "step": 13770
    },
    {
      "epoch": 2.6788491446345257,
      "grad_norm": 0.0113889891654253,
      "learning_rate": 2.7380767236910318e-05,
      "loss": 0.0003,
      "step": 13780
    },
    {
      "epoch": 2.6807931570762054,
      "grad_norm": 0.0012373238569125533,
      "learning_rate": 2.737644720926214e-05,
      "loss": 0.0002,
      "step": 13790
    },
    {
      "epoch": 2.682737169517885,
      "grad_norm": 0.04669653996825218,
      "learning_rate": 2.7372127181613963e-05,
      "loss": 0.0049,
      "step": 13800
    },
    {
      "epoch": 2.6846811819595646,
      "grad_norm": 0.00839145202189684,
      "learning_rate": 2.7367807153965787e-05,
      "loss": 0.0059,
      "step": 13810
    },
    {
      "epoch": 2.6866251944012443,
      "grad_norm": 0.03788343816995621,
      "learning_rate": 2.7363487126317608e-05,
      "loss": 0.0519,
      "step": 13820
    },
    {
      "epoch": 2.688569206842924,
      "grad_norm": 0.0028941829223185778,
      "learning_rate": 2.7359167098669432e-05,
      "loss": 0.0012,
      "step": 13830
    },
    {
      "epoch": 2.6905132192846035,
      "grad_norm": 0.0013182510156184435,
      "learning_rate": 2.7354847071021256e-05,
      "loss": 0.0004,
      "step": 13840
    },
    {
      "epoch": 2.692457231726283,
      "grad_norm": 0.0014234986156225204,
      "learning_rate": 2.7350527043373077e-05,
      "loss": 0.0001,
      "step": 13850
    },
    {
      "epoch": 2.694401244167963,
      "grad_norm": 0.027090344578027725,
      "learning_rate": 2.73462070157249e-05,
      "loss": 0.0001,
      "step": 13860
    },
    {
      "epoch": 2.6963452566096424,
      "grad_norm": 0.0013737359549850225,
      "learning_rate": 2.7341886988076725e-05,
      "loss": 0.0001,
      "step": 13870
    },
    {
      "epoch": 2.698289269051322,
      "grad_norm": 0.0009326313738711178,
      "learning_rate": 2.7337566960428546e-05,
      "loss": 0.0001,
      "step": 13880
    },
    {
      "epoch": 2.7002332814930017,
      "grad_norm": 0.0009075346169993281,
      "learning_rate": 2.7333246932780373e-05,
      "loss": 0.0016,
      "step": 13890
    },
    {
      "epoch": 2.7021772939346813,
      "grad_norm": 0.0008535095839761198,
      "learning_rate": 2.7328926905132194e-05,
      "loss": 0.0001,
      "step": 13900
    },
    {
      "epoch": 2.704121306376361,
      "grad_norm": 0.0009541657636873424,
      "learning_rate": 2.7324606877484014e-05,
      "loss": 0.0047,
      "step": 13910
    },
    {
      "epoch": 2.7060653188180406,
      "grad_norm": 0.0007977483328431845,
      "learning_rate": 2.7320286849835842e-05,
      "loss": 0.005,
      "step": 13920
    },
    {
      "epoch": 2.70800933125972,
      "grad_norm": 0.0011885813437402248,
      "learning_rate": 2.7315966822187663e-05,
      "loss": 0.0001,
      "step": 13930
    },
    {
      "epoch": 2.7099533437014,
      "grad_norm": 0.0007595171919092536,
      "learning_rate": 2.7311646794539483e-05,
      "loss": 0.0066,
      "step": 13940
    },
    {
      "epoch": 2.7118973561430795,
      "grad_norm": 0.0047095888294279575,
      "learning_rate": 2.730732676689131e-05,
      "loss": 0.0003,
      "step": 13950
    },
    {
      "epoch": 2.713841368584759,
      "grad_norm": 0.0033689714036881924,
      "learning_rate": 2.730300673924313e-05,
      "loss": 0.0009,
      "step": 13960
    },
    {
      "epoch": 2.7157853810264383,
      "grad_norm": 0.0005142369773238897,
      "learning_rate": 2.7298686711594952e-05,
      "loss": 0.0019,
      "step": 13970
    },
    {
      "epoch": 2.717729393468118,
      "grad_norm": 0.0005661284667439759,
      "learning_rate": 2.729436668394678e-05,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 2.7196734059097976,
      "grad_norm": 23.970685958862305,
      "learning_rate": 2.72900466562986e-05,
      "loss": 0.0212,
      "step": 13990
    },
    {
      "epoch": 2.721617418351477,
      "grad_norm": 8.228215217590332,
      "learning_rate": 2.728572662865042e-05,
      "loss": 0.0191,
      "step": 14000
    },
    {
      "epoch": 2.723561430793157,
      "grad_norm": 0.0008016114006750286,
      "learning_rate": 2.728140660100225e-05,
      "loss": 0.0195,
      "step": 14010
    },
    {
      "epoch": 2.7255054432348365,
      "grad_norm": 0.0025419793091714382,
      "learning_rate": 2.727708657335407e-05,
      "loss": 0.0004,
      "step": 14020
    },
    {
      "epoch": 2.727449455676516,
      "grad_norm": 0.0009768184972926974,
      "learning_rate": 2.727276654570589e-05,
      "loss": 0.0236,
      "step": 14030
    },
    {
      "epoch": 2.7293934681181957,
      "grad_norm": 0.0016797282733023167,
      "learning_rate": 2.7268446518057718e-05,
      "loss": 0.0008,
      "step": 14040
    },
    {
      "epoch": 2.7313374805598754,
      "grad_norm": 0.0014780414057895541,
      "learning_rate": 2.726412649040954e-05,
      "loss": 0.0158,
      "step": 14050
    },
    {
      "epoch": 2.733281493001555,
      "grad_norm": 0.0010615041246637702,
      "learning_rate": 2.725980646276136e-05,
      "loss": 0.0127,
      "step": 14060
    },
    {
      "epoch": 2.7352255054432346,
      "grad_norm": 0.0009521336178295314,
      "learning_rate": 2.7255486435113187e-05,
      "loss": 0.0047,
      "step": 14070
    },
    {
      "epoch": 2.7371695178849142,
      "grad_norm": 0.0007355589768849313,
      "learning_rate": 2.7251166407465007e-05,
      "loss": 0.0001,
      "step": 14080
    },
    {
      "epoch": 2.739113530326594,
      "grad_norm": 0.0012342658592388034,
      "learning_rate": 2.724684637981683e-05,
      "loss": 0.002,
      "step": 14090
    },
    {
      "epoch": 2.7410575427682735,
      "grad_norm": 0.0013453944120556116,
      "learning_rate": 2.7242526352168656e-05,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 2.743001555209953,
      "grad_norm": 0.0006602790090255439,
      "learning_rate": 2.7238206324520476e-05,
      "loss": 0.0344,
      "step": 14110
    },
    {
      "epoch": 2.744945567651633,
      "grad_norm": 0.009713885374367237,
      "learning_rate": 2.72338862968723e-05,
      "loss": 0.0159,
      "step": 14120
    },
    {
      "epoch": 2.7468895800933124,
      "grad_norm": 58.04640197753906,
      "learning_rate": 2.7229566269224125e-05,
      "loss": 0.0052,
      "step": 14130
    },
    {
      "epoch": 2.748833592534992,
      "grad_norm": 0.006072379183024168,
      "learning_rate": 2.7225246241575945e-05,
      "loss": 0.0014,
      "step": 14140
    },
    {
      "epoch": 2.7507776049766717,
      "grad_norm": 0.001883101649582386,
      "learning_rate": 2.7220926213927773e-05,
      "loss": 0.0002,
      "step": 14150
    },
    {
      "epoch": 2.7527216174183513,
      "grad_norm": 0.0015608638059347868,
      "learning_rate": 2.7216606186279594e-05,
      "loss": 0.0001,
      "step": 14160
    },
    {
      "epoch": 2.754665629860031,
      "grad_norm": 0.00120679778046906,
      "learning_rate": 2.7212286158631414e-05,
      "loss": 0.0001,
      "step": 14170
    },
    {
      "epoch": 2.7566096423017106,
      "grad_norm": 0.0011514899088069797,
      "learning_rate": 2.7207966130983242e-05,
      "loss": 0.0001,
      "step": 14180
    },
    {
      "epoch": 2.75855365474339,
      "grad_norm": 0.0011017585638910532,
      "learning_rate": 2.7203646103335062e-05,
      "loss": 0.0048,
      "step": 14190
    },
    {
      "epoch": 2.76049766718507,
      "grad_norm": 0.0010298104025423527,
      "learning_rate": 2.7199326075686883e-05,
      "loss": 0.0001,
      "step": 14200
    },
    {
      "epoch": 2.7624416796267495,
      "grad_norm": 0.0012849457561969757,
      "learning_rate": 2.719500604803871e-05,
      "loss": 0.0191,
      "step": 14210
    },
    {
      "epoch": 2.764385692068429,
      "grad_norm": 0.015647683292627335,
      "learning_rate": 2.719068602039053e-05,
      "loss": 0.0057,
      "step": 14220
    },
    {
      "epoch": 2.7663297045101087,
      "grad_norm": 0.001576524693518877,
      "learning_rate": 2.7186365992742352e-05,
      "loss": 0.0205,
      "step": 14230
    },
    {
      "epoch": 2.7682737169517884,
      "grad_norm": 0.013905685395002365,
      "learning_rate": 2.718204596509418e-05,
      "loss": 0.0171,
      "step": 14240
    },
    {
      "epoch": 2.770217729393468,
      "grad_norm": 0.010471455752849579,
      "learning_rate": 2.7177725937446e-05,
      "loss": 0.001,
      "step": 14250
    },
    {
      "epoch": 2.7721617418351476,
      "grad_norm": 0.0022633452899754047,
      "learning_rate": 2.717340590979782e-05,
      "loss": 0.0002,
      "step": 14260
    },
    {
      "epoch": 2.7741057542768273,
      "grad_norm": 0.009491413831710815,
      "learning_rate": 2.716908588214965e-05,
      "loss": 0.0106,
      "step": 14270
    },
    {
      "epoch": 2.776049766718507,
      "grad_norm": 0.0022042258642613888,
      "learning_rate": 2.716476585450147e-05,
      "loss": 0.0163,
      "step": 14280
    },
    {
      "epoch": 2.7779937791601865,
      "grad_norm": 0.0016433406854048371,
      "learning_rate": 2.7160445826853293e-05,
      "loss": 0.0003,
      "step": 14290
    },
    {
      "epoch": 2.779937791601866,
      "grad_norm": 0.003551690373569727,
      "learning_rate": 2.7156125799205118e-05,
      "loss": 0.0001,
      "step": 14300
    },
    {
      "epoch": 2.781881804043546,
      "grad_norm": 0.0013712719082832336,
      "learning_rate": 2.7151805771556938e-05,
      "loss": 0.0001,
      "step": 14310
    },
    {
      "epoch": 2.7838258164852254,
      "grad_norm": 0.004939990118145943,
      "learning_rate": 2.7147485743908762e-05,
      "loss": 0.0001,
      "step": 14320
    },
    {
      "epoch": 2.785769828926905,
      "grad_norm": 0.1291412115097046,
      "learning_rate": 2.7143165716260586e-05,
      "loss": 0.0006,
      "step": 14330
    },
    {
      "epoch": 2.7877138413685847,
      "grad_norm": 0.001278116600587964,
      "learning_rate": 2.7138845688612407e-05,
      "loss": 0.0005,
      "step": 14340
    },
    {
      "epoch": 2.7896578538102643,
      "grad_norm": 0.000923122453968972,
      "learning_rate": 2.713452566096423e-05,
      "loss": 0.0001,
      "step": 14350
    },
    {
      "epoch": 2.791601866251944,
      "grad_norm": 0.0009269981528632343,
      "learning_rate": 2.7130205633316055e-05,
      "loss": 0.0001,
      "step": 14360
    },
    {
      "epoch": 2.7935458786936236,
      "grad_norm": 0.0011168437777087092,
      "learning_rate": 2.7125885605667876e-05,
      "loss": 0.0032,
      "step": 14370
    },
    {
      "epoch": 2.795489891135303,
      "grad_norm": 0.0008372382144443691,
      "learning_rate": 2.71215655780197e-05,
      "loss": 0.0276,
      "step": 14380
    },
    {
      "epoch": 2.797433903576983,
      "grad_norm": 0.0008115597302094102,
      "learning_rate": 2.7117245550371524e-05,
      "loss": 0.0013,
      "step": 14390
    },
    {
      "epoch": 2.7993779160186625,
      "grad_norm": 0.0010412291157990694,
      "learning_rate": 2.7112925522723345e-05,
      "loss": 0.0001,
      "step": 14400
    },
    {
      "epoch": 2.801321928460342,
      "grad_norm": 0.22111761569976807,
      "learning_rate": 2.710860549507517e-05,
      "loss": 0.0112,
      "step": 14410
    },
    {
      "epoch": 2.8032659409020217,
      "grad_norm": 0.0009457672713324428,
      "learning_rate": 2.7104285467426993e-05,
      "loss": 0.0083,
      "step": 14420
    },
    {
      "epoch": 2.8052099533437014,
      "grad_norm": 0.0009292757604271173,
      "learning_rate": 2.7099965439778814e-05,
      "loss": 0.0038,
      "step": 14430
    },
    {
      "epoch": 2.807153965785381,
      "grad_norm": 0.0011404065880924463,
      "learning_rate": 2.7095645412130638e-05,
      "loss": 0.0001,
      "step": 14440
    },
    {
      "epoch": 2.8090979782270606,
      "grad_norm": 0.0007901473436504602,
      "learning_rate": 2.7091325384482462e-05,
      "loss": 0.0142,
      "step": 14450
    },
    {
      "epoch": 2.8110419906687403,
      "grad_norm": 0.0057134670205414295,
      "learning_rate": 2.7087005356834283e-05,
      "loss": 0.0227,
      "step": 14460
    },
    {
      "epoch": 2.81298600311042,
      "grad_norm": 0.006453216541558504,
      "learning_rate": 2.7082685329186107e-05,
      "loss": 0.0002,
      "step": 14470
    },
    {
      "epoch": 2.8149300155520995,
      "grad_norm": 4.4130988121032715,
      "learning_rate": 2.707836530153793e-05,
      "loss": 0.0251,
      "step": 14480
    },
    {
      "epoch": 2.816874027993779,
      "grad_norm": 4.908254623413086,
      "learning_rate": 2.7074045273889755e-05,
      "loss": 0.0254,
      "step": 14490
    },
    {
      "epoch": 2.818818040435459,
      "grad_norm": 0.0012168223038315773,
      "learning_rate": 2.7069725246241576e-05,
      "loss": 0.0002,
      "step": 14500
    },
    {
      "epoch": 2.8207620528771384,
      "grad_norm": 6.472599506378174,
      "learning_rate": 2.70654052185934e-05,
      "loss": 0.0229,
      "step": 14510
    },
    {
      "epoch": 2.822706065318818,
      "grad_norm": 0.004518055357038975,
      "learning_rate": 2.7061085190945224e-05,
      "loss": 0.0001,
      "step": 14520
    },
    {
      "epoch": 2.8246500777604977,
      "grad_norm": 0.005502315238118172,
      "learning_rate": 2.7056765163297045e-05,
      "loss": 0.0001,
      "step": 14530
    },
    {
      "epoch": 2.8265940902021773,
      "grad_norm": 0.20651690661907196,
      "learning_rate": 2.705244513564887e-05,
      "loss": 0.0204,
      "step": 14540
    },
    {
      "epoch": 2.828538102643857,
      "grad_norm": 0.0010793264955282211,
      "learning_rate": 2.7048125108000693e-05,
      "loss": 0.0167,
      "step": 14550
    },
    {
      "epoch": 2.8304821150855366,
      "grad_norm": 0.0048254006542265415,
      "learning_rate": 2.7043805080352514e-05,
      "loss": 0.0016,
      "step": 14560
    },
    {
      "epoch": 2.8324261275272162,
      "grad_norm": 0.0006675589247606695,
      "learning_rate": 2.7039485052704338e-05,
      "loss": 0.0317,
      "step": 14570
    },
    {
      "epoch": 2.834370139968896,
      "grad_norm": 0.0011712942505255342,
      "learning_rate": 2.7035165025056162e-05,
      "loss": 0.0274,
      "step": 14580
    },
    {
      "epoch": 2.8363141524105755,
      "grad_norm": 0.0008480348624289036,
      "learning_rate": 2.7030844997407983e-05,
      "loss": 0.0002,
      "step": 14590
    },
    {
      "epoch": 2.838258164852255,
      "grad_norm": 0.00204905541613698,
      "learning_rate": 2.7026524969759807e-05,
      "loss": 0.0001,
      "step": 14600
    },
    {
      "epoch": 2.8402021772939348,
      "grad_norm": 0.0013349163345992565,
      "learning_rate": 2.702220494211163e-05,
      "loss": 0.0001,
      "step": 14610
    },
    {
      "epoch": 2.8421461897356144,
      "grad_norm": 0.0016536010662093759,
      "learning_rate": 2.7017884914463452e-05,
      "loss": 0.0001,
      "step": 14620
    },
    {
      "epoch": 2.844090202177294,
      "grad_norm": 0.0011888924054801464,
      "learning_rate": 2.7013564886815276e-05,
      "loss": 0.0001,
      "step": 14630
    },
    {
      "epoch": 2.8460342146189737,
      "grad_norm": 0.0007817888399586082,
      "learning_rate": 2.70092448591671e-05,
      "loss": 0.0004,
      "step": 14640
    },
    {
      "epoch": 2.8479782270606533,
      "grad_norm": 0.0008396326447837055,
      "learning_rate": 2.700492483151892e-05,
      "loss": 0.0001,
      "step": 14650
    },
    {
      "epoch": 2.849922239502333,
      "grad_norm": 0.0006793727516196668,
      "learning_rate": 2.7000604803870745e-05,
      "loss": 0.0045,
      "step": 14660
    },
    {
      "epoch": 2.8518662519440126,
      "grad_norm": 0.000693720648996532,
      "learning_rate": 2.699628477622257e-05,
      "loss": 0.0,
      "step": 14670
    },
    {
      "epoch": 2.853810264385692,
      "grad_norm": 0.0007296064286492765,
      "learning_rate": 2.699196474857439e-05,
      "loss": 0.0,
      "step": 14680
    },
    {
      "epoch": 2.855754276827372,
      "grad_norm": 0.0008431142196059227,
      "learning_rate": 2.6987644720926217e-05,
      "loss": 0.0001,
      "step": 14690
    },
    {
      "epoch": 2.8576982892690515,
      "grad_norm": 0.0008379052742384374,
      "learning_rate": 2.6983324693278038e-05,
      "loss": 0.0001,
      "step": 14700
    },
    {
      "epoch": 2.859642301710731,
      "grad_norm": 0.0015337869990617037,
      "learning_rate": 2.697900466562986e-05,
      "loss": 0.0165,
      "step": 14710
    },
    {
      "epoch": 2.8615863141524107,
      "grad_norm": 0.005206072237342596,
      "learning_rate": 2.6974684637981686e-05,
      "loss": 0.0008,
      "step": 14720
    },
    {
      "epoch": 2.8635303265940903,
      "grad_norm": 0.0012329872697591782,
      "learning_rate": 2.6970364610333507e-05,
      "loss": 0.0004,
      "step": 14730
    },
    {
      "epoch": 2.86547433903577,
      "grad_norm": 0.0019994033500552177,
      "learning_rate": 2.6966044582685328e-05,
      "loss": 0.0001,
      "step": 14740
    },
    {
      "epoch": 2.8674183514774496,
      "grad_norm": 0.0007483769441023469,
      "learning_rate": 2.6961724555037155e-05,
      "loss": 0.0001,
      "step": 14750
    },
    {
      "epoch": 2.8693623639191292,
      "grad_norm": 0.0007807768997736275,
      "learning_rate": 2.6957404527388976e-05,
      "loss": 0.0001,
      "step": 14760
    },
    {
      "epoch": 2.871306376360809,
      "grad_norm": 0.0013499446213245392,
      "learning_rate": 2.6953084499740796e-05,
      "loss": 0.0002,
      "step": 14770
    },
    {
      "epoch": 2.8732503888024885,
      "grad_norm": 0.01650851219892502,
      "learning_rate": 2.6948764472092624e-05,
      "loss": 0.0001,
      "step": 14780
    },
    {
      "epoch": 2.875194401244168,
      "grad_norm": 0.0005987696931697428,
      "learning_rate": 2.6944444444444445e-05,
      "loss": 0.0,
      "step": 14790
    },
    {
      "epoch": 2.8771384136858478,
      "grad_norm": 0.0011621636804193258,
      "learning_rate": 2.6940124416796265e-05,
      "loss": 0.0014,
      "step": 14800
    },
    {
      "epoch": 2.8790824261275274,
      "grad_norm": 0.0006580820772796869,
      "learning_rate": 2.6935804389148093e-05,
      "loss": 0.0001,
      "step": 14810
    },
    {
      "epoch": 2.881026438569207,
      "grad_norm": 0.000659975572489202,
      "learning_rate": 2.6931484361499914e-05,
      "loss": 0.0067,
      "step": 14820
    },
    {
      "epoch": 2.8829704510108867,
      "grad_norm": 0.0012812676141038537,
      "learning_rate": 2.6927164333851734e-05,
      "loss": 0.0001,
      "step": 14830
    },
    {
      "epoch": 2.8849144634525663,
      "grad_norm": 0.0020655193366110325,
      "learning_rate": 2.6922844306203562e-05,
      "loss": 0.0368,
      "step": 14840
    },
    {
      "epoch": 2.886858475894246,
      "grad_norm": 0.007879478856921196,
      "learning_rate": 2.6918524278555383e-05,
      "loss": 0.0002,
      "step": 14850
    },
    {
      "epoch": 2.8888024883359256,
      "grad_norm": 0.0034346894826740026,
      "learning_rate": 2.6914204250907207e-05,
      "loss": 0.0103,
      "step": 14860
    },
    {
      "epoch": 2.890746500777605,
      "grad_norm": 0.0027546605560928583,
      "learning_rate": 2.690988422325903e-05,
      "loss": 0.0002,
      "step": 14870
    },
    {
      "epoch": 2.892690513219285,
      "grad_norm": 0.0017650454537943006,
      "learning_rate": 2.690556419561085e-05,
      "loss": 0.0004,
      "step": 14880
    },
    {
      "epoch": 2.8946345256609645,
      "grad_norm": 0.0010455826995894313,
      "learning_rate": 2.6901244167962676e-05,
      "loss": 0.0001,
      "step": 14890
    },
    {
      "epoch": 2.896578538102644,
      "grad_norm": 0.001400803797878325,
      "learning_rate": 2.68969241403145e-05,
      "loss": 0.0001,
      "step": 14900
    },
    {
      "epoch": 2.8985225505443237,
      "grad_norm": 0.005893482360988855,
      "learning_rate": 2.689260411266632e-05,
      "loss": 0.0001,
      "step": 14910
    },
    {
      "epoch": 2.9004665629860034,
      "grad_norm": 0.02110395021736622,
      "learning_rate": 2.6888284085018145e-05,
      "loss": 0.0018,
      "step": 14920
    },
    {
      "epoch": 2.902410575427683,
      "grad_norm": 0.0013877005549147725,
      "learning_rate": 2.688396405736997e-05,
      "loss": 0.0001,
      "step": 14930
    },
    {
      "epoch": 2.9043545878693626,
      "grad_norm": 0.0009667170234024525,
      "learning_rate": 2.687964402972179e-05,
      "loss": 0.0001,
      "step": 14940
    },
    {
      "epoch": 2.9062986003110423,
      "grad_norm": 0.011193732731044292,
      "learning_rate": 2.6875324002073614e-05,
      "loss": 0.0001,
      "step": 14950
    },
    {
      "epoch": 2.908242612752722,
      "grad_norm": 0.0009268089779652655,
      "learning_rate": 2.6871003974425438e-05,
      "loss": 0.0002,
      "step": 14960
    },
    {
      "epoch": 2.910186625194401,
      "grad_norm": 0.0012447639601305127,
      "learning_rate": 2.686668394677726e-05,
      "loss": 0.0019,
      "step": 14970
    },
    {
      "epoch": 2.9121306376360807,
      "grad_norm": 0.0007522088126279414,
      "learning_rate": 2.6862363919129082e-05,
      "loss": 0.0201,
      "step": 14980
    },
    {
      "epoch": 2.9140746500777603,
      "grad_norm": 0.0006900072330608964,
      "learning_rate": 2.6858043891480907e-05,
      "loss": 0.0186,
      "step": 14990
    },
    {
      "epoch": 2.91601866251944,
      "grad_norm": 0.0016643914859741926,
      "learning_rate": 2.6853723863832727e-05,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 2.9179626749611196,
      "grad_norm": 0.0007997223292477429,
      "learning_rate": 2.684940383618455e-05,
      "loss": 0.0001,
      "step": 15010
    },
    {
      "epoch": 2.9199066874027992,
      "grad_norm": 4.227664947509766,
      "learning_rate": 2.6845083808536376e-05,
      "loss": 0.024,
      "step": 15020
    },
    {
      "epoch": 2.921850699844479,
      "grad_norm": 0.05127929523587227,
      "learning_rate": 2.6840763780888196e-05,
      "loss": 0.0001,
      "step": 15030
    },
    {
      "epoch": 2.9237947122861585,
      "grad_norm": 0.0008243443444371223,
      "learning_rate": 2.683644375324002e-05,
      "loss": 0.0,
      "step": 15040
    },
    {
      "epoch": 2.925738724727838,
      "grad_norm": 0.0006863028393127024,
      "learning_rate": 2.6832123725591844e-05,
      "loss": 0.0004,
      "step": 15050
    },
    {
      "epoch": 2.9276827371695178,
      "grad_norm": 31.30270004272461,
      "learning_rate": 2.682780369794367e-05,
      "loss": 0.0035,
      "step": 15060
    },
    {
      "epoch": 2.9296267496111974,
      "grad_norm": 0.0006603203364647925,
      "learning_rate": 2.6823483670295493e-05,
      "loss": 0.0002,
      "step": 15070
    },
    {
      "epoch": 2.931570762052877,
      "grad_norm": 0.0008697315352037549,
      "learning_rate": 2.6819163642647313e-05,
      "loss": 0.0214,
      "step": 15080
    },
    {
      "epoch": 2.9335147744945567,
      "grad_norm": 0.0005474392091855407,
      "learning_rate": 2.6814843614999138e-05,
      "loss": 0.0161,
      "step": 15090
    },
    {
      "epoch": 2.9354587869362363,
      "grad_norm": 0.0005807525594718754,
      "learning_rate": 2.681052358735096e-05,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 2.937402799377916,
      "grad_norm": 0.020390620455145836,
      "learning_rate": 2.6806203559702782e-05,
      "loss": 0.0132,
      "step": 15110
    },
    {
      "epoch": 2.9393468118195956,
      "grad_norm": 0.000672360067255795,
      "learning_rate": 2.6801883532054606e-05,
      "loss": 0.0979,
      "step": 15120
    },
    {
      "epoch": 2.941290824261275,
      "grad_norm": 0.0014421581290662289,
      "learning_rate": 2.679756350440643e-05,
      "loss": 0.0004,
      "step": 15130
    },
    {
      "epoch": 2.943234836702955,
      "grad_norm": 0.001038536080159247,
      "learning_rate": 2.679324347675825e-05,
      "loss": 0.0001,
      "step": 15140
    },
    {
      "epoch": 2.9451788491446345,
      "grad_norm": 0.0017320846673101187,
      "learning_rate": 2.6788923449110075e-05,
      "loss": 0.0158,
      "step": 15150
    },
    {
      "epoch": 2.947122861586314,
      "grad_norm": 0.0018774339696392417,
      "learning_rate": 2.67846034214619e-05,
      "loss": 0.0001,
      "step": 15160
    },
    {
      "epoch": 2.9490668740279937,
      "grad_norm": 0.0016798696015030146,
      "learning_rate": 2.678028339381372e-05,
      "loss": 0.0002,
      "step": 15170
    },
    {
      "epoch": 2.9510108864696734,
      "grad_norm": 0.0015919758006930351,
      "learning_rate": 2.6775963366165544e-05,
      "loss": 0.0001,
      "step": 15180
    },
    {
      "epoch": 2.952954898911353,
      "grad_norm": 5.952312469482422,
      "learning_rate": 2.677164333851737e-05,
      "loss": 0.0201,
      "step": 15190
    },
    {
      "epoch": 2.9548989113530326,
      "grad_norm": 0.02802225947380066,
      "learning_rate": 2.676732331086919e-05,
      "loss": 0.0006,
      "step": 15200
    },
    {
      "epoch": 2.9568429237947123,
      "grad_norm": 0.031111648306250572,
      "learning_rate": 2.6763003283221013e-05,
      "loss": 0.0297,
      "step": 15210
    },
    {
      "epoch": 2.958786936236392,
      "grad_norm": 0.008063606917858124,
      "learning_rate": 2.6758683255572837e-05,
      "loss": 0.0007,
      "step": 15220
    },
    {
      "epoch": 2.9607309486780715,
      "grad_norm": 0.0065582189708948135,
      "learning_rate": 2.6754363227924658e-05,
      "loss": 0.0002,
      "step": 15230
    },
    {
      "epoch": 2.962674961119751,
      "grad_norm": 0.0015000723069533706,
      "learning_rate": 2.6750043200276482e-05,
      "loss": 0.0001,
      "step": 15240
    },
    {
      "epoch": 2.964618973561431,
      "grad_norm": 0.0011449186131358147,
      "learning_rate": 2.6745723172628306e-05,
      "loss": 0.0002,
      "step": 15250
    },
    {
      "epoch": 2.9665629860031104,
      "grad_norm": 7.468949794769287,
      "learning_rate": 2.674140314498013e-05,
      "loss": 0.0192,
      "step": 15260
    },
    {
      "epoch": 2.96850699844479,
      "grad_norm": 0.0016201924299821258,
      "learning_rate": 2.673708311733195e-05,
      "loss": 0.0005,
      "step": 15270
    },
    {
      "epoch": 2.9704510108864697,
      "grad_norm": 0.003525442909449339,
      "learning_rate": 2.6732763089683775e-05,
      "loss": 0.0001,
      "step": 15280
    },
    {
      "epoch": 2.9723950233281493,
      "grad_norm": 0.0010564419208094478,
      "learning_rate": 2.67284430620356e-05,
      "loss": 0.0005,
      "step": 15290
    },
    {
      "epoch": 2.974339035769829,
      "grad_norm": 0.0007357153226621449,
      "learning_rate": 2.672412303438742e-05,
      "loss": 0.0016,
      "step": 15300
    },
    {
      "epoch": 2.9762830482115086,
      "grad_norm": 0.0011556296376511455,
      "learning_rate": 2.6719803006739244e-05,
      "loss": 0.0002,
      "step": 15310
    },
    {
      "epoch": 2.978227060653188,
      "grad_norm": 0.0012808619067072868,
      "learning_rate": 2.671548297909107e-05,
      "loss": 0.0002,
      "step": 15320
    },
    {
      "epoch": 2.980171073094868,
      "grad_norm": 0.02575511485338211,
      "learning_rate": 2.671116295144289e-05,
      "loss": 0.0002,
      "step": 15330
    },
    {
      "epoch": 2.9821150855365475,
      "grad_norm": 0.0006569791003130376,
      "learning_rate": 2.6706842923794713e-05,
      "loss": 0.0001,
      "step": 15340
    },
    {
      "epoch": 2.984059097978227,
      "grad_norm": 0.0008718058234080672,
      "learning_rate": 2.6702522896146537e-05,
      "loss": 0.0021,
      "step": 15350
    },
    {
      "epoch": 2.9860031104199067,
      "grad_norm": 0.0006833001389168203,
      "learning_rate": 2.6698202868498358e-05,
      "loss": 0.0,
      "step": 15360
    },
    {
      "epoch": 2.9879471228615864,
      "grad_norm": 0.0006080276798456907,
      "learning_rate": 2.6693882840850182e-05,
      "loss": 0.0,
      "step": 15370
    },
    {
      "epoch": 2.989891135303266,
      "grad_norm": 0.022756004706025124,
      "learning_rate": 2.6689562813202006e-05,
      "loss": 0.0001,
      "step": 15380
    },
    {
      "epoch": 2.9918351477449456,
      "grad_norm": 0.011971518397331238,
      "learning_rate": 2.6685242785553827e-05,
      "loss": 0.0001,
      "step": 15390
    },
    {
      "epoch": 2.9937791601866253,
      "grad_norm": 0.0006124072824604809,
      "learning_rate": 2.668092275790565e-05,
      "loss": 0.0001,
      "step": 15400
    },
    {
      "epoch": 2.995723172628305,
      "grad_norm": 0.0006731967441737652,
      "learning_rate": 2.6676602730257475e-05,
      "loss": 0.0,
      "step": 15410
    },
    {
      "epoch": 2.9976671850699845,
      "grad_norm": 0.0005111072096042335,
      "learning_rate": 2.6672282702609296e-05,
      "loss": 0.0,
      "step": 15420
    },
    {
      "epoch": 2.999611197511664,
      "grad_norm": 0.0005432896432466805,
      "learning_rate": 2.666796267496112e-05,
      "loss": 0.035,
      "step": 15430
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.9961207800377437,
      "eval_loss": 0.009071913547813892,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.9961207800377437,
          "precision": 0.9954945515507125,
          "recall": 0.9967477968946706,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.9961207800377437,
          "precision": 0.9954945515507125,
          "recall": 0.9967477968946706,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.9961207800377437,
          "precision": 0.9954945515507125,
          "recall": 0.9967477968946706,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9961207800377436,
          "precision": 0.9954945515507125,
          "recall": 0.9967477968946706,
          "support": 9532
        }
      },
      "eval_runtime": 71.6586,
      "eval_samples_per_second": 106.994,
      "eval_steps_per_second": 13.383,
      "step": 15432
    },
    {
      "epoch": 3.001555209953344,
      "grad_norm": 0.0006594199221581221,
      "learning_rate": 2.6663642647312944e-05,
      "loss": 0.0001,
      "step": 15440
    },
    {
      "epoch": 3.0034992223950234,
      "grad_norm": 0.0005148936179466546,
      "learning_rate": 2.6659322619664765e-05,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 3.005443234836703,
      "grad_norm": 0.0006483282195404172,
      "learning_rate": 2.6655002592016592e-05,
      "loss": 0.0,
      "step": 15460
    },
    {
      "epoch": 3.0073872472783827,
      "grad_norm": 0.0007392402039840817,
      "learning_rate": 2.6650682564368413e-05,
      "loss": 0.0001,
      "step": 15470
    },
    {
      "epoch": 3.0093312597200623,
      "grad_norm": 0.0005521713756024837,
      "learning_rate": 2.6646362536720234e-05,
      "loss": 0.0001,
      "step": 15480
    },
    {
      "epoch": 3.011275272161742,
      "grad_norm": 0.0029455465264618397,
      "learning_rate": 2.664204250907206e-05,
      "loss": 0.0183,
      "step": 15490
    },
    {
      "epoch": 3.0132192846034216,
      "grad_norm": 0.002434826223179698,
      "learning_rate": 2.6637722481423882e-05,
      "loss": 0.0002,
      "step": 15500
    },
    {
      "epoch": 3.015163297045101,
      "grad_norm": 0.0031352743972092867,
      "learning_rate": 2.6633402453775703e-05,
      "loss": 0.0002,
      "step": 15510
    },
    {
      "epoch": 3.017107309486781,
      "grad_norm": 0.0034522146452218294,
      "learning_rate": 2.662908242612753e-05,
      "loss": 0.0001,
      "step": 15520
    },
    {
      "epoch": 3.0190513219284605,
      "grad_norm": 0.0027496879920363426,
      "learning_rate": 2.662476239847935e-05,
      "loss": 0.0002,
      "step": 15530
    },
    {
      "epoch": 3.02099533437014,
      "grad_norm": 0.002648118883371353,
      "learning_rate": 2.6620442370831172e-05,
      "loss": 0.0156,
      "step": 15540
    },
    {
      "epoch": 3.0229393468118197,
      "grad_norm": 0.0026115025393664837,
      "learning_rate": 2.6616122343183e-05,
      "loss": 0.0001,
      "step": 15550
    },
    {
      "epoch": 3.0248833592534994,
      "grad_norm": 0.004341547843068838,
      "learning_rate": 2.661180231553482e-05,
      "loss": 0.0002,
      "step": 15560
    },
    {
      "epoch": 3.026827371695179,
      "grad_norm": 0.001483024563640356,
      "learning_rate": 2.660748228788664e-05,
      "loss": 0.0002,
      "step": 15570
    },
    {
      "epoch": 3.0287713841368586,
      "grad_norm": 0.00166797055862844,
      "learning_rate": 2.6603162260238468e-05,
      "loss": 0.0001,
      "step": 15580
    },
    {
      "epoch": 3.0307153965785383,
      "grad_norm": 0.0016882020281627774,
      "learning_rate": 2.659884223259029e-05,
      "loss": 0.0001,
      "step": 15590
    },
    {
      "epoch": 3.032659409020218,
      "grad_norm": 0.0036779253277927637,
      "learning_rate": 2.659452220494211e-05,
      "loss": 0.0001,
      "step": 15600
    },
    {
      "epoch": 3.0346034214618975,
      "grad_norm": 0.0007529291324317455,
      "learning_rate": 2.6590202177293937e-05,
      "loss": 0.0002,
      "step": 15610
    },
    {
      "epoch": 3.036547433903577,
      "grad_norm": 0.002033556578680873,
      "learning_rate": 2.6585882149645758e-05,
      "loss": 0.0001,
      "step": 15620
    },
    {
      "epoch": 3.038491446345257,
      "grad_norm": 0.0019122115336358547,
      "learning_rate": 2.658156212199758e-05,
      "loss": 0.0001,
      "step": 15630
    },
    {
      "epoch": 3.0404354587869364,
      "grad_norm": 0.0012949962401762605,
      "learning_rate": 2.6577242094349406e-05,
      "loss": 0.0009,
      "step": 15640
    },
    {
      "epoch": 3.042379471228616,
      "grad_norm": 0.0016938918270170689,
      "learning_rate": 2.6572922066701227e-05,
      "loss": 0.0001,
      "step": 15650
    },
    {
      "epoch": 3.0443234836702957,
      "grad_norm": 0.0010551537852734327,
      "learning_rate": 2.656860203905305e-05,
      "loss": 0.0032,
      "step": 15660
    },
    {
      "epoch": 3.046267496111975,
      "grad_norm": 0.001072192215360701,
      "learning_rate": 2.6564282011404875e-05,
      "loss": 0.0001,
      "step": 15670
    },
    {
      "epoch": 3.0482115085536545,
      "grad_norm": 0.0008247525547631085,
      "learning_rate": 2.6559961983756696e-05,
      "loss": 0.0215,
      "step": 15680
    },
    {
      "epoch": 3.050155520995334,
      "grad_norm": 0.004308045841753483,
      "learning_rate": 2.655564195610852e-05,
      "loss": 0.0003,
      "step": 15690
    },
    {
      "epoch": 3.052099533437014,
      "grad_norm": 0.07700945436954498,
      "learning_rate": 2.6551321928460344e-05,
      "loss": 0.0003,
      "step": 15700
    },
    {
      "epoch": 3.0540435458786934,
      "grad_norm": 0.0010173179907724261,
      "learning_rate": 2.6547001900812165e-05,
      "loss": 0.0002,
      "step": 15710
    },
    {
      "epoch": 3.055987558320373,
      "grad_norm": 0.08277516067028046,
      "learning_rate": 2.654268187316399e-05,
      "loss": 0.0002,
      "step": 15720
    },
    {
      "epoch": 3.0579315707620527,
      "grad_norm": 0.0010994699550792575,
      "learning_rate": 2.6538361845515813e-05,
      "loss": 0.0002,
      "step": 15730
    },
    {
      "epoch": 3.0598755832037323,
      "grad_norm": 0.0010042445501312613,
      "learning_rate": 2.6534041817867634e-05,
      "loss": 0.0001,
      "step": 15740
    },
    {
      "epoch": 3.061819595645412,
      "grad_norm": 0.0014743517385795712,
      "learning_rate": 2.6529721790219458e-05,
      "loss": 0.0001,
      "step": 15750
    },
    {
      "epoch": 3.0637636080870916,
      "grad_norm": 0.0012861863942816854,
      "learning_rate": 2.6525401762571282e-05,
      "loss": 0.0001,
      "step": 15760
    },
    {
      "epoch": 3.065707620528771,
      "grad_norm": 0.0005413983017206192,
      "learning_rate": 2.6521081734923103e-05,
      "loss": 0.0,
      "step": 15770
    },
    {
      "epoch": 3.067651632970451,
      "grad_norm": 0.00047241634456440806,
      "learning_rate": 2.6516761707274927e-05,
      "loss": 0.0001,
      "step": 15780
    },
    {
      "epoch": 3.0695956454121305,
      "grad_norm": 0.0007441220805048943,
      "learning_rate": 2.651244167962675e-05,
      "loss": 0.0001,
      "step": 15790
    },
    {
      "epoch": 3.07153965785381,
      "grad_norm": 0.0017564911395311356,
      "learning_rate": 2.650812165197857e-05,
      "loss": 0.0165,
      "step": 15800
    },
    {
      "epoch": 3.0734836702954897,
      "grad_norm": 0.0012135652359575033,
      "learning_rate": 2.6503801624330396e-05,
      "loss": 0.0001,
      "step": 15810
    },
    {
      "epoch": 3.0754276827371694,
      "grad_norm": 0.0006475562113337219,
      "learning_rate": 2.649948159668222e-05,
      "loss": 0.0001,
      "step": 15820
    },
    {
      "epoch": 3.077371695178849,
      "grad_norm": 0.0017987946048378944,
      "learning_rate": 2.649516156903404e-05,
      "loss": 0.0132,
      "step": 15830
    },
    {
      "epoch": 3.0793157076205286,
      "grad_norm": 0.009854498319327831,
      "learning_rate": 2.6490841541385865e-05,
      "loss": 0.0,
      "step": 15840
    },
    {
      "epoch": 3.0812597200622083,
      "grad_norm": 0.000655482173897326,
      "learning_rate": 2.648652151373769e-05,
      "loss": 0.0006,
      "step": 15850
    },
    {
      "epoch": 3.083203732503888,
      "grad_norm": 0.0006984244100749493,
      "learning_rate": 2.6482201486089513e-05,
      "loss": 0.0064,
      "step": 15860
    },
    {
      "epoch": 3.0851477449455675,
      "grad_norm": 0.000730020459741354,
      "learning_rate": 2.6477881458441333e-05,
      "loss": 0.0,
      "step": 15870
    },
    {
      "epoch": 3.087091757387247,
      "grad_norm": 0.0006289846496656537,
      "learning_rate": 2.6473561430793158e-05,
      "loss": 0.0053,
      "step": 15880
    },
    {
      "epoch": 3.089035769828927,
      "grad_norm": 0.0004283503512851894,
      "learning_rate": 2.646924140314498e-05,
      "loss": 0.0,
      "step": 15890
    },
    {
      "epoch": 3.0909797822706064,
      "grad_norm": 0.0008531387429684401,
      "learning_rate": 2.6464921375496802e-05,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 3.092923794712286,
      "grad_norm": 0.000575234938878566,
      "learning_rate": 2.6460601347848627e-05,
      "loss": 0.0,
      "step": 15910
    },
    {
      "epoch": 3.0948678071539657,
      "grad_norm": 0.0010756135452538729,
      "learning_rate": 2.645628132020045e-05,
      "loss": 0.0151,
      "step": 15920
    },
    {
      "epoch": 3.0968118195956453,
      "grad_norm": 0.0007573896436952055,
      "learning_rate": 2.645196129255227e-05,
      "loss": 0.0,
      "step": 15930
    },
    {
      "epoch": 3.098755832037325,
      "grad_norm": 0.000749073107726872,
      "learning_rate": 2.6447641264904095e-05,
      "loss": 0.0001,
      "step": 15940
    },
    {
      "epoch": 3.1006998444790046,
      "grad_norm": 0.000457604241091758,
      "learning_rate": 2.644332123725592e-05,
      "loss": 0.0002,
      "step": 15950
    },
    {
      "epoch": 3.1026438569206842,
      "grad_norm": 0.0009449907229281962,
      "learning_rate": 2.6439001209607744e-05,
      "loss": 0.002,
      "step": 15960
    },
    {
      "epoch": 3.104587869362364,
      "grad_norm": 0.0005904099089093506,
      "learning_rate": 2.6434681181959564e-05,
      "loss": 0.0,
      "step": 15970
    },
    {
      "epoch": 3.1065318818040435,
      "grad_norm": 0.0009264402324333787,
      "learning_rate": 2.643036115431139e-05,
      "loss": 0.0,
      "step": 15980
    },
    {
      "epoch": 3.108475894245723,
      "grad_norm": 0.0014593604719266295,
      "learning_rate": 2.6426041126663213e-05,
      "loss": 0.0002,
      "step": 15990
    },
    {
      "epoch": 3.1104199066874028,
      "grad_norm": 6.311673164367676,
      "learning_rate": 2.6421721099015033e-05,
      "loss": 0.0008,
      "step": 16000
    },
    {
      "epoch": 3.1123639191290824,
      "grad_norm": 0.0013933411100879312,
      "learning_rate": 2.6417401071366857e-05,
      "loss": 0.0,
      "step": 16010
    },
    {
      "epoch": 3.114307931570762,
      "grad_norm": 0.000674045120831579,
      "learning_rate": 2.641308104371868e-05,
      "loss": 0.0137,
      "step": 16020
    },
    {
      "epoch": 3.1162519440124417,
      "grad_norm": 0.0006405944004654884,
      "learning_rate": 2.6408761016070502e-05,
      "loss": 0.0018,
      "step": 16030
    },
    {
      "epoch": 3.1181959564541213,
      "grad_norm": 0.0006572467391379178,
      "learning_rate": 2.6404440988422326e-05,
      "loss": 0.0001,
      "step": 16040
    },
    {
      "epoch": 3.120139968895801,
      "grad_norm": 0.0006942460313439369,
      "learning_rate": 2.640012096077415e-05,
      "loss": 0.0001,
      "step": 16050
    },
    {
      "epoch": 3.1220839813374806,
      "grad_norm": 0.0012118907179683447,
      "learning_rate": 2.6395800933125975e-05,
      "loss": 0.0825,
      "step": 16060
    },
    {
      "epoch": 3.12402799377916,
      "grad_norm": 0.004507794976234436,
      "learning_rate": 2.6391480905477795e-05,
      "loss": 0.0026,
      "step": 16070
    },
    {
      "epoch": 3.12597200622084,
      "grad_norm": 0.0006137957097962499,
      "learning_rate": 2.638716087782962e-05,
      "loss": 0.0149,
      "step": 16080
    },
    {
      "epoch": 3.1279160186625194,
      "grad_norm": 0.0009779470274224877,
      "learning_rate": 2.6382840850181444e-05,
      "loss": 0.0,
      "step": 16090
    },
    {
      "epoch": 3.129860031104199,
      "grad_norm": 0.0010856568114832044,
      "learning_rate": 2.6378520822533264e-05,
      "loss": 0.0134,
      "step": 16100
    },
    {
      "epoch": 3.1318040435458787,
      "grad_norm": 0.000698590709362179,
      "learning_rate": 2.637420079488509e-05,
      "loss": 0.0049,
      "step": 16110
    },
    {
      "epoch": 3.1337480559875583,
      "grad_norm": 0.0007763376925140619,
      "learning_rate": 2.6369880767236913e-05,
      "loss": 0.0002,
      "step": 16120
    },
    {
      "epoch": 3.135692068429238,
      "grad_norm": 0.00039086907054297626,
      "learning_rate": 2.6365560739588733e-05,
      "loss": 0.0067,
      "step": 16130
    },
    {
      "epoch": 3.1376360808709176,
      "grad_norm": 0.0009809195762500167,
      "learning_rate": 2.6361240711940557e-05,
      "loss": 0.0186,
      "step": 16140
    },
    {
      "epoch": 3.1395800933125972,
      "grad_norm": 0.002219655318185687,
      "learning_rate": 2.635692068429238e-05,
      "loss": 0.0348,
      "step": 16150
    },
    {
      "epoch": 3.141524105754277,
      "grad_norm": 0.005121250636875629,
      "learning_rate": 2.6352600656644202e-05,
      "loss": 0.0002,
      "step": 16160
    },
    {
      "epoch": 3.1434681181959565,
      "grad_norm": 0.0016354448162019253,
      "learning_rate": 2.6348280628996026e-05,
      "loss": 0.0001,
      "step": 16170
    },
    {
      "epoch": 3.145412130637636,
      "grad_norm": 0.0018510267836973071,
      "learning_rate": 2.634396060134785e-05,
      "loss": 0.0001,
      "step": 16180
    },
    {
      "epoch": 3.1473561430793158,
      "grad_norm": 0.0029847074765712023,
      "learning_rate": 2.633964057369967e-05,
      "loss": 0.0001,
      "step": 16190
    },
    {
      "epoch": 3.1493001555209954,
      "grad_norm": 0.0009136598091572523,
      "learning_rate": 2.6335320546051495e-05,
      "loss": 0.0001,
      "step": 16200
    },
    {
      "epoch": 3.151244167962675,
      "grad_norm": 0.0026521608233451843,
      "learning_rate": 2.633100051840332e-05,
      "loss": 0.0001,
      "step": 16210
    },
    {
      "epoch": 3.1531881804043547,
      "grad_norm": 3.4911742210388184,
      "learning_rate": 2.632668049075514e-05,
      "loss": 0.0282,
      "step": 16220
    },
    {
      "epoch": 3.1551321928460343,
      "grad_norm": 0.0009841379942372441,
      "learning_rate": 2.6322360463106964e-05,
      "loss": 0.0028,
      "step": 16230
    },
    {
      "epoch": 3.157076205287714,
      "grad_norm": 5.539043426513672,
      "learning_rate": 2.6318040435458788e-05,
      "loss": 0.0113,
      "step": 16240
    },
    {
      "epoch": 3.1590202177293936,
      "grad_norm": 14.08935260772705,
      "learning_rate": 2.631372040781061e-05,
      "loss": 0.0017,
      "step": 16250
    },
    {
      "epoch": 3.160964230171073,
      "grad_norm": 0.0012490145163610578,
      "learning_rate": 2.6309400380162437e-05,
      "loss": 0.0001,
      "step": 16260
    },
    {
      "epoch": 3.162908242612753,
      "grad_norm": 0.0024534855037927628,
      "learning_rate": 2.6305080352514257e-05,
      "loss": 0.0001,
      "step": 16270
    },
    {
      "epoch": 3.1648522550544325,
      "grad_norm": 9.520755767822266,
      "learning_rate": 2.6300760324866078e-05,
      "loss": 0.0131,
      "step": 16280
    },
    {
      "epoch": 3.166796267496112,
      "grad_norm": 0.0009089891100302339,
      "learning_rate": 2.6296440297217905e-05,
      "loss": 0.0001,
      "step": 16290
    },
    {
      "epoch": 3.1687402799377917,
      "grad_norm": 0.0011158104753121734,
      "learning_rate": 2.6292120269569726e-05,
      "loss": 0.0001,
      "step": 16300
    },
    {
      "epoch": 3.1706842923794714,
      "grad_norm": 0.001497643650509417,
      "learning_rate": 2.6287800241921547e-05,
      "loss": 0.0001,
      "step": 16310
    },
    {
      "epoch": 3.172628304821151,
      "grad_norm": 0.0009344852296635509,
      "learning_rate": 2.6283480214273374e-05,
      "loss": 0.0061,
      "step": 16320
    },
    {
      "epoch": 3.1745723172628306,
      "grad_norm": 0.0005478236707858741,
      "learning_rate": 2.6279160186625195e-05,
      "loss": 0.0124,
      "step": 16330
    },
    {
      "epoch": 3.1765163297045103,
      "grad_norm": 0.001236673560924828,
      "learning_rate": 2.6274840158977016e-05,
      "loss": 0.0191,
      "step": 16340
    },
    {
      "epoch": 3.17846034214619,
      "grad_norm": 0.003352646715939045,
      "learning_rate": 2.6270520131328843e-05,
      "loss": 0.0154,
      "step": 16350
    },
    {
      "epoch": 3.1804043545878695,
      "grad_norm": 0.00871708057820797,
      "learning_rate": 2.6266200103680664e-05,
      "loss": 0.0004,
      "step": 16360
    },
    {
      "epoch": 3.182348367029549,
      "grad_norm": 0.0061929309740662575,
      "learning_rate": 2.6261880076032485e-05,
      "loss": 0.003,
      "step": 16370
    },
    {
      "epoch": 3.184292379471229,
      "grad_norm": 13.851212501525879,
      "learning_rate": 2.6257560048384312e-05,
      "loss": 0.0017,
      "step": 16380
    },
    {
      "epoch": 3.1862363919129084,
      "grad_norm": 0.0013247375609353185,
      "learning_rate": 2.6253240020736133e-05,
      "loss": 0.0002,
      "step": 16390
    },
    {
      "epoch": 3.188180404354588,
      "grad_norm": 0.005632495041936636,
      "learning_rate": 2.6248919993087954e-05,
      "loss": 0.0002,
      "step": 16400
    },
    {
      "epoch": 3.1901244167962677,
      "grad_norm": 0.0009033522801473737,
      "learning_rate": 2.624459996543978e-05,
      "loss": 0.0007,
      "step": 16410
    },
    {
      "epoch": 3.1920684292379473,
      "grad_norm": 0.0034604547545313835,
      "learning_rate": 2.6240279937791602e-05,
      "loss": 0.0001,
      "step": 16420
    },
    {
      "epoch": 3.194012441679627,
      "grad_norm": 0.0027313122991472483,
      "learning_rate": 2.6235959910143426e-05,
      "loss": 0.0001,
      "step": 16430
    },
    {
      "epoch": 3.1959564541213066,
      "grad_norm": 0.00076536915730685,
      "learning_rate": 2.623163988249525e-05,
      "loss": 0.0001,
      "step": 16440
    },
    {
      "epoch": 3.197900466562986,
      "grad_norm": 0.0015665243845432997,
      "learning_rate": 2.622731985484707e-05,
      "loss": 0.0175,
      "step": 16450
    },
    {
      "epoch": 3.199844479004666,
      "grad_norm": 0.001896716421470046,
      "learning_rate": 2.6222999827198895e-05,
      "loss": 0.0002,
      "step": 16460
    },
    {
      "epoch": 3.2017884914463455,
      "grad_norm": 0.019824737682938576,
      "learning_rate": 2.621867979955072e-05,
      "loss": 0.0004,
      "step": 16470
    },
    {
      "epoch": 3.203732503888025,
      "grad_norm": 0.004996525589376688,
      "learning_rate": 2.621435977190254e-05,
      "loss": 0.0009,
      "step": 16480
    },
    {
      "epoch": 3.2056765163297047,
      "grad_norm": 0.003162850858643651,
      "learning_rate": 2.6210039744254364e-05,
      "loss": 0.0003,
      "step": 16490
    },
    {
      "epoch": 3.2076205287713844,
      "grad_norm": 0.0018938292050734162,
      "learning_rate": 2.6205719716606188e-05,
      "loss": 0.017,
      "step": 16500
    },
    {
      "epoch": 3.2095645412130636,
      "grad_norm": 0.0035444118548184633,
      "learning_rate": 2.620139968895801e-05,
      "loss": 0.0002,
      "step": 16510
    },
    {
      "epoch": 3.211508553654743,
      "grad_norm": 0.011075749062001705,
      "learning_rate": 2.6197079661309833e-05,
      "loss": 0.0002,
      "step": 16520
    },
    {
      "epoch": 3.213452566096423,
      "grad_norm": 0.024583112448453903,
      "learning_rate": 2.6192759633661657e-05,
      "loss": 0.0004,
      "step": 16530
    },
    {
      "epoch": 3.2153965785381025,
      "grad_norm": 0.003407058771699667,
      "learning_rate": 2.6188439606013478e-05,
      "loss": 0.0018,
      "step": 16540
    },
    {
      "epoch": 3.217340590979782,
      "grad_norm": 0.003423608373850584,
      "learning_rate": 2.6184119578365302e-05,
      "loss": 0.0001,
      "step": 16550
    },
    {
      "epoch": 3.2192846034214617,
      "grad_norm": 0.014133043587207794,
      "learning_rate": 2.6179799550717126e-05,
      "loss": 0.0005,
      "step": 16560
    },
    {
      "epoch": 3.2212286158631414,
      "grad_norm": 0.001675663166679442,
      "learning_rate": 2.6175479523068947e-05,
      "loss": 0.0001,
      "step": 16570
    },
    {
      "epoch": 3.223172628304821,
      "grad_norm": 0.0015906553016975522,
      "learning_rate": 2.617115949542077e-05,
      "loss": 0.0048,
      "step": 16580
    },
    {
      "epoch": 3.2251166407465006,
      "grad_norm": 0.0022471798583865166,
      "learning_rate": 2.6166839467772595e-05,
      "loss": 0.0004,
      "step": 16590
    },
    {
      "epoch": 3.2270606531881803,
      "grad_norm": 0.0009383635479025543,
      "learning_rate": 2.6162519440124416e-05,
      "loss": 0.0053,
      "step": 16600
    },
    {
      "epoch": 3.22900466562986,
      "grad_norm": 0.005474907346069813,
      "learning_rate": 2.615819941247624e-05,
      "loss": 0.0001,
      "step": 16610
    },
    {
      "epoch": 3.2309486780715395,
      "grad_norm": 0.001967936521396041,
      "learning_rate": 2.6153879384828064e-05,
      "loss": 0.0113,
      "step": 16620
    },
    {
      "epoch": 3.232892690513219,
      "grad_norm": 0.006411408074200153,
      "learning_rate": 2.6149559357179888e-05,
      "loss": 0.0001,
      "step": 16630
    },
    {
      "epoch": 3.234836702954899,
      "grad_norm": 0.008338253013789654,
      "learning_rate": 2.614523932953171e-05,
      "loss": 0.0002,
      "step": 16640
    },
    {
      "epoch": 3.2367807153965784,
      "grad_norm": 0.0013917734613642097,
      "learning_rate": 2.6140919301883533e-05,
      "loss": 0.0001,
      "step": 16650
    },
    {
      "epoch": 3.238724727838258,
      "grad_norm": 47.05322265625,
      "learning_rate": 2.6136599274235357e-05,
      "loss": 0.0034,
      "step": 16660
    },
    {
      "epoch": 3.2406687402799377,
      "grad_norm": 0.000831086013931781,
      "learning_rate": 2.6132279246587178e-05,
      "loss": 0.0001,
      "step": 16670
    },
    {
      "epoch": 3.2426127527216173,
      "grad_norm": 0.001988636562600732,
      "learning_rate": 2.6127959218939002e-05,
      "loss": 0.0001,
      "step": 16680
    },
    {
      "epoch": 3.244556765163297,
      "grad_norm": 0.0010047447867691517,
      "learning_rate": 2.6123639191290826e-05,
      "loss": 0.016,
      "step": 16690
    },
    {
      "epoch": 3.2465007776049766,
      "grad_norm": 0.0010699221165850759,
      "learning_rate": 2.6119319163642647e-05,
      "loss": 0.0015,
      "step": 16700
    },
    {
      "epoch": 3.248444790046656,
      "grad_norm": 0.0005411450401879847,
      "learning_rate": 2.611499913599447e-05,
      "loss": 0.0001,
      "step": 16710
    },
    {
      "epoch": 3.250388802488336,
      "grad_norm": 0.0011239798041060567,
      "learning_rate": 2.6110679108346295e-05,
      "loss": 0.0235,
      "step": 16720
    },
    {
      "epoch": 3.2523328149300155,
      "grad_norm": 0.011785777285695076,
      "learning_rate": 2.6106359080698115e-05,
      "loss": 0.0002,
      "step": 16730
    },
    {
      "epoch": 3.254276827371695,
      "grad_norm": 0.011873769573867321,
      "learning_rate": 2.610203905304994e-05,
      "loss": 0.0004,
      "step": 16740
    },
    {
      "epoch": 3.2562208398133747,
      "grad_norm": 0.002858587075024843,
      "learning_rate": 2.6097719025401764e-05,
      "loss": 0.0002,
      "step": 16750
    },
    {
      "epoch": 3.2581648522550544,
      "grad_norm": 0.005958734080195427,
      "learning_rate": 2.6093398997753584e-05,
      "loss": 0.0002,
      "step": 16760
    },
    {
      "epoch": 3.260108864696734,
      "grad_norm": 0.0027055004611611366,
      "learning_rate": 2.608907897010541e-05,
      "loss": 0.0001,
      "step": 16770
    },
    {
      "epoch": 3.2620528771384136,
      "grad_norm": 0.0021688900887966156,
      "learning_rate": 2.6084758942457233e-05,
      "loss": 0.0284,
      "step": 16780
    },
    {
      "epoch": 3.2639968895800933,
      "grad_norm": 0.0015256042825058103,
      "learning_rate": 2.6080438914809053e-05,
      "loss": 0.0001,
      "step": 16790
    },
    {
      "epoch": 3.265940902021773,
      "grad_norm": 0.001843344303779304,
      "learning_rate": 2.6076118887160877e-05,
      "loss": 0.0001,
      "step": 16800
    },
    {
      "epoch": 3.2678849144634525,
      "grad_norm": 0.0007297567208297551,
      "learning_rate": 2.60717988595127e-05,
      "loss": 0.0001,
      "step": 16810
    },
    {
      "epoch": 3.269828926905132,
      "grad_norm": 0.0021438542753458023,
      "learning_rate": 2.6067478831864522e-05,
      "loss": 0.0001,
      "step": 16820
    },
    {
      "epoch": 3.271772939346812,
      "grad_norm": 0.0011033335467800498,
      "learning_rate": 2.606315880421635e-05,
      "loss": 0.0001,
      "step": 16830
    },
    {
      "epoch": 3.2737169517884914,
      "grad_norm": 0.0008470164611935616,
      "learning_rate": 2.605883877656817e-05,
      "loss": 0.0001,
      "step": 16840
    },
    {
      "epoch": 3.275660964230171,
      "grad_norm": 0.0011651746463030577,
      "learning_rate": 2.6054518748919995e-05,
      "loss": 0.0001,
      "step": 16850
    },
    {
      "epoch": 3.2776049766718507,
      "grad_norm": 0.02413279563188553,
      "learning_rate": 2.605019872127182e-05,
      "loss": 0.0002,
      "step": 16860
    },
    {
      "epoch": 3.2795489891135303,
      "grad_norm": 0.005243014078587294,
      "learning_rate": 2.604587869362364e-05,
      "loss": 0.0001,
      "step": 16870
    },
    {
      "epoch": 3.28149300155521,
      "grad_norm": 0.002877316204831004,
      "learning_rate": 2.6041558665975464e-05,
      "loss": 0.0001,
      "step": 16880
    },
    {
      "epoch": 3.2834370139968896,
      "grad_norm": 0.0008054947829805315,
      "learning_rate": 2.6037238638327288e-05,
      "loss": 0.0001,
      "step": 16890
    },
    {
      "epoch": 3.285381026438569,
      "grad_norm": 0.0004915576428174973,
      "learning_rate": 2.603291861067911e-05,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 3.287325038880249,
      "grad_norm": 0.0010152114555239677,
      "learning_rate": 2.6028598583030933e-05,
      "loss": 0.0,
      "step": 16910
    },
    {
      "epoch": 3.2892690513219285,
      "grad_norm": 0.0007512690499424934,
      "learning_rate": 2.6024278555382757e-05,
      "loss": 0.0,
      "step": 16920
    },
    {
      "epoch": 3.291213063763608,
      "grad_norm": 0.0008184110629372299,
      "learning_rate": 2.6019958527734577e-05,
      "loss": 0.0,
      "step": 16930
    },
    {
      "epoch": 3.2931570762052877,
      "grad_norm": 0.0010252721840515733,
      "learning_rate": 2.60156385000864e-05,
      "loss": 0.0091,
      "step": 16940
    },
    {
      "epoch": 3.2951010886469674,
      "grad_norm": 0.0009729671292006969,
      "learning_rate": 2.6011318472438226e-05,
      "loss": 0.0128,
      "step": 16950
    },
    {
      "epoch": 3.297045101088647,
      "grad_norm": 0.0019289252813905478,
      "learning_rate": 2.6006998444790046e-05,
      "loss": 0.0001,
      "step": 16960
    },
    {
      "epoch": 3.2989891135303266,
      "grad_norm": 0.0021694733295589685,
      "learning_rate": 2.600267841714187e-05,
      "loss": 0.0008,
      "step": 16970
    },
    {
      "epoch": 3.3009331259720063,
      "grad_norm": 0.000717687071301043,
      "learning_rate": 2.5998358389493695e-05,
      "loss": 0.0,
      "step": 16980
    },
    {
      "epoch": 3.302877138413686,
      "grad_norm": 0.0005711769917979836,
      "learning_rate": 2.5994038361845515e-05,
      "loss": 0.0,
      "step": 16990
    },
    {
      "epoch": 3.3048211508553655,
      "grad_norm": 0.0005141496076248586,
      "learning_rate": 2.598971833419734e-05,
      "loss": 0.0001,
      "step": 17000
    },
    {
      "epoch": 3.306765163297045,
      "grad_norm": 0.0009066536440514028,
      "learning_rate": 2.5985398306549163e-05,
      "loss": 0.0211,
      "step": 17010
    },
    {
      "epoch": 3.308709175738725,
      "grad_norm": 0.0007545094704255462,
      "learning_rate": 2.5981078278900984e-05,
      "loss": 0.0,
      "step": 17020
    },
    {
      "epoch": 3.3106531881804044,
      "grad_norm": 0.0005888863233849406,
      "learning_rate": 2.5976758251252812e-05,
      "loss": 0.0147,
      "step": 17030
    },
    {
      "epoch": 3.312597200622084,
      "grad_norm": 0.004201503470540047,
      "learning_rate": 2.5972438223604632e-05,
      "loss": 0.0213,
      "step": 17040
    },
    {
      "epoch": 3.3145412130637637,
      "grad_norm": 0.0004796015564352274,
      "learning_rate": 2.5968118195956453e-05,
      "loss": 0.0015,
      "step": 17050
    },
    {
      "epoch": 3.3164852255054433,
      "grad_norm": 0.0022198979277163744,
      "learning_rate": 2.596379816830828e-05,
      "loss": 0.0036,
      "step": 17060
    },
    {
      "epoch": 3.318429237947123,
      "grad_norm": 0.0006286929710768163,
      "learning_rate": 2.59594781406601e-05,
      "loss": 0.0,
      "step": 17070
    },
    {
      "epoch": 3.3203732503888026,
      "grad_norm": 0.0007648819009773433,
      "learning_rate": 2.5955158113011922e-05,
      "loss": 0.0001,
      "step": 17080
    },
    {
      "epoch": 3.3223172628304822,
      "grad_norm": 0.003634813940152526,
      "learning_rate": 2.595083808536375e-05,
      "loss": 0.0085,
      "step": 17090
    },
    {
      "epoch": 3.324261275272162,
      "grad_norm": 0.0008220957242883742,
      "learning_rate": 2.594651805771557e-05,
      "loss": 0.0001,
      "step": 17100
    },
    {
      "epoch": 3.3262052877138415,
      "grad_norm": 0.006633631885051727,
      "learning_rate": 2.594219803006739e-05,
      "loss": 0.0122,
      "step": 17110
    },
    {
      "epoch": 3.328149300155521,
      "grad_norm": 0.0009312430047430098,
      "learning_rate": 2.593787800241922e-05,
      "loss": 0.0001,
      "step": 17120
    },
    {
      "epoch": 3.3300933125972008,
      "grad_norm": 0.0006605019443668425,
      "learning_rate": 2.593355797477104e-05,
      "loss": 0.0001,
      "step": 17130
    },
    {
      "epoch": 3.3320373250388804,
      "grad_norm": 0.0018035323591902852,
      "learning_rate": 2.592923794712286e-05,
      "loss": 0.0001,
      "step": 17140
    },
    {
      "epoch": 3.33398133748056,
      "grad_norm": 0.0012749979505315423,
      "learning_rate": 2.5924917919474687e-05,
      "loss": 0.0005,
      "step": 17150
    },
    {
      "epoch": 3.3359253499222397,
      "grad_norm": 0.0012735472992062569,
      "learning_rate": 2.5920597891826508e-05,
      "loss": 0.0258,
      "step": 17160
    },
    {
      "epoch": 3.3378693623639193,
      "grad_norm": 0.0004052663571201265,
      "learning_rate": 2.591627786417833e-05,
      "loss": 0.0057,
      "step": 17170
    },
    {
      "epoch": 3.339813374805599,
      "grad_norm": 0.000465304940007627,
      "learning_rate": 2.5911957836530156e-05,
      "loss": 0.0,
      "step": 17180
    },
    {
      "epoch": 3.3417573872472786,
      "grad_norm": 0.000515789957717061,
      "learning_rate": 2.5907637808881977e-05,
      "loss": 0.0,
      "step": 17190
    },
    {
      "epoch": 3.343701399688958,
      "grad_norm": 0.00038172624772414565,
      "learning_rate": 2.59033177812338e-05,
      "loss": 0.0309,
      "step": 17200
    },
    {
      "epoch": 3.345645412130638,
      "grad_norm": 0.0008258426678366959,
      "learning_rate": 2.5898997753585625e-05,
      "loss": 0.0001,
      "step": 17210
    },
    {
      "epoch": 3.3475894245723175,
      "grad_norm": 0.0007242587744258344,
      "learning_rate": 2.5894677725937446e-05,
      "loss": 0.0,
      "step": 17220
    },
    {
      "epoch": 3.349533437013997,
      "grad_norm": 0.0006179899210110307,
      "learning_rate": 2.589035769828927e-05,
      "loss": 0.0,
      "step": 17230
    },
    {
      "epoch": 3.3514774494556763,
      "grad_norm": 0.0011788959382101893,
      "learning_rate": 2.5886037670641094e-05,
      "loss": 0.0154,
      "step": 17240
    },
    {
      "epoch": 3.353421461897356,
      "grad_norm": 0.0032829060219228268,
      "learning_rate": 2.5881717642992915e-05,
      "loss": 0.0001,
      "step": 17250
    },
    {
      "epoch": 3.3553654743390355,
      "grad_norm": 0.0017375739989802241,
      "learning_rate": 2.587739761534474e-05,
      "loss": 0.0003,
      "step": 17260
    },
    {
      "epoch": 3.357309486780715,
      "grad_norm": 1.2970200777053833,
      "learning_rate": 2.5873077587696563e-05,
      "loss": 0.0494,
      "step": 17270
    },
    {
      "epoch": 3.359253499222395,
      "grad_norm": 0.015593556687235832,
      "learning_rate": 2.5868757560048384e-05,
      "loss": 0.002,
      "step": 17280
    },
    {
      "epoch": 3.3611975116640744,
      "grad_norm": 0.3896724581718445,
      "learning_rate": 2.5864437532400208e-05,
      "loss": 0.0017,
      "step": 17290
    },
    {
      "epoch": 3.363141524105754,
      "grad_norm": 0.004282390233129263,
      "learning_rate": 2.5860117504752032e-05,
      "loss": 0.0003,
      "step": 17300
    },
    {
      "epoch": 3.3650855365474337,
      "grad_norm": 0.0033825512509793043,
      "learning_rate": 2.5855797477103853e-05,
      "loss": 0.0002,
      "step": 17310
    },
    {
      "epoch": 3.3670295489891133,
      "grad_norm": 0.017759377136826515,
      "learning_rate": 2.5851477449455677e-05,
      "loss": 0.0359,
      "step": 17320
    },
    {
      "epoch": 3.368973561430793,
      "grad_norm": 0.003095508785918355,
      "learning_rate": 2.58471574218075e-05,
      "loss": 0.0002,
      "step": 17330
    },
    {
      "epoch": 3.3709175738724726,
      "grad_norm": 2.052368640899658,
      "learning_rate": 2.5842837394159322e-05,
      "loss": 0.0009,
      "step": 17340
    },
    {
      "epoch": 3.3728615863141522,
      "grad_norm": 0.0017602832522243261,
      "learning_rate": 2.5838517366511146e-05,
      "loss": 0.0001,
      "step": 17350
    },
    {
      "epoch": 3.374805598755832,
      "grad_norm": 0.0032002374064177275,
      "learning_rate": 2.583419733886297e-05,
      "loss": 0.015,
      "step": 17360
    },
    {
      "epoch": 3.3767496111975115,
      "grad_norm": 0.004544621333479881,
      "learning_rate": 2.582987731121479e-05,
      "loss": 0.0003,
      "step": 17370
    },
    {
      "epoch": 3.378693623639191,
      "grad_norm": 0.00986372958868742,
      "learning_rate": 2.5825557283566615e-05,
      "loss": 0.0003,
      "step": 17380
    },
    {
      "epoch": 3.3806376360808708,
      "grad_norm": 0.026568885892629623,
      "learning_rate": 2.582123725591844e-05,
      "loss": 0.0018,
      "step": 17390
    },
    {
      "epoch": 3.3825816485225504,
      "grad_norm": 0.0011295247822999954,
      "learning_rate": 2.5816917228270263e-05,
      "loss": 0.0022,
      "step": 17400
    },
    {
      "epoch": 3.38452566096423,
      "grad_norm": 0.0073486813344061375,
      "learning_rate": 2.5812597200622084e-05,
      "loss": 0.0001,
      "step": 17410
    },
    {
      "epoch": 3.3864696734059097,
      "grad_norm": 0.00921041052788496,
      "learning_rate": 2.5808277172973908e-05,
      "loss": 0.0001,
      "step": 17420
    },
    {
      "epoch": 3.3884136858475893,
      "grad_norm": 0.0023358918260782957,
      "learning_rate": 2.5803957145325732e-05,
      "loss": 0.0001,
      "step": 17430
    },
    {
      "epoch": 3.390357698289269,
      "grad_norm": 0.0017808603588491678,
      "learning_rate": 2.5799637117677553e-05,
      "loss": 0.0002,
      "step": 17440
    },
    {
      "epoch": 3.3923017107309485,
      "grad_norm": 0.0018742838874459267,
      "learning_rate": 2.5795317090029377e-05,
      "loss": 0.0154,
      "step": 17450
    },
    {
      "epoch": 3.394245723172628,
      "grad_norm": 0.006800489965826273,
      "learning_rate": 2.57909970623812e-05,
      "loss": 0.0002,
      "step": 17460
    },
    {
      "epoch": 3.396189735614308,
      "grad_norm": 0.006399726029485464,
      "learning_rate": 2.5786677034733022e-05,
      "loss": 0.0003,
      "step": 17470
    },
    {
      "epoch": 3.3981337480559874,
      "grad_norm": 0.006729300133883953,
      "learning_rate": 2.5782357007084846e-05,
      "loss": 0.0134,
      "step": 17480
    },
    {
      "epoch": 3.400077760497667,
      "grad_norm": 0.003082492621615529,
      "learning_rate": 2.577803697943667e-05,
      "loss": 0.0002,
      "step": 17490
    },
    {
      "epoch": 3.4020217729393467,
      "grad_norm": 0.003183558816090226,
      "learning_rate": 2.577371695178849e-05,
      "loss": 0.0002,
      "step": 17500
    },
    {
      "epoch": 3.4039657853810263,
      "grad_norm": 0.001892593689262867,
      "learning_rate": 2.5769396924140315e-05,
      "loss": 0.0001,
      "step": 17510
    },
    {
      "epoch": 3.405909797822706,
      "grad_norm": 0.0021561249159276485,
      "learning_rate": 2.576507689649214e-05,
      "loss": 0.0001,
      "step": 17520
    },
    {
      "epoch": 3.4078538102643856,
      "grad_norm": 0.004526808857917786,
      "learning_rate": 2.576075686884396e-05,
      "loss": 0.0007,
      "step": 17530
    },
    {
      "epoch": 3.4097978227060652,
      "grad_norm": 0.002606672700494528,
      "learning_rate": 2.5756436841195784e-05,
      "loss": 0.0134,
      "step": 17540
    },
    {
      "epoch": 3.411741835147745,
      "grad_norm": 0.002401528414338827,
      "learning_rate": 2.5752116813547608e-05,
      "loss": 0.027,
      "step": 17550
    },
    {
      "epoch": 3.4136858475894245,
      "grad_norm": 0.0032153972424566746,
      "learning_rate": 2.574779678589943e-05,
      "loss": 0.0002,
      "step": 17560
    },
    {
      "epoch": 3.415629860031104,
      "grad_norm": 0.0015178683679550886,
      "learning_rate": 2.5743476758251253e-05,
      "loss": 0.0019,
      "step": 17570
    },
    {
      "epoch": 3.4175738724727838,
      "grad_norm": 0.00184533535502851,
      "learning_rate": 2.5739156730603077e-05,
      "loss": 0.0001,
      "step": 17580
    },
    {
      "epoch": 3.4195178849144634,
      "grad_norm": 0.014548148959875107,
      "learning_rate": 2.5734836702954898e-05,
      "loss": 0.0001,
      "step": 17590
    },
    {
      "epoch": 3.421461897356143,
      "grad_norm": 0.0012172851711511612,
      "learning_rate": 2.5730516675306725e-05,
      "loss": 0.0002,
      "step": 17600
    },
    {
      "epoch": 3.4234059097978227,
      "grad_norm": 0.0008425810956396163,
      "learning_rate": 2.5726196647658546e-05,
      "loss": 0.0001,
      "step": 17610
    },
    {
      "epoch": 3.4253499222395023,
      "grad_norm": 0.016576144844293594,
      "learning_rate": 2.5721876620010366e-05,
      "loss": 0.0001,
      "step": 17620
    },
    {
      "epoch": 3.427293934681182,
      "grad_norm": 0.007875601761043072,
      "learning_rate": 2.5717556592362194e-05,
      "loss": 0.0001,
      "step": 17630
    },
    {
      "epoch": 3.4292379471228616,
      "grad_norm": 0.0010940447682514787,
      "learning_rate": 2.5713236564714015e-05,
      "loss": 0.0001,
      "step": 17640
    },
    {
      "epoch": 3.431181959564541,
      "grad_norm": 0.0006880313740111887,
      "learning_rate": 2.5708916537065835e-05,
      "loss": 0.0002,
      "step": 17650
    },
    {
      "epoch": 3.433125972006221,
      "grad_norm": 0.0006898890715092421,
      "learning_rate": 2.5704596509417663e-05,
      "loss": 0.0127,
      "step": 17660
    },
    {
      "epoch": 3.4350699844479005,
      "grad_norm": 0.012136043980717659,
      "learning_rate": 2.5700276481769484e-05,
      "loss": 0.0001,
      "step": 17670
    },
    {
      "epoch": 3.43701399688958,
      "grad_norm": 0.002357461489737034,
      "learning_rate": 2.5695956454121304e-05,
      "loss": 0.0001,
      "step": 17680
    },
    {
      "epoch": 3.4389580093312597,
      "grad_norm": 0.0019191390601918101,
      "learning_rate": 2.5691636426473132e-05,
      "loss": 0.0032,
      "step": 17690
    },
    {
      "epoch": 3.4409020217729394,
      "grad_norm": 0.44881072640419006,
      "learning_rate": 2.5687316398824953e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 3.442846034214619,
      "grad_norm": 0.0028713250067085028,
      "learning_rate": 2.5682996371176773e-05,
      "loss": 0.0001,
      "step": 17710
    },
    {
      "epoch": 3.4447900466562986,
      "grad_norm": 0.0011761346831917763,
      "learning_rate": 2.56786763435286e-05,
      "loss": 0.0001,
      "step": 17720
    },
    {
      "epoch": 3.4467340590979783,
      "grad_norm": 0.0018913218518719077,
      "learning_rate": 2.567435631588042e-05,
      "loss": 0.0103,
      "step": 17730
    },
    {
      "epoch": 3.448678071539658,
      "grad_norm": 0.01519093569368124,
      "learning_rate": 2.5670036288232242e-05,
      "loss": 0.0192,
      "step": 17740
    },
    {
      "epoch": 3.4506220839813375,
      "grad_norm": 0.005421704147011042,
      "learning_rate": 2.566571626058407e-05,
      "loss": 0.0002,
      "step": 17750
    },
    {
      "epoch": 3.452566096423017,
      "grad_norm": 0.002550487406551838,
      "learning_rate": 2.566139623293589e-05,
      "loss": 0.0002,
      "step": 17760
    },
    {
      "epoch": 3.454510108864697,
      "grad_norm": 0.0032962714321911335,
      "learning_rate": 2.5657076205287715e-05,
      "loss": 0.0002,
      "step": 17770
    },
    {
      "epoch": 3.4564541213063764,
      "grad_norm": 0.003963280003517866,
      "learning_rate": 2.565275617763954e-05,
      "loss": 0.0001,
      "step": 17780
    },
    {
      "epoch": 3.458398133748056,
      "grad_norm": 0.42621684074401855,
      "learning_rate": 2.564843614999136e-05,
      "loss": 0.0004,
      "step": 17790
    },
    {
      "epoch": 3.4603421461897357,
      "grad_norm": 0.002566459821537137,
      "learning_rate": 2.5644116122343187e-05,
      "loss": 0.0001,
      "step": 17800
    },
    {
      "epoch": 3.4622861586314153,
      "grad_norm": 0.0021424409933388233,
      "learning_rate": 2.5639796094695008e-05,
      "loss": 0.0001,
      "step": 17810
    },
    {
      "epoch": 3.464230171073095,
      "grad_norm": 0.0015380694530904293,
      "learning_rate": 2.563547606704683e-05,
      "loss": 0.0001,
      "step": 17820
    },
    {
      "epoch": 3.4661741835147746,
      "grad_norm": 0.0016926784301176667,
      "learning_rate": 2.5631156039398656e-05,
      "loss": 0.0001,
      "step": 17830
    },
    {
      "epoch": 3.468118195956454,
      "grad_norm": 0.0026653544045984745,
      "learning_rate": 2.5626836011750477e-05,
      "loss": 0.0001,
      "step": 17840
    },
    {
      "epoch": 3.470062208398134,
      "grad_norm": 0.0018447911133989692,
      "learning_rate": 2.5622515984102297e-05,
      "loss": 0.0001,
      "step": 17850
    },
    {
      "epoch": 3.4720062208398135,
      "grad_norm": 0.0012480319710448384,
      "learning_rate": 2.5618195956454125e-05,
      "loss": 0.0001,
      "step": 17860
    },
    {
      "epoch": 3.473950233281493,
      "grad_norm": 0.001193070551380515,
      "learning_rate": 2.5613875928805946e-05,
      "loss": 0.0205,
      "step": 17870
    },
    {
      "epoch": 3.4758942457231727,
      "grad_norm": 0.0021839672699570656,
      "learning_rate": 2.5609555901157766e-05,
      "loss": 0.0019,
      "step": 17880
    },
    {
      "epoch": 3.4778382581648524,
      "grad_norm": 0.0020996828097850084,
      "learning_rate": 2.5605235873509594e-05,
      "loss": 0.0188,
      "step": 17890
    },
    {
      "epoch": 3.479782270606532,
      "grad_norm": 0.0021951086819171906,
      "learning_rate": 2.5600915845861414e-05,
      "loss": 0.0003,
      "step": 17900
    },
    {
      "epoch": 3.4817262830482116,
      "grad_norm": 0.0010648434981703758,
      "learning_rate": 2.5596595818213235e-05,
      "loss": 0.0001,
      "step": 17910
    },
    {
      "epoch": 3.4836702954898913,
      "grad_norm": 0.001871624612249434,
      "learning_rate": 2.5592275790565063e-05,
      "loss": 0.0001,
      "step": 17920
    },
    {
      "epoch": 3.485614307931571,
      "grad_norm": 33.48337173461914,
      "learning_rate": 2.5587955762916883e-05,
      "loss": 0.0023,
      "step": 17930
    },
    {
      "epoch": 3.4875583203732505,
      "grad_norm": 0.002196880057454109,
      "learning_rate": 2.5583635735268704e-05,
      "loss": 0.0001,
      "step": 17940
    },
    {
      "epoch": 3.48950233281493,
      "grad_norm": 0.0014243514742702246,
      "learning_rate": 2.557931570762053e-05,
      "loss": 0.0002,
      "step": 17950
    },
    {
      "epoch": 3.49144634525661,
      "grad_norm": 0.001768524874933064,
      "learning_rate": 2.5574995679972352e-05,
      "loss": 0.0001,
      "step": 17960
    },
    {
      "epoch": 3.4933903576982894,
      "grad_norm": 0.000884778331965208,
      "learning_rate": 2.5570675652324173e-05,
      "loss": 0.0001,
      "step": 17970
    },
    {
      "epoch": 3.495334370139969,
      "grad_norm": 0.0013639299431815743,
      "learning_rate": 2.5566355624676e-05,
      "loss": 0.0001,
      "step": 17980
    },
    {
      "epoch": 3.4972783825816487,
      "grad_norm": 0.0019705265294760466,
      "learning_rate": 2.556203559702782e-05,
      "loss": 0.0001,
      "step": 17990
    },
    {
      "epoch": 3.4992223950233283,
      "grad_norm": 0.0007736333645880222,
      "learning_rate": 2.5557715569379645e-05,
      "loss": 0.0001,
      "step": 18000
    },
    {
      "epoch": 3.501166407465008,
      "grad_norm": 0.001087683835066855,
      "learning_rate": 2.555339554173147e-05,
      "loss": 0.0001,
      "step": 18010
    },
    {
      "epoch": 3.5031104199066876,
      "grad_norm": 0.001235989504493773,
      "learning_rate": 2.554907551408329e-05,
      "loss": 0.0042,
      "step": 18020
    },
    {
      "epoch": 3.505054432348367,
      "grad_norm": 0.0008067557355388999,
      "learning_rate": 2.5544755486435114e-05,
      "loss": 0.0001,
      "step": 18030
    },
    {
      "epoch": 3.506998444790047,
      "grad_norm": 0.0016416750149801373,
      "learning_rate": 2.554043545878694e-05,
      "loss": 0.0002,
      "step": 18040
    },
    {
      "epoch": 3.5089424572317265,
      "grad_norm": 0.0038660799618810415,
      "learning_rate": 2.553611543113876e-05,
      "loss": 0.0001,
      "step": 18050
    },
    {
      "epoch": 3.510886469673406,
      "grad_norm": 0.001301210722886026,
      "learning_rate": 2.5531795403490583e-05,
      "loss": 0.0013,
      "step": 18060
    },
    {
      "epoch": 3.5128304821150858,
      "grad_norm": 0.0005776422331109643,
      "learning_rate": 2.5527475375842407e-05,
      "loss": 0.0186,
      "step": 18070
    },
    {
      "epoch": 3.5147744945567654,
      "grad_norm": 0.000670047418680042,
      "learning_rate": 2.5523155348194228e-05,
      "loss": 0.0001,
      "step": 18080
    },
    {
      "epoch": 3.516718506998445,
      "grad_norm": 0.005486396607011557,
      "learning_rate": 2.5518835320546052e-05,
      "loss": 0.0362,
      "step": 18090
    },
    {
      "epoch": 3.5186625194401246,
      "grad_norm": 0.001816288335248828,
      "learning_rate": 2.5514515292897876e-05,
      "loss": 0.0002,
      "step": 18100
    },
    {
      "epoch": 3.5206065318818043,
      "grad_norm": 0.012042157351970673,
      "learning_rate": 2.5510195265249697e-05,
      "loss": 0.0001,
      "step": 18110
    },
    {
      "epoch": 3.522550544323484,
      "grad_norm": 0.00851779617369175,
      "learning_rate": 2.550587523760152e-05,
      "loss": 0.0011,
      "step": 18120
    },
    {
      "epoch": 3.5244945567651635,
      "grad_norm": 0.000822090485598892,
      "learning_rate": 2.5501555209953345e-05,
      "loss": 0.0076,
      "step": 18130
    },
    {
      "epoch": 3.526438569206843,
      "grad_norm": 0.05079791694879532,
      "learning_rate": 2.5497235182305166e-05,
      "loss": 0.0002,
      "step": 18140
    },
    {
      "epoch": 3.528382581648523,
      "grad_norm": 0.8984309434890747,
      "learning_rate": 2.549291515465699e-05,
      "loss": 0.0063,
      "step": 18150
    },
    {
      "epoch": 3.5303265940902024,
      "grad_norm": 0.002557821338996291,
      "learning_rate": 2.5488595127008814e-05,
      "loss": 0.0001,
      "step": 18160
    },
    {
      "epoch": 3.532270606531882,
      "grad_norm": 0.0007229981711134315,
      "learning_rate": 2.5484275099360635e-05,
      "loss": 0.0,
      "step": 18170
    },
    {
      "epoch": 3.5342146189735617,
      "grad_norm": 0.0008374769240617752,
      "learning_rate": 2.547995507171246e-05,
      "loss": 0.0001,
      "step": 18180
    },
    {
      "epoch": 3.536158631415241,
      "grad_norm": 0.0007329676882363856,
      "learning_rate": 2.5475635044064283e-05,
      "loss": 0.0067,
      "step": 18190
    },
    {
      "epoch": 3.5381026438569205,
      "grad_norm": 0.0009592474089004099,
      "learning_rate": 2.5471315016416107e-05,
      "loss": 0.0186,
      "step": 18200
    },
    {
      "epoch": 3.5400466562986,
      "grad_norm": 0.0009412855724804103,
      "learning_rate": 2.5466994988767928e-05,
      "loss": 0.029,
      "step": 18210
    },
    {
      "epoch": 3.54199066874028,
      "grad_norm": 0.010325501672923565,
      "learning_rate": 2.5462674961119752e-05,
      "loss": 0.0001,
      "step": 18220
    },
    {
      "epoch": 3.5439346811819594,
      "grad_norm": 0.0016840198077261448,
      "learning_rate": 2.5458354933471576e-05,
      "loss": 0.0001,
      "step": 18230
    },
    {
      "epoch": 3.545878693623639,
      "grad_norm": 0.09688321501016617,
      "learning_rate": 2.5454034905823397e-05,
      "loss": 0.0001,
      "step": 18240
    },
    {
      "epoch": 3.5478227060653187,
      "grad_norm": 0.0014616213738918304,
      "learning_rate": 2.544971487817522e-05,
      "loss": 0.0001,
      "step": 18250
    },
    {
      "epoch": 3.5497667185069983,
      "grad_norm": 0.001603523618541658,
      "learning_rate": 2.5445394850527045e-05,
      "loss": 0.0001,
      "step": 18260
    },
    {
      "epoch": 3.551710730948678,
      "grad_norm": 0.0024477315600961447,
      "learning_rate": 2.5441074822878866e-05,
      "loss": 0.0002,
      "step": 18270
    },
    {
      "epoch": 3.5536547433903576,
      "grad_norm": 0.0007275652606040239,
      "learning_rate": 2.543675479523069e-05,
      "loss": 0.0064,
      "step": 18280
    },
    {
      "epoch": 3.555598755832037,
      "grad_norm": 0.0010448802495375276,
      "learning_rate": 2.5432434767582514e-05,
      "loss": 0.0085,
      "step": 18290
    },
    {
      "epoch": 3.557542768273717,
      "grad_norm": 0.0005582714802585542,
      "learning_rate": 2.5428114739934335e-05,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 3.5594867807153965,
      "grad_norm": 0.034959834069013596,
      "learning_rate": 2.542379471228616e-05,
      "loss": 0.0026,
      "step": 18310
    },
    {
      "epoch": 3.561430793157076,
      "grad_norm": 0.0005802975501865149,
      "learning_rate": 2.5419474684637983e-05,
      "loss": 0.0,
      "step": 18320
    },
    {
      "epoch": 3.5633748055987557,
      "grad_norm": 0.0006181110511533916,
      "learning_rate": 2.5415154656989804e-05,
      "loss": 0.0102,
      "step": 18330
    },
    {
      "epoch": 3.5653188180404354,
      "grad_norm": 0.0009510621894150972,
      "learning_rate": 2.5410834629341628e-05,
      "loss": 0.0003,
      "step": 18340
    },
    {
      "epoch": 3.567262830482115,
      "grad_norm": 0.0005772479926235974,
      "learning_rate": 2.5406514601693452e-05,
      "loss": 0.0,
      "step": 18350
    },
    {
      "epoch": 3.5692068429237946,
      "grad_norm": 0.000752363761421293,
      "learning_rate": 2.5402194574045273e-05,
      "loss": 0.0036,
      "step": 18360
    },
    {
      "epoch": 3.5711508553654743,
      "grad_norm": 0.0004175247740931809,
      "learning_rate": 2.5397874546397097e-05,
      "loss": 0.0,
      "step": 18370
    },
    {
      "epoch": 3.573094867807154,
      "grad_norm": 0.000682818703353405,
      "learning_rate": 2.539355451874892e-05,
      "loss": 0.0178,
      "step": 18380
    },
    {
      "epoch": 3.5750388802488335,
      "grad_norm": 0.07125305384397507,
      "learning_rate": 2.538923449110074e-05,
      "loss": 0.0001,
      "step": 18390
    },
    {
      "epoch": 3.576982892690513,
      "grad_norm": 0.0007229673210531473,
      "learning_rate": 2.538491446345257e-05,
      "loss": 0.0001,
      "step": 18400
    },
    {
      "epoch": 3.578926905132193,
      "grad_norm": 0.0029311703983694315,
      "learning_rate": 2.538059443580439e-05,
      "loss": 0.0001,
      "step": 18410
    },
    {
      "epoch": 3.5808709175738724,
      "grad_norm": 0.0031233993358910084,
      "learning_rate": 2.537627440815621e-05,
      "loss": 0.0057,
      "step": 18420
    },
    {
      "epoch": 3.582814930015552,
      "grad_norm": 0.017471758648753166,
      "learning_rate": 2.5371954380508038e-05,
      "loss": 0.0067,
      "step": 18430
    },
    {
      "epoch": 3.5847589424572317,
      "grad_norm": 0.002502486342564225,
      "learning_rate": 2.536763435285986e-05,
      "loss": 0.0001,
      "step": 18440
    },
    {
      "epoch": 3.5867029548989113,
      "grad_norm": 0.0012708640424534678,
      "learning_rate": 2.536331432521168e-05,
      "loss": 0.0001,
      "step": 18450
    },
    {
      "epoch": 3.588646967340591,
      "grad_norm": 0.0006953743868507445,
      "learning_rate": 2.5358994297563507e-05,
      "loss": 0.0069,
      "step": 18460
    },
    {
      "epoch": 3.5905909797822706,
      "grad_norm": 0.0006689301808364689,
      "learning_rate": 2.5354674269915328e-05,
      "loss": 0.0004,
      "step": 18470
    },
    {
      "epoch": 3.5925349922239502,
      "grad_norm": 0.0019442149205133319,
      "learning_rate": 2.535035424226715e-05,
      "loss": 0.0006,
      "step": 18480
    },
    {
      "epoch": 3.59447900466563,
      "grad_norm": 0.0008514119544997811,
      "learning_rate": 2.5346034214618976e-05,
      "loss": 0.0231,
      "step": 18490
    },
    {
      "epoch": 3.5964230171073095,
      "grad_norm": 0.0016324445605278015,
      "learning_rate": 2.5341714186970797e-05,
      "loss": 0.0002,
      "step": 18500
    },
    {
      "epoch": 3.598367029548989,
      "grad_norm": 0.000781975919380784,
      "learning_rate": 2.5337394159322617e-05,
      "loss": 0.0022,
      "step": 18510
    },
    {
      "epoch": 3.6003110419906688,
      "grad_norm": 0.0010557790519669652,
      "learning_rate": 2.5333074131674445e-05,
      "loss": 0.0001,
      "step": 18520
    },
    {
      "epoch": 3.6022550544323484,
      "grad_norm": 0.0006763563142158091,
      "learning_rate": 2.5328754104026266e-05,
      "loss": 0.0,
      "step": 18530
    },
    {
      "epoch": 3.604199066874028,
      "grad_norm": 0.000924326537642628,
      "learning_rate": 2.5324434076378086e-05,
      "loss": 0.0001,
      "step": 18540
    },
    {
      "epoch": 3.6061430793157077,
      "grad_norm": 0.0007184793357737362,
      "learning_rate": 2.5320114048729914e-05,
      "loss": 0.0001,
      "step": 18550
    },
    {
      "epoch": 3.6080870917573873,
      "grad_norm": 0.0010303499875590205,
      "learning_rate": 2.5315794021081735e-05,
      "loss": 0.0001,
      "step": 18560
    },
    {
      "epoch": 3.610031104199067,
      "grad_norm": 0.00046942965127527714,
      "learning_rate": 2.531147399343356e-05,
      "loss": 0.0002,
      "step": 18570
    },
    {
      "epoch": 3.6119751166407466,
      "grad_norm": 0.0009420532733201981,
      "learning_rate": 2.5307153965785383e-05,
      "loss": 0.0,
      "step": 18580
    },
    {
      "epoch": 3.613919129082426,
      "grad_norm": 0.0009337981464341283,
      "learning_rate": 2.5302833938137204e-05,
      "loss": 0.0197,
      "step": 18590
    },
    {
      "epoch": 3.615863141524106,
      "grad_norm": 0.0006392763461917639,
      "learning_rate": 2.5298513910489028e-05,
      "loss": 0.0015,
      "step": 18600
    },
    {
      "epoch": 3.6178071539657854,
      "grad_norm": 0.0010729157365858555,
      "learning_rate": 2.5294193882840852e-05,
      "loss": 0.0001,
      "step": 18610
    },
    {
      "epoch": 3.619751166407465,
      "grad_norm": 0.001265364931896329,
      "learning_rate": 2.5289873855192672e-05,
      "loss": 0.0,
      "step": 18620
    },
    {
      "epoch": 3.6216951788491447,
      "grad_norm": 0.000644512299913913,
      "learning_rate": 2.5285553827544497e-05,
      "loss": 0.0001,
      "step": 18630
    },
    {
      "epoch": 3.6236391912908243,
      "grad_norm": 0.0007525541004724801,
      "learning_rate": 2.528123379989632e-05,
      "loss": 0.0001,
      "step": 18640
    },
    {
      "epoch": 3.625583203732504,
      "grad_norm": 0.6672385334968567,
      "learning_rate": 2.527691377224814e-05,
      "loss": 0.0013,
      "step": 18650
    },
    {
      "epoch": 3.6275272161741836,
      "grad_norm": 0.0006030669901520014,
      "learning_rate": 2.527259374459997e-05,
      "loss": 0.0,
      "step": 18660
    },
    {
      "epoch": 3.6294712286158632,
      "grad_norm": 0.019446661695837975,
      "learning_rate": 2.526827371695179e-05,
      "loss": 0.02,
      "step": 18670
    },
    {
      "epoch": 3.631415241057543,
      "grad_norm": 0.015168040059506893,
      "learning_rate": 2.526395368930361e-05,
      "loss": 0.0003,
      "step": 18680
    },
    {
      "epoch": 3.6333592534992225,
      "grad_norm": 0.005259547382593155,
      "learning_rate": 2.5259633661655438e-05,
      "loss": 0.0004,
      "step": 18690
    },
    {
      "epoch": 3.635303265940902,
      "grad_norm": 0.0018069921061396599,
      "learning_rate": 2.525531363400726e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 3.6372472783825818,
      "grad_norm": 0.14786602556705475,
      "learning_rate": 2.525099360635908e-05,
      "loss": 0.0015,
      "step": 18710
    },
    {
      "epoch": 3.6391912908242614,
      "grad_norm": 0.0008107882458716631,
      "learning_rate": 2.5246673578710907e-05,
      "loss": 0.0001,
      "step": 18720
    },
    {
      "epoch": 3.641135303265941,
      "grad_norm": 0.0023451161105185747,
      "learning_rate": 2.5242353551062728e-05,
      "loss": 0.0154,
      "step": 18730
    },
    {
      "epoch": 3.6430793157076207,
      "grad_norm": 0.0015881018480286002,
      "learning_rate": 2.5238033523414548e-05,
      "loss": 0.0001,
      "step": 18740
    },
    {
      "epoch": 3.6450233281493003,
      "grad_norm": 0.00140131707303226,
      "learning_rate": 2.5233713495766376e-05,
      "loss": 0.0001,
      "step": 18750
    },
    {
      "epoch": 3.64696734059098,
      "grad_norm": 0.0011909030145034194,
      "learning_rate": 2.5229393468118196e-05,
      "loss": 0.0001,
      "step": 18760
    },
    {
      "epoch": 3.6489113530326596,
      "grad_norm": 0.000734383356757462,
      "learning_rate": 2.522507344047002e-05,
      "loss": 0.0001,
      "step": 18770
    },
    {
      "epoch": 3.650855365474339,
      "grad_norm": 0.0004175911017227918,
      "learning_rate": 2.5220753412821845e-05,
      "loss": 0.0014,
      "step": 18780
    },
    {
      "epoch": 3.6527993779160184,
      "grad_norm": 0.015313766896724701,
      "learning_rate": 2.5216433385173665e-05,
      "loss": 0.0001,
      "step": 18790
    },
    {
      "epoch": 3.654743390357698,
      "grad_norm": 0.0009549019741825759,
      "learning_rate": 2.521211335752549e-05,
      "loss": 0.003,
      "step": 18800
    },
    {
      "epoch": 3.6566874027993777,
      "grad_norm": 0.0006787176826037467,
      "learning_rate": 2.5207793329877314e-05,
      "loss": 0.0,
      "step": 18810
    },
    {
      "epoch": 3.6586314152410573,
      "grad_norm": 0.0007675462984479964,
      "learning_rate": 2.5203473302229134e-05,
      "loss": 0.0001,
      "step": 18820
    },
    {
      "epoch": 3.660575427682737,
      "grad_norm": 0.0010972117306664586,
      "learning_rate": 2.519915327458096e-05,
      "loss": 0.0001,
      "step": 18830
    },
    {
      "epoch": 3.6625194401244165,
      "grad_norm": 0.0011230313684791327,
      "learning_rate": 2.5194833246932783e-05,
      "loss": 0.0001,
      "step": 18840
    },
    {
      "epoch": 3.664463452566096,
      "grad_norm": 0.0005184084293432534,
      "learning_rate": 2.5190513219284603e-05,
      "loss": 0.0022,
      "step": 18850
    },
    {
      "epoch": 3.666407465007776,
      "grad_norm": 0.0005797594203613698,
      "learning_rate": 2.5186193191636427e-05,
      "loss": 0.0001,
      "step": 18860
    },
    {
      "epoch": 3.6683514774494554,
      "grad_norm": 0.0007350861560553312,
      "learning_rate": 2.518187316398825e-05,
      "loss": 0.0001,
      "step": 18870
    },
    {
      "epoch": 3.670295489891135,
      "grad_norm": 0.0012180220801383257,
      "learning_rate": 2.5177553136340072e-05,
      "loss": 0.0,
      "step": 18880
    },
    {
      "epoch": 3.6722395023328147,
      "grad_norm": 0.00140386784914881,
      "learning_rate": 2.5173233108691896e-05,
      "loss": 0.0001,
      "step": 18890
    },
    {
      "epoch": 3.6741835147744943,
      "grad_norm": 0.005920600611716509,
      "learning_rate": 2.516891308104372e-05,
      "loss": 0.0304,
      "step": 18900
    },
    {
      "epoch": 3.676127527216174,
      "grad_norm": 0.014586623758077621,
      "learning_rate": 2.516459305339554e-05,
      "loss": 0.0008,
      "step": 18910
    },
    {
      "epoch": 3.6780715396578536,
      "grad_norm": 0.01206931658089161,
      "learning_rate": 2.5160273025747365e-05,
      "loss": 0.0003,
      "step": 18920
    },
    {
      "epoch": 3.6800155520995332,
      "grad_norm": 0.0018270844593644142,
      "learning_rate": 2.515595299809919e-05,
      "loss": 0.0001,
      "step": 18930
    },
    {
      "epoch": 3.681959564541213,
      "grad_norm": 0.311007559299469,
      "learning_rate": 2.515163297045101e-05,
      "loss": 0.0002,
      "step": 18940
    },
    {
      "epoch": 3.6839035769828925,
      "grad_norm": 0.0015966471983119845,
      "learning_rate": 2.5147312942802834e-05,
      "loss": 0.0001,
      "step": 18950
    },
    {
      "epoch": 3.685847589424572,
      "grad_norm": 0.0008549520862288773,
      "learning_rate": 2.514299291515466e-05,
      "loss": 0.0002,
      "step": 18960
    },
    {
      "epoch": 3.6877916018662518,
      "grad_norm": 0.001550803193822503,
      "learning_rate": 2.5138672887506482e-05,
      "loss": 0.0001,
      "step": 18970
    },
    {
      "epoch": 3.6897356143079314,
      "grad_norm": 0.0016187779838219285,
      "learning_rate": 2.5134352859858303e-05,
      "loss": 0.0001,
      "step": 18980
    },
    {
      "epoch": 3.691679626749611,
      "grad_norm": 0.0008553596562705934,
      "learning_rate": 2.5130032832210127e-05,
      "loss": 0.0007,
      "step": 18990
    },
    {
      "epoch": 3.6936236391912907,
      "grad_norm": 0.0010215126676484942,
      "learning_rate": 2.512571280456195e-05,
      "loss": 0.009,
      "step": 19000
    },
    {
      "epoch": 3.6955676516329703,
      "grad_norm": 0.000852390076033771,
      "learning_rate": 2.5121392776913772e-05,
      "loss": 0.0062,
      "step": 19010
    },
    {
      "epoch": 3.69751166407465,
      "grad_norm": 0.0011082346318289638,
      "learning_rate": 2.5117072749265596e-05,
      "loss": 0.0002,
      "step": 19020
    },
    {
      "epoch": 3.6994556765163296,
      "grad_norm": 0.0007033415604382753,
      "learning_rate": 2.511275272161742e-05,
      "loss": 0.0104,
      "step": 19030
    },
    {
      "epoch": 3.701399688958009,
      "grad_norm": 0.0019967115949839354,
      "learning_rate": 2.510843269396924e-05,
      "loss": 0.0001,
      "step": 19040
    },
    {
      "epoch": 3.703343701399689,
      "grad_norm": 0.0010624604765325785,
      "learning_rate": 2.5104112666321065e-05,
      "loss": 0.0001,
      "step": 19050
    },
    {
      "epoch": 3.7052877138413685,
      "grad_norm": 0.0010213811183348298,
      "learning_rate": 2.509979263867289e-05,
      "loss": 0.0,
      "step": 19060
    },
    {
      "epoch": 3.707231726283048,
      "grad_norm": 3.5652077198028564,
      "learning_rate": 2.509547261102471e-05,
      "loss": 0.0175,
      "step": 19070
    },
    {
      "epoch": 3.7091757387247277,
      "grad_norm": 0.0021540222223848104,
      "learning_rate": 2.5091152583376534e-05,
      "loss": 0.0037,
      "step": 19080
    },
    {
      "epoch": 3.7111197511664074,
      "grad_norm": 0.000641662220004946,
      "learning_rate": 2.5086832555728358e-05,
      "loss": 0.0001,
      "step": 19090
    },
    {
      "epoch": 3.713063763608087,
      "grad_norm": 0.0022692037746310234,
      "learning_rate": 2.508251252808018e-05,
      "loss": 0.0115,
      "step": 19100
    },
    {
      "epoch": 3.7150077760497666,
      "grad_norm": 0.01106335036456585,
      "learning_rate": 2.5078192500432003e-05,
      "loss": 0.0003,
      "step": 19110
    },
    {
      "epoch": 3.7169517884914463,
      "grad_norm": 0.0054446980357170105,
      "learning_rate": 2.5073872472783827e-05,
      "loss": 0.0005,
      "step": 19120
    },
    {
      "epoch": 3.718895800933126,
      "grad_norm": 0.0040445043705403805,
      "learning_rate": 2.5069552445135648e-05,
      "loss": 0.0002,
      "step": 19130
    },
    {
      "epoch": 3.7208398133748055,
      "grad_norm": 0.0011399921495467424,
      "learning_rate": 2.5065232417487472e-05,
      "loss": 0.0036,
      "step": 19140
    },
    {
      "epoch": 3.722783825816485,
      "grad_norm": 0.0026183812879025936,
      "learning_rate": 2.5060912389839296e-05,
      "loss": 0.0003,
      "step": 19150
    },
    {
      "epoch": 3.724727838258165,
      "grad_norm": 0.003258556593209505,
      "learning_rate": 2.5056592362191117e-05,
      "loss": 0.0001,
      "step": 19160
    },
    {
      "epoch": 3.7266718506998444,
      "grad_norm": 0.000940299651119858,
      "learning_rate": 2.5052272334542944e-05,
      "loss": 0.0001,
      "step": 19170
    },
    {
      "epoch": 3.728615863141524,
      "grad_norm": 0.0007580547244288027,
      "learning_rate": 2.5047952306894765e-05,
      "loss": 0.0001,
      "step": 19180
    },
    {
      "epoch": 3.7305598755832037,
      "grad_norm": 0.0017729491228237748,
      "learning_rate": 2.5043632279246586e-05,
      "loss": 0.0001,
      "step": 19190
    },
    {
      "epoch": 3.7325038880248833,
      "grad_norm": 0.0009557941812090576,
      "learning_rate": 2.5039312251598413e-05,
      "loss": 0.0001,
      "step": 19200
    },
    {
      "epoch": 3.734447900466563,
      "grad_norm": 0.0003552204289007932,
      "learning_rate": 2.5034992223950234e-05,
      "loss": 0.0001,
      "step": 19210
    },
    {
      "epoch": 3.7363919129082426,
      "grad_norm": 0.0003403702285140753,
      "learning_rate": 2.5030672196302055e-05,
      "loss": 0.0001,
      "step": 19220
    },
    {
      "epoch": 3.738335925349922,
      "grad_norm": 0.002744565950706601,
      "learning_rate": 2.5026352168653882e-05,
      "loss": 0.0001,
      "step": 19230
    },
    {
      "epoch": 3.740279937791602,
      "grad_norm": 0.0013614592608064413,
      "learning_rate": 2.5022032141005703e-05,
      "loss": 0.0001,
      "step": 19240
    },
    {
      "epoch": 3.7422239502332815,
      "grad_norm": 0.0020527963060885668,
      "learning_rate": 2.5017712113357524e-05,
      "loss": 0.0001,
      "step": 19250
    },
    {
      "epoch": 3.744167962674961,
      "grad_norm": 0.00043694733176380396,
      "learning_rate": 2.501339208570935e-05,
      "loss": 0.0001,
      "step": 19260
    },
    {
      "epoch": 3.7461119751166407,
      "grad_norm": 0.0016779538709670305,
      "learning_rate": 2.5009072058061172e-05,
      "loss": 0.0001,
      "step": 19270
    },
    {
      "epoch": 3.7480559875583204,
      "grad_norm": 0.0008525290759280324,
      "learning_rate": 2.5004752030412993e-05,
      "loss": 0.0,
      "step": 19280
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.0012602430069819093,
      "learning_rate": 2.500043200276482e-05,
      "loss": 0.0,
      "step": 19290
    },
    {
      "epoch": 3.7519440124416796,
      "grad_norm": 0.0010382102336734533,
      "learning_rate": 2.499611197511664e-05,
      "loss": 0.0,
      "step": 19300
    },
    {
      "epoch": 3.7538880248833593,
      "grad_norm": 0.0008124796440824866,
      "learning_rate": 2.499179194746846e-05,
      "loss": 0.0002,
      "step": 19310
    },
    {
      "epoch": 3.755832037325039,
      "grad_norm": 0.0010290241334587336,
      "learning_rate": 2.498747191982029e-05,
      "loss": 0.0,
      "step": 19320
    },
    {
      "epoch": 3.7577760497667185,
      "grad_norm": 0.000825752504169941,
      "learning_rate": 2.498315189217211e-05,
      "loss": 0.0001,
      "step": 19330
    },
    {
      "epoch": 3.759720062208398,
      "grad_norm": 0.0007730225916020572,
      "learning_rate": 2.497883186452393e-05,
      "loss": 0.0057,
      "step": 19340
    },
    {
      "epoch": 3.761664074650078,
      "grad_norm": 0.00043081509647890925,
      "learning_rate": 2.4974511836875758e-05,
      "loss": 0.0145,
      "step": 19350
    },
    {
      "epoch": 3.7636080870917574,
      "grad_norm": 0.0051739998161792755,
      "learning_rate": 2.497019180922758e-05,
      "loss": 0.0002,
      "step": 19360
    },
    {
      "epoch": 3.765552099533437,
      "grad_norm": 0.001646595192141831,
      "learning_rate": 2.4965871781579403e-05,
      "loss": 0.0002,
      "step": 19370
    },
    {
      "epoch": 3.7674961119751167,
      "grad_norm": 0.0027954918332397938,
      "learning_rate": 2.4961551753931227e-05,
      "loss": 0.0002,
      "step": 19380
    },
    {
      "epoch": 3.7694401244167963,
      "grad_norm": 0.0003267380816396326,
      "learning_rate": 2.4957231726283048e-05,
      "loss": 0.0001,
      "step": 19390
    },
    {
      "epoch": 3.771384136858476,
      "grad_norm": 0.0008600969449616969,
      "learning_rate": 2.4952911698634872e-05,
      "loss": 0.0001,
      "step": 19400
    },
    {
      "epoch": 3.7733281493001556,
      "grad_norm": 0.0011567248729988933,
      "learning_rate": 2.4948591670986696e-05,
      "loss": 0.0001,
      "step": 19410
    },
    {
      "epoch": 3.775272161741835,
      "grad_norm": 0.0015430341009050608,
      "learning_rate": 2.4944271643338517e-05,
      "loss": 0.012,
      "step": 19420
    },
    {
      "epoch": 3.777216174183515,
      "grad_norm": 0.0037424047477543354,
      "learning_rate": 2.493995161569034e-05,
      "loss": 0.0001,
      "step": 19430
    },
    {
      "epoch": 3.7791601866251945,
      "grad_norm": 0.00041069931467063725,
      "learning_rate": 2.4935631588042165e-05,
      "loss": 0.0,
      "step": 19440
    },
    {
      "epoch": 3.781104199066874,
      "grad_norm": 0.0003681741945911199,
      "learning_rate": 2.4931311560393986e-05,
      "loss": 0.0001,
      "step": 19450
    },
    {
      "epoch": 3.7830482115085537,
      "grad_norm": 0.0007106221164576709,
      "learning_rate": 2.492699153274581e-05,
      "loss": 0.0,
      "step": 19460
    },
    {
      "epoch": 3.7849922239502334,
      "grad_norm": 0.0009236151236109436,
      "learning_rate": 2.4922671505097634e-05,
      "loss": 0.0,
      "step": 19470
    },
    {
      "epoch": 3.786936236391913,
      "grad_norm": 0.0009521828033030033,
      "learning_rate": 2.4918351477449455e-05,
      "loss": 0.0019,
      "step": 19480
    },
    {
      "epoch": 3.7888802488335926,
      "grad_norm": 0.12203619629144669,
      "learning_rate": 2.491403144980128e-05,
      "loss": 0.022,
      "step": 19490
    },
    {
      "epoch": 3.7908242612752723,
      "grad_norm": 0.0021758750081062317,
      "learning_rate": 2.4909711422153103e-05,
      "loss": 0.0013,
      "step": 19500
    },
    {
      "epoch": 3.792768273716952,
      "grad_norm": 0.0007980057271197438,
      "learning_rate": 2.4905391394504923e-05,
      "loss": 0.0002,
      "step": 19510
    },
    {
      "epoch": 3.7947122861586315,
      "grad_norm": 0.0006390056223608553,
      "learning_rate": 2.4901071366856748e-05,
      "loss": 0.0,
      "step": 19520
    },
    {
      "epoch": 3.796656298600311,
      "grad_norm": 0.002736342139542103,
      "learning_rate": 2.489675133920857e-05,
      "loss": 0.0186,
      "step": 19530
    },
    {
      "epoch": 3.798600311041991,
      "grad_norm": 0.01087463740259409,
      "learning_rate": 2.4892431311560392e-05,
      "loss": 0.0001,
      "step": 19540
    },
    {
      "epoch": 3.8005443234836704,
      "grad_norm": 0.0056759449653327465,
      "learning_rate": 2.4888111283912217e-05,
      "loss": 0.0001,
      "step": 19550
    },
    {
      "epoch": 3.80248833592535,
      "grad_norm": 0.00033869806793518364,
      "learning_rate": 2.488379125626404e-05,
      "loss": 0.0002,
      "step": 19560
    },
    {
      "epoch": 3.8044323483670297,
      "grad_norm": 0.0009435747051611543,
      "learning_rate": 2.4879471228615865e-05,
      "loss": 0.0001,
      "step": 19570
    },
    {
      "epoch": 3.8063763608087093,
      "grad_norm": 0.0004182986740488559,
      "learning_rate": 2.487515120096769e-05,
      "loss": 0.0001,
      "step": 19580
    },
    {
      "epoch": 3.808320373250389,
      "grad_norm": 0.000319055950967595,
      "learning_rate": 2.487083117331951e-05,
      "loss": 0.0,
      "step": 19590
    },
    {
      "epoch": 3.8102643856920686,
      "grad_norm": 0.00047418195754289627,
      "learning_rate": 2.4866511145671334e-05,
      "loss": 0.0,
      "step": 19600
    },
    {
      "epoch": 3.8122083981337482,
      "grad_norm": 0.00034393611713312566,
      "learning_rate": 2.4862191118023158e-05,
      "loss": 0.0,
      "step": 19610
    },
    {
      "epoch": 3.814152410575428,
      "grad_norm": 0.000660085876006633,
      "learning_rate": 2.485787109037498e-05,
      "loss": 0.0,
      "step": 19620
    },
    {
      "epoch": 3.8160964230171075,
      "grad_norm": 0.0010738271521404386,
      "learning_rate": 2.4853551062726803e-05,
      "loss": 0.0,
      "step": 19630
    },
    {
      "epoch": 3.818040435458787,
      "grad_norm": 0.5276195406913757,
      "learning_rate": 2.4849231035078627e-05,
      "loss": 0.0001,
      "step": 19640
    },
    {
      "epoch": 3.8199844479004668,
      "grad_norm": 0.00036863237619400024,
      "learning_rate": 2.4844911007430447e-05,
      "loss": 0.0,
      "step": 19650
    },
    {
      "epoch": 3.8219284603421464,
      "grad_norm": 0.0006637577898800373,
      "learning_rate": 2.484059097978227e-05,
      "loss": 0.001,
      "step": 19660
    },
    {
      "epoch": 3.823872472783826,
      "grad_norm": 0.0005240946193225682,
      "learning_rate": 2.4836270952134096e-05,
      "loss": 0.0001,
      "step": 19670
    },
    {
      "epoch": 3.8258164852255057,
      "grad_norm": 0.0004991775495000184,
      "learning_rate": 2.4831950924485916e-05,
      "loss": 0.019,
      "step": 19680
    },
    {
      "epoch": 3.8277604976671853,
      "grad_norm": 0.002830847864970565,
      "learning_rate": 2.482763089683774e-05,
      "loss": 0.0001,
      "step": 19690
    },
    {
      "epoch": 3.829704510108865,
      "grad_norm": 0.0007757198181934655,
      "learning_rate": 2.4823310869189565e-05,
      "loss": 0.0001,
      "step": 19700
    },
    {
      "epoch": 3.8316485225505446,
      "grad_norm": 0.0006576108862645924,
      "learning_rate": 2.4818990841541385e-05,
      "loss": 0.0,
      "step": 19710
    },
    {
      "epoch": 3.833592534992224,
      "grad_norm": 0.003987508360296488,
      "learning_rate": 2.481467081389321e-05,
      "loss": 0.0496,
      "step": 19720
    },
    {
      "epoch": 3.835536547433904,
      "grad_norm": 0.002785617485642433,
      "learning_rate": 2.4810350786245034e-05,
      "loss": 0.0001,
      "step": 19730
    },
    {
      "epoch": 3.8374805598755835,
      "grad_norm": 0.001598013681359589,
      "learning_rate": 2.4806030758596854e-05,
      "loss": 0.0001,
      "step": 19740
    },
    {
      "epoch": 3.839424572317263,
      "grad_norm": 0.019243940711021423,
      "learning_rate": 2.480171073094868e-05,
      "loss": 0.0001,
      "step": 19750
    },
    {
      "epoch": 3.8413685847589427,
      "grad_norm": 0.0010370404925197363,
      "learning_rate": 2.4797390703300503e-05,
      "loss": 0.0001,
      "step": 19760
    },
    {
      "epoch": 3.8433125972006223,
      "grad_norm": 0.0014392375014722347,
      "learning_rate": 2.4793070675652327e-05,
      "loss": 0.0124,
      "step": 19770
    },
    {
      "epoch": 3.845256609642302,
      "grad_norm": 0.011814549565315247,
      "learning_rate": 2.4788750648004147e-05,
      "loss": 0.0001,
      "step": 19780
    },
    {
      "epoch": 3.8472006220839816,
      "grad_norm": 0.0008794766617938876,
      "learning_rate": 2.478443062035597e-05,
      "loss": 0.0068,
      "step": 19790
    },
    {
      "epoch": 3.849144634525661,
      "grad_norm": 0.0004923635278828442,
      "learning_rate": 2.4780110592707796e-05,
      "loss": 0.0017,
      "step": 19800
    },
    {
      "epoch": 3.8510886469673404,
      "grad_norm": 0.001004908001050353,
      "learning_rate": 2.4775790565059616e-05,
      "loss": 0.0222,
      "step": 19810
    },
    {
      "epoch": 3.85303265940902,
      "grad_norm": 0.0010531520238146186,
      "learning_rate": 2.477147053741144e-05,
      "loss": 0.0059,
      "step": 19820
    },
    {
      "epoch": 3.8549766718506997,
      "grad_norm": 0.00640775915235281,
      "learning_rate": 2.4767150509763265e-05,
      "loss": 0.0001,
      "step": 19830
    },
    {
      "epoch": 3.8569206842923793,
      "grad_norm": 0.0036148151848465204,
      "learning_rate": 2.4762830482115085e-05,
      "loss": 0.0002,
      "step": 19840
    },
    {
      "epoch": 3.858864696734059,
      "grad_norm": 0.0005337453912943602,
      "learning_rate": 2.475851045446691e-05,
      "loss": 0.0001,
      "step": 19850
    },
    {
      "epoch": 3.8608087091757386,
      "grad_norm": 0.0016494684386998415,
      "learning_rate": 2.4754190426818733e-05,
      "loss": 0.0001,
      "step": 19860
    },
    {
      "epoch": 3.8627527216174182,
      "grad_norm": 0.0010596788488328457,
      "learning_rate": 2.4749870399170554e-05,
      "loss": 0.0005,
      "step": 19870
    },
    {
      "epoch": 3.864696734059098,
      "grad_norm": 5.995049476623535,
      "learning_rate": 2.4745550371522378e-05,
      "loss": 0.0005,
      "step": 19880
    },
    {
      "epoch": 3.8666407465007775,
      "grad_norm": 0.001101566362194717,
      "learning_rate": 2.4741230343874202e-05,
      "loss": 0.0001,
      "step": 19890
    },
    {
      "epoch": 3.868584758942457,
      "grad_norm": 0.0012555918656289577,
      "learning_rate": 2.4736910316226023e-05,
      "loss": 0.0001,
      "step": 19900
    },
    {
      "epoch": 3.8705287713841368,
      "grad_norm": 0.0006812914507463574,
      "learning_rate": 2.4732590288577847e-05,
      "loss": 0.0001,
      "step": 19910
    },
    {
      "epoch": 3.8724727838258164,
      "grad_norm": 0.02074943110346794,
      "learning_rate": 2.472827026092967e-05,
      "loss": 0.0026,
      "step": 19920
    },
    {
      "epoch": 3.874416796267496,
      "grad_norm": 0.0004149019659962505,
      "learning_rate": 2.4723950233281492e-05,
      "loss": 0.0431,
      "step": 19930
    },
    {
      "epoch": 3.8763608087091757,
      "grad_norm": 0.0011190917575731874,
      "learning_rate": 2.471963020563332e-05,
      "loss": 0.0001,
      "step": 19940
    },
    {
      "epoch": 3.8783048211508553,
      "grad_norm": 0.0008963536820374429,
      "learning_rate": 2.471531017798514e-05,
      "loss": 0.0008,
      "step": 19950
    },
    {
      "epoch": 3.880248833592535,
      "grad_norm": 0.0004871496348641813,
      "learning_rate": 2.471099015033696e-05,
      "loss": 0.0171,
      "step": 19960
    },
    {
      "epoch": 3.8821928460342146,
      "grad_norm": 0.0006514668348245323,
      "learning_rate": 2.470667012268879e-05,
      "loss": 0.0292,
      "step": 19970
    },
    {
      "epoch": 3.884136858475894,
      "grad_norm": 0.008131169714033604,
      "learning_rate": 2.470235009504061e-05,
      "loss": 0.0001,
      "step": 19980
    },
    {
      "epoch": 3.886080870917574,
      "grad_norm": 0.00244313501752913,
      "learning_rate": 2.469803006739243e-05,
      "loss": 0.0001,
      "step": 19990
    },
    {
      "epoch": 3.8880248833592534,
      "grad_norm": 0.0006633680895902216,
      "learning_rate": 2.4693710039744257e-05,
      "loss": 0.0215,
      "step": 20000
    },
    {
      "epoch": 3.889968895800933,
      "grad_norm": 0.003710151882842183,
      "learning_rate": 2.4689390012096078e-05,
      "loss": 0.0013,
      "step": 20010
    },
    {
      "epoch": 3.8919129082426127,
      "grad_norm": 0.002369069494307041,
      "learning_rate": 2.46850699844479e-05,
      "loss": 0.0001,
      "step": 20020
    },
    {
      "epoch": 3.8938569206842923,
      "grad_norm": 0.0006171899731270969,
      "learning_rate": 2.4680749956799726e-05,
      "loss": 0.001,
      "step": 20030
    },
    {
      "epoch": 3.895800933125972,
      "grad_norm": 0.0006364876171573997,
      "learning_rate": 2.4676429929151547e-05,
      "loss": 0.0332,
      "step": 20040
    },
    {
      "epoch": 3.8977449455676516,
      "grad_norm": 0.0032821863424032927,
      "learning_rate": 2.4672109901503368e-05,
      "loss": 0.0085,
      "step": 20050
    },
    {
      "epoch": 3.8996889580093312,
      "grad_norm": 46.03361892700195,
      "learning_rate": 2.4667789873855195e-05,
      "loss": 0.0076,
      "step": 20060
    },
    {
      "epoch": 3.901632970451011,
      "grad_norm": 0.0012682812521234155,
      "learning_rate": 2.4663469846207016e-05,
      "loss": 0.0001,
      "step": 20070
    },
    {
      "epoch": 3.9035769828926905,
      "grad_norm": 0.0021561188623309135,
      "learning_rate": 2.4659149818558837e-05,
      "loss": 0.0001,
      "step": 20080
    },
    {
      "epoch": 3.90552099533437,
      "grad_norm": 0.003167320741340518,
      "learning_rate": 2.4654829790910664e-05,
      "loss": 0.001,
      "step": 20090
    },
    {
      "epoch": 3.9074650077760498,
      "grad_norm": 0.002397448057308793,
      "learning_rate": 2.4650509763262485e-05,
      "loss": 0.0027,
      "step": 20100
    },
    {
      "epoch": 3.9094090202177294,
      "grad_norm": 0.0010182043770328164,
      "learning_rate": 2.4646189735614306e-05,
      "loss": 0.0001,
      "step": 20110
    },
    {
      "epoch": 3.911353032659409,
      "grad_norm": 0.0006707607535645366,
      "learning_rate": 2.4641869707966133e-05,
      "loss": 0.0028,
      "step": 20120
    },
    {
      "epoch": 3.9132970451010887,
      "grad_norm": 0.008038530126214027,
      "learning_rate": 2.4637549680317954e-05,
      "loss": 0.0001,
      "step": 20130
    },
    {
      "epoch": 3.9152410575427683,
      "grad_norm": 0.0012969934614375234,
      "learning_rate": 2.4633229652669778e-05,
      "loss": 0.0001,
      "step": 20140
    },
    {
      "epoch": 3.917185069984448,
      "grad_norm": 0.0011865173000842333,
      "learning_rate": 2.4628909625021602e-05,
      "loss": 0.0001,
      "step": 20150
    },
    {
      "epoch": 3.9191290824261276,
      "grad_norm": 0.0009802138665691018,
      "learning_rate": 2.4624589597373423e-05,
      "loss": 0.0001,
      "step": 20160
    },
    {
      "epoch": 3.921073094867807,
      "grad_norm": 0.0006356376688927412,
      "learning_rate": 2.4620269569725247e-05,
      "loss": 0.0001,
      "step": 20170
    },
    {
      "epoch": 3.923017107309487,
      "grad_norm": 0.0005494447541423142,
      "learning_rate": 2.461594954207707e-05,
      "loss": 0.0001,
      "step": 20180
    },
    {
      "epoch": 3.9249611197511665,
      "grad_norm": 0.001024258672259748,
      "learning_rate": 2.4611629514428892e-05,
      "loss": 0.0,
      "step": 20190
    },
    {
      "epoch": 3.926905132192846,
      "grad_norm": 0.0010865706717595458,
      "learning_rate": 2.4607309486780716e-05,
      "loss": 0.0001,
      "step": 20200
    },
    {
      "epoch": 3.9288491446345257,
      "grad_norm": 0.0010740595171228051,
      "learning_rate": 2.460298945913254e-05,
      "loss": 0.0018,
      "step": 20210
    },
    {
      "epoch": 3.9307931570762054,
      "grad_norm": 0.0008502326090820134,
      "learning_rate": 2.459866943148436e-05,
      "loss": 0.0001,
      "step": 20220
    },
    {
      "epoch": 3.932737169517885,
      "grad_norm": 0.0006828258628956974,
      "learning_rate": 2.4594349403836185e-05,
      "loss": 0.0,
      "step": 20230
    },
    {
      "epoch": 3.9346811819595646,
      "grad_norm": 0.0005617267452180386,
      "learning_rate": 2.459002937618801e-05,
      "loss": 0.0003,
      "step": 20240
    },
    {
      "epoch": 3.9366251944012443,
      "grad_norm": 0.0015765723073855042,
      "learning_rate": 2.458570934853983e-05,
      "loss": 0.0106,
      "step": 20250
    },
    {
      "epoch": 3.938569206842924,
      "grad_norm": 0.0004992530448362231,
      "learning_rate": 2.4581389320891654e-05,
      "loss": 0.0,
      "step": 20260
    },
    {
      "epoch": 3.9405132192846035,
      "grad_norm": 0.0004039355553686619,
      "learning_rate": 2.4577069293243478e-05,
      "loss": 0.0174,
      "step": 20270
    },
    {
      "epoch": 3.942457231726283,
      "grad_norm": 0.0012933437246829271,
      "learning_rate": 2.45727492655953e-05,
      "loss": 0.0002,
      "step": 20280
    },
    {
      "epoch": 3.944401244167963,
      "grad_norm": 0.0005011603934690356,
      "learning_rate": 2.4568429237947123e-05,
      "loss": 0.0,
      "step": 20290
    },
    {
      "epoch": 3.9463452566096424,
      "grad_norm": 0.0006825861055403948,
      "learning_rate": 2.4564109210298947e-05,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 3.948289269051322,
      "grad_norm": 0.0004809890815522522,
      "learning_rate": 2.4559789182650768e-05,
      "loss": 0.0,
      "step": 20310
    },
    {
      "epoch": 3.9502332814930017,
      "grad_norm": 0.0007940152427181602,
      "learning_rate": 2.4555469155002592e-05,
      "loss": 0.0002,
      "step": 20320
    },
    {
      "epoch": 3.9521772939346813,
      "grad_norm": 0.7507883310317993,
      "learning_rate": 2.4551149127354416e-05,
      "loss": 0.0005,
      "step": 20330
    },
    {
      "epoch": 3.954121306376361,
      "grad_norm": 0.00036834736238233745,
      "learning_rate": 2.454682909970624e-05,
      "loss": 0.0,
      "step": 20340
    },
    {
      "epoch": 3.9560653188180406,
      "grad_norm": 0.0005861162790097296,
      "learning_rate": 2.454250907205806e-05,
      "loss": 0.0,
      "step": 20350
    },
    {
      "epoch": 3.95800933125972,
      "grad_norm": 0.0009049419895745814,
      "learning_rate": 2.4538189044409885e-05,
      "loss": 0.0123,
      "step": 20360
    },
    {
      "epoch": 3.9599533437014,
      "grad_norm": 0.0014321220805868506,
      "learning_rate": 2.453386901676171e-05,
      "loss": 0.0123,
      "step": 20370
    },
    {
      "epoch": 3.9618973561430795,
      "grad_norm": 0.0008112251525744796,
      "learning_rate": 2.452954898911353e-05,
      "loss": 0.0001,
      "step": 20380
    },
    {
      "epoch": 3.963841368584759,
      "grad_norm": 0.0008418328361585736,
      "learning_rate": 2.4525228961465354e-05,
      "loss": 0.0195,
      "step": 20390
    },
    {
      "epoch": 3.9657853810264383,
      "grad_norm": 0.0009622668731026351,
      "learning_rate": 2.4520908933817178e-05,
      "loss": 0.0002,
      "step": 20400
    },
    {
      "epoch": 3.967729393468118,
      "grad_norm": 0.0005040523828938603,
      "learning_rate": 2.4516588906169e-05,
      "loss": 0.0001,
      "step": 20410
    },
    {
      "epoch": 3.9696734059097976,
      "grad_norm": 0.000746738922316581,
      "learning_rate": 2.4512268878520823e-05,
      "loss": 0.0,
      "step": 20420
    },
    {
      "epoch": 3.971617418351477,
      "grad_norm": 0.0005002251709811389,
      "learning_rate": 2.4507948850872647e-05,
      "loss": 0.0001,
      "step": 20430
    },
    {
      "epoch": 3.973561430793157,
      "grad_norm": 0.001760355313308537,
      "learning_rate": 2.4503628823224467e-05,
      "loss": 0.0082,
      "step": 20440
    },
    {
      "epoch": 3.9755054432348365,
      "grad_norm": 0.0019583741668611765,
      "learning_rate": 2.449930879557629e-05,
      "loss": 0.014,
      "step": 20450
    },
    {
      "epoch": 3.977449455676516,
      "grad_norm": 0.0023438213393092155,
      "learning_rate": 2.4494988767928116e-05,
      "loss": 0.0001,
      "step": 20460
    },
    {
      "epoch": 3.9793934681181957,
      "grad_norm": 0.0014792934525758028,
      "learning_rate": 2.449066874027994e-05,
      "loss": 0.0001,
      "step": 20470
    },
    {
      "epoch": 3.9813374805598754,
      "grad_norm": 0.00036376729258336127,
      "learning_rate": 2.448634871263176e-05,
      "loss": 0.0001,
      "step": 20480
    },
    {
      "epoch": 3.983281493001555,
      "grad_norm": 0.0009505901834927499,
      "learning_rate": 2.4482028684983585e-05,
      "loss": 0.0001,
      "step": 20490
    },
    {
      "epoch": 3.9852255054432346,
      "grad_norm": 0.001534661976620555,
      "learning_rate": 2.447770865733541e-05,
      "loss": 0.0231,
      "step": 20500
    },
    {
      "epoch": 3.9871695178849142,
      "grad_norm": 0.02081017568707466,
      "learning_rate": 2.447338862968723e-05,
      "loss": 0.0005,
      "step": 20510
    },
    {
      "epoch": 3.989113530326594,
      "grad_norm": 0.0022603122051805258,
      "learning_rate": 2.4469068602039054e-05,
      "loss": 0.0071,
      "step": 20520
    },
    {
      "epoch": 3.9910575427682735,
      "grad_norm": 0.004938790574669838,
      "learning_rate": 2.4464748574390878e-05,
      "loss": 0.0002,
      "step": 20530
    },
    {
      "epoch": 3.993001555209953,
      "grad_norm": 0.0023630079813301563,
      "learning_rate": 2.4460428546742702e-05,
      "loss": 0.0012,
      "step": 20540
    },
    {
      "epoch": 3.994945567651633,
      "grad_norm": 0.002612069481983781,
      "learning_rate": 2.4456108519094523e-05,
      "loss": 0.0001,
      "step": 20550
    },
    {
      "epoch": 3.9968895800933124,
      "grad_norm": 4.035825252532959,
      "learning_rate": 2.4451788491446347e-05,
      "loss": 0.0475,
      "step": 20560
    },
    {
      "epoch": 3.998833592534992,
      "grad_norm": 0.008433562703430653,
      "learning_rate": 2.444746846379817e-05,
      "loss": 0.0174,
      "step": 20570
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.9938135682080318,
      "eval_loss": 0.00911762472242117,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.9938135682080318,
          "precision": 0.9932928107315029,
          "recall": 0.9943348720100713,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.9938135682080318,
          "precision": 0.9932928107315029,
          "recall": 0.9943348720100713,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.9938135682080318,
          "precision": 0.9932928107315029,
          "recall": 0.9943348720100713,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9938135682080318,
          "precision": 0.9932928107315028,
          "recall": 0.9943348720100713,
          "support": 9532
        }
      },
      "eval_runtime": 71.9215,
      "eval_samples_per_second": 106.602,
      "eval_steps_per_second": 13.334,
      "step": 20576
    },
    {
      "epoch": 4.000777604976672,
      "grad_norm": 0.022229846566915512,
      "learning_rate": 2.444314843614999e-05,
      "loss": 0.0044,
      "step": 20580
    },
    {
      "epoch": 4.002721617418351,
      "grad_norm": 0.004618231672793627,
      "learning_rate": 2.4438828408501816e-05,
      "loss": 0.0005,
      "step": 20590
    },
    {
      "epoch": 4.004665629860031,
      "grad_norm": 0.0027193203568458557,
      "learning_rate": 2.443450838085364e-05,
      "loss": 0.0009,
      "step": 20600
    },
    {
      "epoch": 4.006609642301711,
      "grad_norm": 7.879278182983398,
      "learning_rate": 2.443018835320546e-05,
      "loss": 0.0051,
      "step": 20610
    },
    {
      "epoch": 4.00855365474339,
      "grad_norm": 0.0023862486705183983,
      "learning_rate": 2.4425868325557285e-05,
      "loss": 0.0001,
      "step": 20620
    },
    {
      "epoch": 4.01049766718507,
      "grad_norm": 0.0019630244933068752,
      "learning_rate": 2.442154829790911e-05,
      "loss": 0.0002,
      "step": 20630
    },
    {
      "epoch": 4.0124416796267495,
      "grad_norm": 0.010537438094615936,
      "learning_rate": 2.441722827026093e-05,
      "loss": 0.0001,
      "step": 20640
    },
    {
      "epoch": 4.014385692068429,
      "grad_norm": 0.0015472614904865623,
      "learning_rate": 2.4412908242612753e-05,
      "loss": 0.0001,
      "step": 20650
    },
    {
      "epoch": 4.016329704510109,
      "grad_norm": 0.01079155970364809,
      "learning_rate": 2.4408588214964578e-05,
      "loss": 0.0002,
      "step": 20660
    },
    {
      "epoch": 4.018273716951788,
      "grad_norm": 0.0016679003601893783,
      "learning_rate": 2.44042681873164e-05,
      "loss": 0.0001,
      "step": 20670
    },
    {
      "epoch": 4.020217729393468,
      "grad_norm": 0.0009245974360965192,
      "learning_rate": 2.4399948159668222e-05,
      "loss": 0.0001,
      "step": 20680
    },
    {
      "epoch": 4.022161741835148,
      "grad_norm": 0.0021645596716552973,
      "learning_rate": 2.4395628132020047e-05,
      "loss": 0.0001,
      "step": 20690
    },
    {
      "epoch": 4.024105754276827,
      "grad_norm": 0.0008115696837194264,
      "learning_rate": 2.4391308104371867e-05,
      "loss": 0.0001,
      "step": 20700
    },
    {
      "epoch": 4.026049766718507,
      "grad_norm": 0.0007417913875542581,
      "learning_rate": 2.438698807672369e-05,
      "loss": 0.0001,
      "step": 20710
    },
    {
      "epoch": 4.0279937791601865,
      "grad_norm": 0.0011157843982800841,
      "learning_rate": 2.4382668049075515e-05,
      "loss": 0.0001,
      "step": 20720
    },
    {
      "epoch": 4.029937791601866,
      "grad_norm": 0.000863805296830833,
      "learning_rate": 2.4378348021427336e-05,
      "loss": 0.0001,
      "step": 20730
    },
    {
      "epoch": 4.031881804043546,
      "grad_norm": 0.0009639774216338992,
      "learning_rate": 2.4374027993779164e-05,
      "loss": 0.0001,
      "step": 20740
    },
    {
      "epoch": 4.033825816485225,
      "grad_norm": 0.0012372849741950631,
      "learning_rate": 2.4369707966130984e-05,
      "loss": 0.0001,
      "step": 20750
    },
    {
      "epoch": 4.035769828926905,
      "grad_norm": 0.000948278873693198,
      "learning_rate": 2.4365387938482805e-05,
      "loss": 0.0001,
      "step": 20760
    },
    {
      "epoch": 4.037713841368585,
      "grad_norm": 0.0008893009508028626,
      "learning_rate": 2.4361067910834633e-05,
      "loss": 0.0021,
      "step": 20770
    },
    {
      "epoch": 4.039657853810264,
      "grad_norm": 0.0007010320550762117,
      "learning_rate": 2.4356747883186453e-05,
      "loss": 0.0,
      "step": 20780
    },
    {
      "epoch": 4.041601866251944,
      "grad_norm": 0.0008616308332420886,
      "learning_rate": 2.4352427855538274e-05,
      "loss": 0.0,
      "step": 20790
    },
    {
      "epoch": 4.043545878693624,
      "grad_norm": 0.0007029681000858545,
      "learning_rate": 2.43481078278901e-05,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 4.045489891135303,
      "grad_norm": 0.0010514984605833888,
      "learning_rate": 2.4343787800241922e-05,
      "loss": 0.0,
      "step": 20810
    },
    {
      "epoch": 4.047433903576983,
      "grad_norm": 0.0005421254318207502,
      "learning_rate": 2.4339467772593743e-05,
      "loss": 0.0134,
      "step": 20820
    },
    {
      "epoch": 4.0493779160186625,
      "grad_norm": 0.001406138762831688,
      "learning_rate": 2.433514774494557e-05,
      "loss": 0.0109,
      "step": 20830
    },
    {
      "epoch": 4.051321928460342,
      "grad_norm": 0.004575219936668873,
      "learning_rate": 2.433082771729739e-05,
      "loss": 0.0007,
      "step": 20840
    },
    {
      "epoch": 4.053265940902022,
      "grad_norm": 0.022838888689875603,
      "learning_rate": 2.4326507689649212e-05,
      "loss": 0.0001,
      "step": 20850
    },
    {
      "epoch": 4.055209953343701,
      "grad_norm": 3.351616859436035,
      "learning_rate": 2.432218766200104e-05,
      "loss": 0.0019,
      "step": 20860
    },
    {
      "epoch": 4.057153965785381,
      "grad_norm": 0.0007244293810799718,
      "learning_rate": 2.431786763435286e-05,
      "loss": 0.0,
      "step": 20870
    },
    {
      "epoch": 4.059097978227061,
      "grad_norm": 0.0006362586282193661,
      "learning_rate": 2.431354760670468e-05,
      "loss": 0.0,
      "step": 20880
    },
    {
      "epoch": 4.06104199066874,
      "grad_norm": 0.0004948669811710715,
      "learning_rate": 2.430922757905651e-05,
      "loss": 0.0005,
      "step": 20890
    },
    {
      "epoch": 4.06298600311042,
      "grad_norm": 0.018670324236154556,
      "learning_rate": 2.430490755140833e-05,
      "loss": 0.0001,
      "step": 20900
    },
    {
      "epoch": 4.0649300155520995,
      "grad_norm": 0.0005056950612924993,
      "learning_rate": 2.4300587523760153e-05,
      "loss": 0.0001,
      "step": 20910
    },
    {
      "epoch": 4.066874027993779,
      "grad_norm": 0.0005472461343742907,
      "learning_rate": 2.4296267496111977e-05,
      "loss": 0.0001,
      "step": 20920
    },
    {
      "epoch": 4.068818040435459,
      "grad_norm": 0.0006321269902400672,
      "learning_rate": 2.4291947468463798e-05,
      "loss": 0.0025,
      "step": 20930
    },
    {
      "epoch": 4.070762052877138,
      "grad_norm": 0.0008286910015158355,
      "learning_rate": 2.4287627440815622e-05,
      "loss": 0.0,
      "step": 20940
    },
    {
      "epoch": 4.072706065318818,
      "grad_norm": 0.000638782512396574,
      "learning_rate": 2.4283307413167446e-05,
      "loss": 0.0001,
      "step": 20950
    },
    {
      "epoch": 4.074650077760498,
      "grad_norm": 0.00054698227904737,
      "learning_rate": 2.4278987385519267e-05,
      "loss": 0.0001,
      "step": 20960
    },
    {
      "epoch": 4.076594090202177,
      "grad_norm": 0.0006968042580410838,
      "learning_rate": 2.427466735787109e-05,
      "loss": 0.0,
      "step": 20970
    },
    {
      "epoch": 4.078538102643857,
      "grad_norm": 0.0005944091826677322,
      "learning_rate": 2.4270347330222915e-05,
      "loss": 0.0,
      "step": 20980
    },
    {
      "epoch": 4.080482115085537,
      "grad_norm": 0.0007156252977438271,
      "learning_rate": 2.4266027302574736e-05,
      "loss": 0.0,
      "step": 20990
    },
    {
      "epoch": 4.082426127527216,
      "grad_norm": 0.0005838618380948901,
      "learning_rate": 2.426170727492656e-05,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 4.084370139968896,
      "grad_norm": 0.002139824442565441,
      "learning_rate": 2.4257387247278384e-05,
      "loss": 0.0001,
      "step": 21010
    },
    {
      "epoch": 4.0863141524105755,
      "grad_norm": 0.0004901874926872551,
      "learning_rate": 2.4253067219630205e-05,
      "loss": 0.0,
      "step": 21020
    },
    {
      "epoch": 4.088258164852255,
      "grad_norm": 0.0005405413685366511,
      "learning_rate": 2.424874719198203e-05,
      "loss": 0.0,
      "step": 21030
    },
    {
      "epoch": 4.090202177293935,
      "grad_norm": 0.0019831988029181957,
      "learning_rate": 2.4244427164333853e-05,
      "loss": 0.0185,
      "step": 21040
    },
    {
      "epoch": 4.092146189735614,
      "grad_norm": 0.023404540494084358,
      "learning_rate": 2.4240107136685674e-05,
      "loss": 0.0003,
      "step": 21050
    },
    {
      "epoch": 4.094090202177294,
      "grad_norm": 0.019668709486722946,
      "learning_rate": 2.4235787109037498e-05,
      "loss": 0.0119,
      "step": 21060
    },
    {
      "epoch": 4.096034214618974,
      "grad_norm": 0.012417206540703773,
      "learning_rate": 2.4231467081389322e-05,
      "loss": 0.0004,
      "step": 21070
    },
    {
      "epoch": 4.097978227060653,
      "grad_norm": 0.00550175691023469,
      "learning_rate": 2.4227147053741143e-05,
      "loss": 0.0001,
      "step": 21080
    },
    {
      "epoch": 4.099922239502333,
      "grad_norm": 0.0023314394056797028,
      "learning_rate": 2.4222827026092967e-05,
      "loss": 0.0001,
      "step": 21090
    },
    {
      "epoch": 4.1018662519440126,
      "grad_norm": 2.3649842739105225,
      "learning_rate": 2.421850699844479e-05,
      "loss": 0.0154,
      "step": 21100
    },
    {
      "epoch": 4.103810264385692,
      "grad_norm": 0.0008051624754443765,
      "learning_rate": 2.4214186970796615e-05,
      "loss": 0.0002,
      "step": 21110
    },
    {
      "epoch": 4.105754276827372,
      "grad_norm": 0.0008690714603289962,
      "learning_rate": 2.4209866943148436e-05,
      "loss": 0.0002,
      "step": 21120
    },
    {
      "epoch": 4.1076982892690515,
      "grad_norm": 0.012283760122954845,
      "learning_rate": 2.420554691550026e-05,
      "loss": 0.0002,
      "step": 21130
    },
    {
      "epoch": 4.109642301710731,
      "grad_norm": 0.0010336112463846803,
      "learning_rate": 2.4201226887852084e-05,
      "loss": 0.0005,
      "step": 21140
    },
    {
      "epoch": 4.111586314152411,
      "grad_norm": 0.0008660103776492178,
      "learning_rate": 2.4196906860203905e-05,
      "loss": 0.0074,
      "step": 21150
    },
    {
      "epoch": 4.11353032659409,
      "grad_norm": 0.0007740826113149524,
      "learning_rate": 2.419258683255573e-05,
      "loss": 0.0001,
      "step": 21160
    },
    {
      "epoch": 4.11547433903577,
      "grad_norm": 0.001791489077731967,
      "learning_rate": 2.4188266804907553e-05,
      "loss": 0.0001,
      "step": 21170
    },
    {
      "epoch": 4.11741835147745,
      "grad_norm": 0.0003959718451369554,
      "learning_rate": 2.4183946777259374e-05,
      "loss": 0.0001,
      "step": 21180
    },
    {
      "epoch": 4.119362363919129,
      "grad_norm": 0.0012614513980224729,
      "learning_rate": 2.4179626749611198e-05,
      "loss": 0.0001,
      "step": 21190
    },
    {
      "epoch": 4.121306376360809,
      "grad_norm": 0.0008163372403942049,
      "learning_rate": 2.4175306721963022e-05,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 4.1232503888024885,
      "grad_norm": 0.0009933068649843335,
      "learning_rate": 2.4170986694314843e-05,
      "loss": 0.0001,
      "step": 21210
    },
    {
      "epoch": 4.125194401244168,
      "grad_norm": 0.0004516560002230108,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.0,
      "step": 21220
    },
    {
      "epoch": 4.127138413685848,
      "grad_norm": 0.0008438472868874669,
      "learning_rate": 2.416234663901849e-05,
      "loss": 0.0,
      "step": 21230
    },
    {
      "epoch": 4.129082426127527,
      "grad_norm": 0.0026407046243548393,
      "learning_rate": 2.415802661137031e-05,
      "loss": 0.0001,
      "step": 21240
    },
    {
      "epoch": 4.131026438569207,
      "grad_norm": 0.0005193030228838325,
      "learning_rate": 2.4153706583722136e-05,
      "loss": 0.0,
      "step": 21250
    },
    {
      "epoch": 4.132970451010887,
      "grad_norm": 5.585245132446289,
      "learning_rate": 2.414938655607396e-05,
      "loss": 0.011,
      "step": 21260
    },
    {
      "epoch": 4.134914463452566,
      "grad_norm": 0.0007004103390499949,
      "learning_rate": 2.414506652842578e-05,
      "loss": 0.0001,
      "step": 21270
    },
    {
      "epoch": 4.136858475894246,
      "grad_norm": 0.00041428295662626624,
      "learning_rate": 2.4140746500777605e-05,
      "loss": 0.0169,
      "step": 21280
    },
    {
      "epoch": 4.138802488335926,
      "grad_norm": 0.002151220105588436,
      "learning_rate": 2.413642647312943e-05,
      "loss": 0.0065,
      "step": 21290
    },
    {
      "epoch": 4.140746500777605,
      "grad_norm": 0.0012275762856006622,
      "learning_rate": 2.413210644548125e-05,
      "loss": 0.0001,
      "step": 21300
    },
    {
      "epoch": 4.142690513219285,
      "grad_norm": 0.0012345419963821769,
      "learning_rate": 2.4127786417833077e-05,
      "loss": 0.0,
      "step": 21310
    },
    {
      "epoch": 4.1446345256609645,
      "grad_norm": 0.0006346727604977787,
      "learning_rate": 2.4123466390184898e-05,
      "loss": 0.0145,
      "step": 21320
    },
    {
      "epoch": 4.146578538102644,
      "grad_norm": 0.03624570369720459,
      "learning_rate": 2.411914636253672e-05,
      "loss": 0.0014,
      "step": 21330
    },
    {
      "epoch": 4.148522550544324,
      "grad_norm": 0.0028777807019650936,
      "learning_rate": 2.4114826334888546e-05,
      "loss": 0.0003,
      "step": 21340
    },
    {
      "epoch": 4.150466562986003,
      "grad_norm": 0.0038253236562013626,
      "learning_rate": 2.4110506307240367e-05,
      "loss": 0.0001,
      "step": 21350
    },
    {
      "epoch": 4.152410575427683,
      "grad_norm": 0.001738888444378972,
      "learning_rate": 2.4106186279592187e-05,
      "loss": 0.0001,
      "step": 21360
    },
    {
      "epoch": 4.154354587869363,
      "grad_norm": 0.0004961913218721747,
      "learning_rate": 2.4101866251944015e-05,
      "loss": 0.0001,
      "step": 21370
    },
    {
      "epoch": 4.156298600311042,
      "grad_norm": 0.00110435183160007,
      "learning_rate": 2.4097546224295836e-05,
      "loss": 0.0001,
      "step": 21380
    },
    {
      "epoch": 4.158242612752722,
      "grad_norm": 3.1780552864074707,
      "learning_rate": 2.409322619664766e-05,
      "loss": 0.007,
      "step": 21390
    },
    {
      "epoch": 4.1601866251944015,
      "grad_norm": 0.0012718377402052283,
      "learning_rate": 2.4088906168999484e-05,
      "loss": 0.0001,
      "step": 21400
    },
    {
      "epoch": 4.162130637636081,
      "grad_norm": 0.00042920626583509147,
      "learning_rate": 2.4084586141351305e-05,
      "loss": 0.0,
      "step": 21410
    },
    {
      "epoch": 4.164074650077761,
      "grad_norm": 0.0010820068418979645,
      "learning_rate": 2.408026611370313e-05,
      "loss": 0.0001,
      "step": 21420
    },
    {
      "epoch": 4.16601866251944,
      "grad_norm": 0.0010500699281692505,
      "learning_rate": 2.4075946086054953e-05,
      "loss": 0.0211,
      "step": 21430
    },
    {
      "epoch": 4.16796267496112,
      "grad_norm": 0.0003188174159731716,
      "learning_rate": 2.4071626058406774e-05,
      "loss": 0.0134,
      "step": 21440
    },
    {
      "epoch": 4.1699066874028,
      "grad_norm": 0.0005853255861438811,
      "learning_rate": 2.4067306030758598e-05,
      "loss": 0.0001,
      "step": 21450
    },
    {
      "epoch": 4.171850699844479,
      "grad_norm": 0.0014535390073433518,
      "learning_rate": 2.4062986003110422e-05,
      "loss": 0.0001,
      "step": 21460
    },
    {
      "epoch": 4.173794712286159,
      "grad_norm": 0.0006412375951185822,
      "learning_rate": 2.4058665975462242e-05,
      "loss": 0.0,
      "step": 21470
    },
    {
      "epoch": 4.175738724727839,
      "grad_norm": 0.000929361442103982,
      "learning_rate": 2.4054345947814067e-05,
      "loss": 0.0,
      "step": 21480
    },
    {
      "epoch": 4.177682737169518,
      "grad_norm": 0.0007263667066581547,
      "learning_rate": 2.405002592016589e-05,
      "loss": 0.0,
      "step": 21490
    },
    {
      "epoch": 4.179626749611198,
      "grad_norm": 0.0009415464010089636,
      "learning_rate": 2.404570589251771e-05,
      "loss": 0.0001,
      "step": 21500
    },
    {
      "epoch": 4.1815707620528775,
      "grad_norm": 0.004167135339230299,
      "learning_rate": 2.404138586486954e-05,
      "loss": 0.0004,
      "step": 21510
    },
    {
      "epoch": 4.183514774494557,
      "grad_norm": 14.542043685913086,
      "learning_rate": 2.403706583722136e-05,
      "loss": 0.0065,
      "step": 21520
    },
    {
      "epoch": 4.185458786936237,
      "grad_norm": 0.0006446862826123834,
      "learning_rate": 2.403274580957318e-05,
      "loss": 0.0081,
      "step": 21530
    },
    {
      "epoch": 4.187402799377916,
      "grad_norm": 0.0005314521258696914,
      "learning_rate": 2.4028425781925008e-05,
      "loss": 0.0005,
      "step": 21540
    },
    {
      "epoch": 4.189346811819596,
      "grad_norm": 0.006047350820153952,
      "learning_rate": 2.402410575427683e-05,
      "loss": 0.0001,
      "step": 21550
    },
    {
      "epoch": 4.191290824261276,
      "grad_norm": 0.0005947197205387056,
      "learning_rate": 2.401978572662865e-05,
      "loss": 0.0,
      "step": 21560
    },
    {
      "epoch": 4.193234836702955,
      "grad_norm": 0.0009212904260493815,
      "learning_rate": 2.4015465698980477e-05,
      "loss": 0.0,
      "step": 21570
    },
    {
      "epoch": 4.195178849144635,
      "grad_norm": 0.0004450072883628309,
      "learning_rate": 2.4011145671332298e-05,
      "loss": 0.0001,
      "step": 21580
    },
    {
      "epoch": 4.1971228615863145,
      "grad_norm": 0.0006194667657837272,
      "learning_rate": 2.4006825643684118e-05,
      "loss": 0.0001,
      "step": 21590
    },
    {
      "epoch": 4.199066874027994,
      "grad_norm": 0.0003627921105362475,
      "learning_rate": 2.4002505616035946e-05,
      "loss": 0.0,
      "step": 21600
    },
    {
      "epoch": 4.201010886469674,
      "grad_norm": 0.0006090333336032927,
      "learning_rate": 2.3998185588387766e-05,
      "loss": 0.0,
      "step": 21610
    },
    {
      "epoch": 4.202954898911353,
      "grad_norm": 0.003998288884758949,
      "learning_rate": 2.3993865560739587e-05,
      "loss": 0.0,
      "step": 21620
    },
    {
      "epoch": 4.204898911353033,
      "grad_norm": 0.0006642063963226974,
      "learning_rate": 2.3989545533091415e-05,
      "loss": 0.0,
      "step": 21630
    },
    {
      "epoch": 4.206842923794713,
      "grad_norm": 0.0006398297846317291,
      "learning_rate": 2.3985225505443235e-05,
      "loss": 0.0,
      "step": 21640
    },
    {
      "epoch": 4.208786936236392,
      "grad_norm": 0.0004873419238720089,
      "learning_rate": 2.3980905477795056e-05,
      "loss": 0.0,
      "step": 21650
    },
    {
      "epoch": 4.210730948678072,
      "grad_norm": 0.0005398905486799777,
      "learning_rate": 2.3976585450146884e-05,
      "loss": 0.0,
      "step": 21660
    },
    {
      "epoch": 4.212674961119752,
      "grad_norm": 0.00041641853749752045,
      "learning_rate": 2.3972265422498704e-05,
      "loss": 0.0066,
      "step": 21670
    },
    {
      "epoch": 4.21461897356143,
      "grad_norm": 0.0005260572652332485,
      "learning_rate": 2.3967945394850525e-05,
      "loss": 0.0088,
      "step": 21680
    },
    {
      "epoch": 4.21656298600311,
      "grad_norm": 5.036745071411133,
      "learning_rate": 2.3963625367202353e-05,
      "loss": 0.017,
      "step": 21690
    },
    {
      "epoch": 4.21850699844479,
      "grad_norm": 0.0009524475899524987,
      "learning_rate": 2.3959305339554173e-05,
      "loss": 0.0,
      "step": 21700
    },
    {
      "epoch": 4.220451010886469,
      "grad_norm": 0.0011636343551799655,
      "learning_rate": 2.3954985311905997e-05,
      "loss": 0.0006,
      "step": 21710
    },
    {
      "epoch": 4.222395023328149,
      "grad_norm": 0.001094565144740045,
      "learning_rate": 2.395066528425782e-05,
      "loss": 0.0002,
      "step": 21720
    },
    {
      "epoch": 4.2243390357698285,
      "grad_norm": 0.0009680820512585342,
      "learning_rate": 2.3946345256609642e-05,
      "loss": 0.0001,
      "step": 21730
    },
    {
      "epoch": 4.226283048211508,
      "grad_norm": 0.0011217480059713125,
      "learning_rate": 2.3942025228961466e-05,
      "loss": 0.0001,
      "step": 21740
    },
    {
      "epoch": 4.228227060653188,
      "grad_norm": 0.0011591973016038537,
      "learning_rate": 2.393770520131329e-05,
      "loss": 0.0001,
      "step": 21750
    },
    {
      "epoch": 4.230171073094867,
      "grad_norm": 0.0011310273548588157,
      "learning_rate": 2.393338517366511e-05,
      "loss": 0.0,
      "step": 21760
    },
    {
      "epoch": 4.232115085536547,
      "grad_norm": 0.004006545525044203,
      "learning_rate": 2.3929065146016935e-05,
      "loss": 0.0,
      "step": 21770
    },
    {
      "epoch": 4.234059097978227,
      "grad_norm": 0.0008872149046510458,
      "learning_rate": 2.392474511836876e-05,
      "loss": 0.0,
      "step": 21780
    },
    {
      "epoch": 4.236003110419906,
      "grad_norm": 0.0010952857555821538,
      "learning_rate": 2.392042509072058e-05,
      "loss": 0.0,
      "step": 21790
    },
    {
      "epoch": 4.237947122861586,
      "grad_norm": 0.0008021511603146791,
      "learning_rate": 2.3916105063072404e-05,
      "loss": 0.0,
      "step": 21800
    },
    {
      "epoch": 4.239891135303266,
      "grad_norm": 0.0008109586196951568,
      "learning_rate": 2.391178503542423e-05,
      "loss": 0.0114,
      "step": 21810
    },
    {
      "epoch": 4.241835147744945,
      "grad_norm": 0.0007544063264504075,
      "learning_rate": 2.390746500777605e-05,
      "loss": 0.0,
      "step": 21820
    },
    {
      "epoch": 4.243779160186625,
      "grad_norm": 0.0005832487950101495,
      "learning_rate": 2.3903144980127873e-05,
      "loss": 0.0,
      "step": 21830
    },
    {
      "epoch": 4.2457231726283045,
      "grad_norm": 0.0005765227833762765,
      "learning_rate": 2.3898824952479697e-05,
      "loss": 0.0,
      "step": 21840
    },
    {
      "epoch": 4.247667185069984,
      "grad_norm": 0.0006546024233102798,
      "learning_rate": 2.3894504924831518e-05,
      "loss": 0.0,
      "step": 21850
    },
    {
      "epoch": 4.249611197511664,
      "grad_norm": 0.001717860926873982,
      "learning_rate": 2.3890184897183342e-05,
      "loss": 0.0,
      "step": 21860
    },
    {
      "epoch": 4.251555209953343,
      "grad_norm": 0.0005821364466100931,
      "learning_rate": 2.3885864869535166e-05,
      "loss": 0.0,
      "step": 21870
    },
    {
      "epoch": 4.253499222395023,
      "grad_norm": 0.0006321121472865343,
      "learning_rate": 2.3881544841886987e-05,
      "loss": 0.0,
      "step": 21880
    },
    {
      "epoch": 4.255443234836703,
      "grad_norm": 0.0006771975895389915,
      "learning_rate": 2.387722481423881e-05,
      "loss": 0.001,
      "step": 21890
    },
    {
      "epoch": 4.257387247278382,
      "grad_norm": 0.0009605201194062829,
      "learning_rate": 2.3872904786590635e-05,
      "loss": 0.0001,
      "step": 21900
    },
    {
      "epoch": 4.259331259720062,
      "grad_norm": 0.0005576441762968898,
      "learning_rate": 2.386858475894246e-05,
      "loss": 0.0029,
      "step": 21910
    },
    {
      "epoch": 4.2612752721617415,
      "grad_norm": 0.0005473921191878617,
      "learning_rate": 2.386426473129428e-05,
      "loss": 0.0,
      "step": 21920
    },
    {
      "epoch": 4.263219284603421,
      "grad_norm": 0.0005865137209184468,
      "learning_rate": 2.3859944703646104e-05,
      "loss": 0.0,
      "step": 21930
    },
    {
      "epoch": 4.265163297045101,
      "grad_norm": 0.0005407285061664879,
      "learning_rate": 2.3855624675997928e-05,
      "loss": 0.0,
      "step": 21940
    },
    {
      "epoch": 4.26710730948678,
      "grad_norm": 2.4554619789123535,
      "learning_rate": 2.385130464834975e-05,
      "loss": 0.0126,
      "step": 21950
    },
    {
      "epoch": 4.26905132192846,
      "grad_norm": 0.0005431681056506932,
      "learning_rate": 2.3846984620701573e-05,
      "loss": 0.0,
      "step": 21960
    },
    {
      "epoch": 4.27099533437014,
      "grad_norm": 0.0005346465623006225,
      "learning_rate": 2.3842664593053397e-05,
      "loss": 0.0001,
      "step": 21970
    },
    {
      "epoch": 4.272939346811819,
      "grad_norm": 0.0005398275097832084,
      "learning_rate": 2.3838344565405218e-05,
      "loss": 0.0,
      "step": 21980
    },
    {
      "epoch": 4.274883359253499,
      "grad_norm": 0.000620408623944968,
      "learning_rate": 2.3834024537757042e-05,
      "loss": 0.0,
      "step": 21990
    },
    {
      "epoch": 4.276827371695179,
      "grad_norm": 0.0005026533035561442,
      "learning_rate": 2.3829704510108866e-05,
      "loss": 0.0,
      "step": 22000
    },
    {
      "epoch": 4.278771384136858,
      "grad_norm": 0.00048482095007784665,
      "learning_rate": 2.3825384482460687e-05,
      "loss": 0.0,
      "step": 22010
    },
    {
      "epoch": 4.280715396578538,
      "grad_norm": 0.0012724149273708463,
      "learning_rate": 2.382106445481251e-05,
      "loss": 0.0,
      "step": 22020
    },
    {
      "epoch": 4.2826594090202175,
      "grad_norm": 0.0004987056599929929,
      "learning_rate": 2.3816744427164335e-05,
      "loss": 0.0,
      "step": 22030
    },
    {
      "epoch": 4.284603421461897,
      "grad_norm": 0.0004287324845790863,
      "learning_rate": 2.3812424399516156e-05,
      "loss": 0.0,
      "step": 22040
    },
    {
      "epoch": 4.286547433903577,
      "grad_norm": 0.0004192535416223109,
      "learning_rate": 2.380810437186798e-05,
      "loss": 0.0,
      "step": 22050
    },
    {
      "epoch": 4.288491446345256,
      "grad_norm": 0.0028500892221927643,
      "learning_rate": 2.3803784344219804e-05,
      "loss": 0.0,
      "step": 22060
    },
    {
      "epoch": 4.290435458786936,
      "grad_norm": 0.00043933518463745713,
      "learning_rate": 2.3799464316571625e-05,
      "loss": 0.0285,
      "step": 22070
    },
    {
      "epoch": 4.292379471228616,
      "grad_norm": 0.003097384236752987,
      "learning_rate": 2.379514428892345e-05,
      "loss": 0.0,
      "step": 22080
    },
    {
      "epoch": 4.294323483670295,
      "grad_norm": 0.0004617625381797552,
      "learning_rate": 2.3790824261275273e-05,
      "loss": 0.0004,
      "step": 22090
    },
    {
      "epoch": 4.296267496111975,
      "grad_norm": 0.00044716979027725756,
      "learning_rate": 2.3786504233627094e-05,
      "loss": 0.0091,
      "step": 22100
    },
    {
      "epoch": 4.2982115085536545,
      "grad_norm": 0.00047464476665481925,
      "learning_rate": 2.378218420597892e-05,
      "loss": 0.032,
      "step": 22110
    },
    {
      "epoch": 4.300155520995334,
      "grad_norm": 0.0004003057547379285,
      "learning_rate": 2.3777864178330742e-05,
      "loss": 0.0001,
      "step": 22120
    },
    {
      "epoch": 4.302099533437014,
      "grad_norm": 0.0006555684958584607,
      "learning_rate": 2.3773544150682563e-05,
      "loss": 0.0002,
      "step": 22130
    },
    {
      "epoch": 4.304043545878693,
      "grad_norm": 0.0004043866356369108,
      "learning_rate": 2.376922412303439e-05,
      "loss": 0.0,
      "step": 22140
    },
    {
      "epoch": 4.305987558320373,
      "grad_norm": 0.00043508410453796387,
      "learning_rate": 2.376490409538621e-05,
      "loss": 0.0,
      "step": 22150
    },
    {
      "epoch": 4.307931570762053,
      "grad_norm": 0.0057208351790905,
      "learning_rate": 2.376058406773803e-05,
      "loss": 0.0206,
      "step": 22160
    },
    {
      "epoch": 4.309875583203732,
      "grad_norm": 0.008891463279724121,
      "learning_rate": 2.375626404008986e-05,
      "loss": 0.0004,
      "step": 22170
    },
    {
      "epoch": 4.311819595645412,
      "grad_norm": 0.00651897769421339,
      "learning_rate": 2.375194401244168e-05,
      "loss": 0.0002,
      "step": 22180
    },
    {
      "epoch": 4.313763608087092,
      "grad_norm": 0.07318134605884552,
      "learning_rate": 2.37476239847935e-05,
      "loss": 0.0001,
      "step": 22190
    },
    {
      "epoch": 4.315707620528771,
      "grad_norm": 0.0008403761312365532,
      "learning_rate": 2.3743303957145328e-05,
      "loss": 0.0032,
      "step": 22200
    },
    {
      "epoch": 4.317651632970451,
      "grad_norm": 0.001083854935131967,
      "learning_rate": 2.373898392949715e-05,
      "loss": 0.0003,
      "step": 22210
    },
    {
      "epoch": 4.3195956454121305,
      "grad_norm": 0.0007780167507007718,
      "learning_rate": 2.373466390184897e-05,
      "loss": 0.0001,
      "step": 22220
    },
    {
      "epoch": 4.32153965785381,
      "grad_norm": 0.0009537755395285785,
      "learning_rate": 2.3730343874200797e-05,
      "loss": 0.0001,
      "step": 22230
    },
    {
      "epoch": 4.32348367029549,
      "grad_norm": 0.0009122273768298328,
      "learning_rate": 2.3726023846552618e-05,
      "loss": 0.0266,
      "step": 22240
    },
    {
      "epoch": 4.325427682737169,
      "grad_norm": 0.000609678216278553,
      "learning_rate": 2.372170381890444e-05,
      "loss": 0.0001,
      "step": 22250
    },
    {
      "epoch": 4.327371695178849,
      "grad_norm": 0.0005980915739201009,
      "learning_rate": 2.3717383791256266e-05,
      "loss": 0.0,
      "step": 22260
    },
    {
      "epoch": 4.329315707620529,
      "grad_norm": 0.001258733100257814,
      "learning_rate": 2.3713063763608087e-05,
      "loss": 0.0,
      "step": 22270
    },
    {
      "epoch": 4.331259720062208,
      "grad_norm": 0.0007138348883017898,
      "learning_rate": 2.370874373595991e-05,
      "loss": 0.0,
      "step": 22280
    },
    {
      "epoch": 4.333203732503888,
      "grad_norm": 0.0006366079323925078,
      "learning_rate": 2.3704423708311735e-05,
      "loss": 0.0155,
      "step": 22290
    },
    {
      "epoch": 4.3351477449455675,
      "grad_norm": 3.7021288871765137,
      "learning_rate": 2.3700103680663556e-05,
      "loss": 0.0015,
      "step": 22300
    },
    {
      "epoch": 4.337091757387247,
      "grad_norm": 0.00050271739019081,
      "learning_rate": 2.3695783653015383e-05,
      "loss": 0.0001,
      "step": 22310
    },
    {
      "epoch": 4.339035769828927,
      "grad_norm": 39.84132385253906,
      "learning_rate": 2.3691463625367204e-05,
      "loss": 0.0068,
      "step": 22320
    },
    {
      "epoch": 4.340979782270606,
      "grad_norm": 0.024458466097712517,
      "learning_rate": 2.3687143597719024e-05,
      "loss": 0.0,
      "step": 22330
    },
    {
      "epoch": 4.342923794712286,
      "grad_norm": 0.033409200608730316,
      "learning_rate": 2.3682823570070852e-05,
      "loss": 0.0,
      "step": 22340
    },
    {
      "epoch": 4.344867807153966,
      "grad_norm": 0.07734577357769012,
      "learning_rate": 2.3678503542422673e-05,
      "loss": 0.0001,
      "step": 22350
    },
    {
      "epoch": 4.346811819595645,
      "grad_norm": 0.00040832586819306016,
      "learning_rate": 2.3674183514774493e-05,
      "loss": 0.0086,
      "step": 22360
    },
    {
      "epoch": 4.348755832037325,
      "grad_norm": 0.0006456142873503268,
      "learning_rate": 2.366986348712632e-05,
      "loss": 0.0,
      "step": 22370
    },
    {
      "epoch": 4.350699844479005,
      "grad_norm": 0.00040630463627167046,
      "learning_rate": 2.366554345947814e-05,
      "loss": 0.0,
      "step": 22380
    },
    {
      "epoch": 4.352643856920684,
      "grad_norm": 0.00042986005428247154,
      "learning_rate": 2.3661223431829962e-05,
      "loss": 0.0,
      "step": 22390
    },
    {
      "epoch": 4.354587869362364,
      "grad_norm": 0.572209358215332,
      "learning_rate": 2.365690340418179e-05,
      "loss": 0.0122,
      "step": 22400
    },
    {
      "epoch": 4.3565318818040435,
      "grad_norm": 0.00045134028187021613,
      "learning_rate": 2.365258337653361e-05,
      "loss": 0.0,
      "step": 22410
    },
    {
      "epoch": 4.358475894245723,
      "grad_norm": 0.0004462807846721262,
      "learning_rate": 2.364826334888543e-05,
      "loss": 0.0427,
      "step": 22420
    },
    {
      "epoch": 4.360419906687403,
      "grad_norm": 0.000501953181810677,
      "learning_rate": 2.364394332123726e-05,
      "loss": 0.0,
      "step": 22430
    },
    {
      "epoch": 4.362363919129082,
      "grad_norm": 0.6101222634315491,
      "learning_rate": 2.363962329358908e-05,
      "loss": 0.0147,
      "step": 22440
    },
    {
      "epoch": 4.364307931570762,
      "grad_norm": 0.0005161163862794638,
      "learning_rate": 2.36353032659409e-05,
      "loss": 0.0006,
      "step": 22450
    },
    {
      "epoch": 4.366251944012442,
      "grad_norm": 0.0005846641142852604,
      "learning_rate": 2.3630983238292728e-05,
      "loss": 0.0,
      "step": 22460
    },
    {
      "epoch": 4.368195956454121,
      "grad_norm": 0.0005107178003527224,
      "learning_rate": 2.362666321064455e-05,
      "loss": 0.0001,
      "step": 22470
    },
    {
      "epoch": 4.370139968895801,
      "grad_norm": 0.0006133636925369501,
      "learning_rate": 2.3622343182996373e-05,
      "loss": 0.0126,
      "step": 22480
    },
    {
      "epoch": 4.3720839813374806,
      "grad_norm": 0.0005187169299460948,
      "learning_rate": 2.3618023155348197e-05,
      "loss": 0.0,
      "step": 22490
    },
    {
      "epoch": 4.37402799377916,
      "grad_norm": 0.0005461367545649409,
      "learning_rate": 2.3613703127700017e-05,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 4.37597200622084,
      "grad_norm": 0.0007193103083409369,
      "learning_rate": 2.360938310005184e-05,
      "loss": 0.0169,
      "step": 22510
    },
    {
      "epoch": 4.3779160186625194,
      "grad_norm": 0.0004960693186149001,
      "learning_rate": 2.3605063072403666e-05,
      "loss": 0.0,
      "step": 22520
    },
    {
      "epoch": 4.379860031104199,
      "grad_norm": 0.010658939369022846,
      "learning_rate": 2.3600743044755486e-05,
      "loss": 0.0344,
      "step": 22530
    },
    {
      "epoch": 4.381804043545879,
      "grad_norm": 0.015046571381390095,
      "learning_rate": 2.359642301710731e-05,
      "loss": 0.001,
      "step": 22540
    },
    {
      "epoch": 4.383748055987558,
      "grad_norm": 0.005422502756118774,
      "learning_rate": 2.3592102989459135e-05,
      "loss": 0.0049,
      "step": 22550
    },
    {
      "epoch": 4.385692068429238,
      "grad_norm": 0.012248288840055466,
      "learning_rate": 2.3587782961810955e-05,
      "loss": 0.0003,
      "step": 22560
    },
    {
      "epoch": 4.387636080870918,
      "grad_norm": 0.0032954681664705276,
      "learning_rate": 2.358346293416278e-05,
      "loss": 0.0002,
      "step": 22570
    },
    {
      "epoch": 4.389580093312597,
      "grad_norm": 0.012775986455380917,
      "learning_rate": 2.3579142906514604e-05,
      "loss": 0.0002,
      "step": 22580
    },
    {
      "epoch": 4.391524105754277,
      "grad_norm": 0.0022609508596360683,
      "learning_rate": 2.3574822878866424e-05,
      "loss": 0.0002,
      "step": 22590
    },
    {
      "epoch": 4.3934681181959565,
      "grad_norm": 0.013445353135466576,
      "learning_rate": 2.357050285121825e-05,
      "loss": 0.0001,
      "step": 22600
    },
    {
      "epoch": 4.395412130637636,
      "grad_norm": 0.0024156246799975634,
      "learning_rate": 2.3566182823570072e-05,
      "loss": 0.0001,
      "step": 22610
    },
    {
      "epoch": 4.397356143079316,
      "grad_norm": 0.004917123354971409,
      "learning_rate": 2.3561862795921893e-05,
      "loss": 0.0001,
      "step": 22620
    },
    {
      "epoch": 4.399300155520995,
      "grad_norm": 0.001648845849558711,
      "learning_rate": 2.3557542768273717e-05,
      "loss": 0.0001,
      "step": 22630
    },
    {
      "epoch": 4.401244167962675,
      "grad_norm": 0.0013237487291917205,
      "learning_rate": 2.355322274062554e-05,
      "loss": 0.0045,
      "step": 22640
    },
    {
      "epoch": 4.403188180404355,
      "grad_norm": 0.0018742253305390477,
      "learning_rate": 2.3548902712977362e-05,
      "loss": 0.0001,
      "step": 22650
    },
    {
      "epoch": 4.405132192846034,
      "grad_norm": 0.001381176058202982,
      "learning_rate": 2.3544582685329186e-05,
      "loss": 0.0001,
      "step": 22660
    },
    {
      "epoch": 4.407076205287714,
      "grad_norm": 0.0007782963220961392,
      "learning_rate": 2.354026265768101e-05,
      "loss": 0.0003,
      "step": 22670
    },
    {
      "epoch": 4.409020217729394,
      "grad_norm": 0.0008831453160382807,
      "learning_rate": 2.3535942630032834e-05,
      "loss": 0.0,
      "step": 22680
    },
    {
      "epoch": 4.410964230171073,
      "grad_norm": 0.0024326848797500134,
      "learning_rate": 2.3531622602384655e-05,
      "loss": 0.0175,
      "step": 22690
    },
    {
      "epoch": 4.412908242612753,
      "grad_norm": 0.00479594012722373,
      "learning_rate": 2.352730257473648e-05,
      "loss": 0.0002,
      "step": 22700
    },
    {
      "epoch": 4.4148522550544325,
      "grad_norm": 0.0054668341763317585,
      "learning_rate": 2.3522982547088303e-05,
      "loss": 0.0002,
      "step": 22710
    },
    {
      "epoch": 4.416796267496112,
      "grad_norm": 0.002962520346045494,
      "learning_rate": 2.3518662519440124e-05,
      "loss": 0.0002,
      "step": 22720
    },
    {
      "epoch": 4.418740279937792,
      "grad_norm": 0.0021364481654018164,
      "learning_rate": 2.3514342491791948e-05,
      "loss": 0.0002,
      "step": 22730
    },
    {
      "epoch": 4.420684292379471,
      "grad_norm": 0.0030323569662868977,
      "learning_rate": 2.3510022464143772e-05,
      "loss": 0.0001,
      "step": 22740
    },
    {
      "epoch": 4.422628304821151,
      "grad_norm": 0.002934283809736371,
      "learning_rate": 2.3505702436495593e-05,
      "loss": 0.0002,
      "step": 22750
    },
    {
      "epoch": 4.424572317262831,
      "grad_norm": 0.0014644963666796684,
      "learning_rate": 2.3501382408847417e-05,
      "loss": 0.0001,
      "step": 22760
    },
    {
      "epoch": 4.42651632970451,
      "grad_norm": 0.001859308802522719,
      "learning_rate": 2.349706238119924e-05,
      "loss": 0.0001,
      "step": 22770
    },
    {
      "epoch": 4.42846034214619,
      "grad_norm": 0.0014563418226316571,
      "learning_rate": 2.3492742353551062e-05,
      "loss": 0.0001,
      "step": 22780
    },
    {
      "epoch": 4.4304043545878695,
      "grad_norm": 0.004135172814130783,
      "learning_rate": 2.3488422325902886e-05,
      "loss": 0.0001,
      "step": 22790
    },
    {
      "epoch": 4.432348367029549,
      "grad_norm": 0.008515419438481331,
      "learning_rate": 2.348410229825471e-05,
      "loss": 0.0002,
      "step": 22800
    },
    {
      "epoch": 4.434292379471229,
      "grad_norm": 0.0009969340171664953,
      "learning_rate": 2.347978227060653e-05,
      "loss": 0.0001,
      "step": 22810
    },
    {
      "epoch": 4.436236391912908,
      "grad_norm": 0.0009571410482749343,
      "learning_rate": 2.3475462242958355e-05,
      "loss": 0.0226,
      "step": 22820
    },
    {
      "epoch": 4.438180404354588,
      "grad_norm": 0.0009790376061573625,
      "learning_rate": 2.347114221531018e-05,
      "loss": 0.0001,
      "step": 22830
    },
    {
      "epoch": 4.440124416796268,
      "grad_norm": 0.0017623718595132232,
      "learning_rate": 2.3466822187662e-05,
      "loss": 0.0132,
      "step": 22840
    },
    {
      "epoch": 4.442068429237947,
      "grad_norm": 0.010998477227985859,
      "learning_rate": 2.3462502160013824e-05,
      "loss": 0.0002,
      "step": 22850
    },
    {
      "epoch": 4.444012441679627,
      "grad_norm": 0.003230463247746229,
      "learning_rate": 2.3458182132365648e-05,
      "loss": 0.0008,
      "step": 22860
    },
    {
      "epoch": 4.445956454121307,
      "grad_norm": 0.0037157447077333927,
      "learning_rate": 2.345386210471747e-05,
      "loss": 0.0002,
      "step": 22870
    },
    {
      "epoch": 4.447900466562986,
      "grad_norm": 0.0006532373954541981,
      "learning_rate": 2.3449542077069296e-05,
      "loss": 0.0078,
      "step": 22880
    },
    {
      "epoch": 4.449844479004666,
      "grad_norm": 0.0028705650474876165,
      "learning_rate": 2.3445222049421117e-05,
      "loss": 0.0001,
      "step": 22890
    },
    {
      "epoch": 4.4517884914463455,
      "grad_norm": 0.0016437661834061146,
      "learning_rate": 2.3440902021772938e-05,
      "loss": 0.0001,
      "step": 22900
    },
    {
      "epoch": 4.453732503888025,
      "grad_norm": 0.0017516989028081298,
      "learning_rate": 2.3436581994124765e-05,
      "loss": 0.0001,
      "step": 22910
    },
    {
      "epoch": 4.455676516329705,
      "grad_norm": 0.005933429580181837,
      "learning_rate": 2.3432261966476586e-05,
      "loss": 0.0001,
      "step": 22920
    },
    {
      "epoch": 4.457620528771384,
      "grad_norm": 0.0008512152126058936,
      "learning_rate": 2.3427941938828407e-05,
      "loss": 0.0235,
      "step": 22930
    },
    {
      "epoch": 4.459564541213064,
      "grad_norm": 8.996615409851074,
      "learning_rate": 2.3423621911180234e-05,
      "loss": 0.0018,
      "step": 22940
    },
    {
      "epoch": 4.461508553654744,
      "grad_norm": 17.3125057220459,
      "learning_rate": 2.3419301883532055e-05,
      "loss": 0.0202,
      "step": 22950
    },
    {
      "epoch": 4.463452566096423,
      "grad_norm": 0.006532303988933563,
      "learning_rate": 2.3414981855883876e-05,
      "loss": 0.0004,
      "step": 22960
    },
    {
      "epoch": 4.465396578538103,
      "grad_norm": 0.006094621494412422,
      "learning_rate": 2.3410661828235703e-05,
      "loss": 0.0002,
      "step": 22970
    },
    {
      "epoch": 4.4673405909797825,
      "grad_norm": 0.003993351943790913,
      "learning_rate": 2.3406341800587524e-05,
      "loss": 0.0108,
      "step": 22980
    },
    {
      "epoch": 4.469284603421462,
      "grad_norm": 0.004204474855214357,
      "learning_rate": 2.3402021772939345e-05,
      "loss": 0.0003,
      "step": 22990
    },
    {
      "epoch": 4.471228615863142,
      "grad_norm": 27.161134719848633,
      "learning_rate": 2.3397701745291172e-05,
      "loss": 0.0048,
      "step": 23000
    },
    {
      "epoch": 4.473172628304821,
      "grad_norm": 0.005622438620775938,
      "learning_rate": 2.3393381717642993e-05,
      "loss": 0.0002,
      "step": 23010
    },
    {
      "epoch": 4.475116640746501,
      "grad_norm": 0.003977817017585039,
      "learning_rate": 2.3389061689994814e-05,
      "loss": 0.0068,
      "step": 23020
    },
    {
      "epoch": 4.477060653188181,
      "grad_norm": 0.005398801527917385,
      "learning_rate": 2.338474166234664e-05,
      "loss": 0.0002,
      "step": 23030
    },
    {
      "epoch": 4.47900466562986,
      "grad_norm": 0.0025501090567559004,
      "learning_rate": 2.3380421634698462e-05,
      "loss": 0.0001,
      "step": 23040
    },
    {
      "epoch": 4.48094867807154,
      "grad_norm": 0.006793173961341381,
      "learning_rate": 2.3376101607050283e-05,
      "loss": 0.0001,
      "step": 23050
    },
    {
      "epoch": 4.48289269051322,
      "grad_norm": 0.004873370751738548,
      "learning_rate": 2.337178157940211e-05,
      "loss": 0.0148,
      "step": 23060
    },
    {
      "epoch": 4.484836702954899,
      "grad_norm": 0.007773402612656355,
      "learning_rate": 2.336746155175393e-05,
      "loss": 0.0001,
      "step": 23070
    },
    {
      "epoch": 4.486780715396579,
      "grad_norm": 0.008833269588649273,
      "learning_rate": 2.3363141524105755e-05,
      "loss": 0.014,
      "step": 23080
    },
    {
      "epoch": 4.4887247278382585,
      "grad_norm": 0.01986624486744404,
      "learning_rate": 2.335882149645758e-05,
      "loss": 0.0007,
      "step": 23090
    },
    {
      "epoch": 4.490668740279938,
      "grad_norm": 0.01184183917939663,
      "learning_rate": 2.33545014688094e-05,
      "loss": 0.0006,
      "step": 23100
    },
    {
      "epoch": 4.492612752721618,
      "grad_norm": 0.002043155487626791,
      "learning_rate": 2.3350181441161224e-05,
      "loss": 0.0002,
      "step": 23110
    },
    {
      "epoch": 4.494556765163297,
      "grad_norm": 0.0033652789425104856,
      "learning_rate": 2.3345861413513048e-05,
      "loss": 0.0005,
      "step": 23120
    },
    {
      "epoch": 4.496500777604977,
      "grad_norm": 0.0019534335006028414,
      "learning_rate": 2.334154138586487e-05,
      "loss": 0.0001,
      "step": 23130
    },
    {
      "epoch": 4.498444790046657,
      "grad_norm": 0.003573198802769184,
      "learning_rate": 2.3337221358216693e-05,
      "loss": 0.0036,
      "step": 23140
    },
    {
      "epoch": 4.500388802488336,
      "grad_norm": 0.018584048375487328,
      "learning_rate": 2.3332901330568517e-05,
      "loss": 0.0001,
      "step": 23150
    },
    {
      "epoch": 4.502332814930016,
      "grad_norm": 0.001071829698048532,
      "learning_rate": 2.3328581302920338e-05,
      "loss": 0.0001,
      "step": 23160
    },
    {
      "epoch": 4.5042768273716955,
      "grad_norm": 0.0007555575575679541,
      "learning_rate": 2.3324261275272162e-05,
      "loss": 0.0001,
      "step": 23170
    },
    {
      "epoch": 4.506220839813375,
      "grad_norm": 0.0013271222123876214,
      "learning_rate": 2.3319941247623986e-05,
      "loss": 0.0001,
      "step": 23180
    },
    {
      "epoch": 4.508164852255055,
      "grad_norm": 0.0025039208121597767,
      "learning_rate": 2.3315621219975807e-05,
      "loss": 0.0005,
      "step": 23190
    },
    {
      "epoch": 4.510108864696734,
      "grad_norm": 0.0008547049365006387,
      "learning_rate": 2.3311301192327634e-05,
      "loss": 0.0,
      "step": 23200
    },
    {
      "epoch": 4.512052877138414,
      "grad_norm": 0.0008922143606469035,
      "learning_rate": 2.3306981164679455e-05,
      "loss": 0.0001,
      "step": 23210
    },
    {
      "epoch": 4.513996889580094,
      "grad_norm": 0.0006524645141325891,
      "learning_rate": 2.3302661137031275e-05,
      "loss": 0.0001,
      "step": 23220
    },
    {
      "epoch": 4.515940902021773,
      "grad_norm": 0.0007072489825077355,
      "learning_rate": 2.3298341109383103e-05,
      "loss": 0.0011,
      "step": 23230
    },
    {
      "epoch": 4.517884914463453,
      "grad_norm": 0.0006371516501531005,
      "learning_rate": 2.3294021081734924e-05,
      "loss": 0.0001,
      "step": 23240
    },
    {
      "epoch": 4.519828926905133,
      "grad_norm": 0.0059886714443564415,
      "learning_rate": 2.3289701054086744e-05,
      "loss": 0.0,
      "step": 23250
    },
    {
      "epoch": 4.521772939346812,
      "grad_norm": 0.03862867131829262,
      "learning_rate": 2.3285381026438572e-05,
      "loss": 0.0001,
      "step": 23260
    },
    {
      "epoch": 4.523716951788492,
      "grad_norm": 0.015466799959540367,
      "learning_rate": 2.3281060998790393e-05,
      "loss": 0.0001,
      "step": 23270
    },
    {
      "epoch": 4.5256609642301715,
      "grad_norm": 0.0006568380631506443,
      "learning_rate": 2.3276740971142217e-05,
      "loss": 0.0001,
      "step": 23280
    },
    {
      "epoch": 4.527604976671851,
      "grad_norm": 0.0005212178803049028,
      "learning_rate": 2.327242094349404e-05,
      "loss": 0.0,
      "step": 23290
    },
    {
      "epoch": 4.529548989113531,
      "grad_norm": 0.0007251639617606997,
      "learning_rate": 2.326810091584586e-05,
      "loss": 0.0,
      "step": 23300
    },
    {
      "epoch": 4.53149300155521,
      "grad_norm": 0.0006417297990992665,
      "learning_rate": 2.3263780888197686e-05,
      "loss": 0.0,
      "step": 23310
    },
    {
      "epoch": 4.53343701399689,
      "grad_norm": 0.0007317928830161691,
      "learning_rate": 2.325946086054951e-05,
      "loss": 0.0327,
      "step": 23320
    },
    {
      "epoch": 4.53538102643857,
      "grad_norm": 0.00213471706956625,
      "learning_rate": 2.325514083290133e-05,
      "loss": 0.0001,
      "step": 23330
    },
    {
      "epoch": 4.537325038880249,
      "grad_norm": 0.0025114607997238636,
      "learning_rate": 2.3250820805253155e-05,
      "loss": 0.0007,
      "step": 23340
    },
    {
      "epoch": 4.539269051321929,
      "grad_norm": 0.0005064121796749532,
      "learning_rate": 2.324650077760498e-05,
      "loss": 0.0001,
      "step": 23350
    },
    {
      "epoch": 4.541213063763609,
      "grad_norm": 0.001052440027706325,
      "learning_rate": 2.32421807499568e-05,
      "loss": 0.0001,
      "step": 23360
    },
    {
      "epoch": 4.543157076205288,
      "grad_norm": 0.0008831885643303394,
      "learning_rate": 2.3237860722308624e-05,
      "loss": 0.017,
      "step": 23370
    },
    {
      "epoch": 4.545101088646968,
      "grad_norm": 0.0005217539728619158,
      "learning_rate": 2.3233540694660448e-05,
      "loss": 0.0019,
      "step": 23380
    },
    {
      "epoch": 4.5470451010886475,
      "grad_norm": 0.0016396077116951346,
      "learning_rate": 2.322922066701227e-05,
      "loss": 0.0017,
      "step": 23390
    },
    {
      "epoch": 4.548989113530327,
      "grad_norm": 0.0012464739847928286,
      "learning_rate": 2.3224900639364093e-05,
      "loss": 0.0249,
      "step": 23400
    },
    {
      "epoch": 4.550933125972006,
      "grad_norm": 1.965484619140625,
      "learning_rate": 2.3220580611715917e-05,
      "loss": 0.0016,
      "step": 23410
    },
    {
      "epoch": 4.5528771384136855,
      "grad_norm": 0.0022275629453361034,
      "learning_rate": 2.3216260584067737e-05,
      "loss": 0.0001,
      "step": 23420
    },
    {
      "epoch": 4.554821150855365,
      "grad_norm": 0.025051062926650047,
      "learning_rate": 2.321194055641956e-05,
      "loss": 0.0001,
      "step": 23430
    },
    {
      "epoch": 4.556765163297045,
      "grad_norm": 0.0008602578891441226,
      "learning_rate": 2.3207620528771386e-05,
      "loss": 0.0001,
      "step": 23440
    },
    {
      "epoch": 4.558709175738724,
      "grad_norm": 0.0004667624889407307,
      "learning_rate": 2.320330050112321e-05,
      "loss": 0.0148,
      "step": 23450
    },
    {
      "epoch": 4.560653188180404,
      "grad_norm": 0.0009928321233019233,
      "learning_rate": 2.319898047347503e-05,
      "loss": 0.0002,
      "step": 23460
    },
    {
      "epoch": 4.562597200622084,
      "grad_norm": 0.00042084965389221907,
      "learning_rate": 2.3194660445826855e-05,
      "loss": 0.0,
      "step": 23470
    },
    {
      "epoch": 4.564541213063763,
      "grad_norm": 0.00043934391578659415,
      "learning_rate": 2.319034041817868e-05,
      "loss": 0.0013,
      "step": 23480
    },
    {
      "epoch": 4.566485225505443,
      "grad_norm": 0.0008018957450985909,
      "learning_rate": 2.31860203905305e-05,
      "loss": 0.0001,
      "step": 23490
    },
    {
      "epoch": 4.5684292379471225,
      "grad_norm": 0.00037947899545542896,
      "learning_rate": 2.3181700362882323e-05,
      "loss": 0.0053,
      "step": 23500
    },
    {
      "epoch": 4.570373250388802,
      "grad_norm": 0.0010130866430699825,
      "learning_rate": 2.3177380335234148e-05,
      "loss": 0.0,
      "step": 23510
    },
    {
      "epoch": 4.572317262830482,
      "grad_norm": 0.0004709167988039553,
      "learning_rate": 2.3173060307585968e-05,
      "loss": 0.001,
      "step": 23520
    },
    {
      "epoch": 4.574261275272161,
      "grad_norm": 0.00040060997707769275,
      "learning_rate": 2.3168740279937792e-05,
      "loss": 0.0,
      "step": 23530
    },
    {
      "epoch": 4.576205287713841,
      "grad_norm": 0.00036768571590073407,
      "learning_rate": 2.3164420252289617e-05,
      "loss": 0.0,
      "step": 23540
    },
    {
      "epoch": 4.578149300155521,
      "grad_norm": 0.00047592108603566885,
      "learning_rate": 2.3160100224641437e-05,
      "loss": 0.0,
      "step": 23550
    },
    {
      "epoch": 4.5800933125972,
      "grad_norm": 0.0007187508163042367,
      "learning_rate": 2.315578019699326e-05,
      "loss": 0.018,
      "step": 23560
    },
    {
      "epoch": 4.58203732503888,
      "grad_norm": 0.0008963731816038489,
      "learning_rate": 2.3151460169345085e-05,
      "loss": 0.04,
      "step": 23570
    },
    {
      "epoch": 4.58398133748056,
      "grad_norm": 0.0025925012305378914,
      "learning_rate": 2.3147140141696906e-05,
      "loss": 0.0001,
      "step": 23580
    },
    {
      "epoch": 4.585925349922239,
      "grad_norm": 0.012964483350515366,
      "learning_rate": 2.314282011404873e-05,
      "loss": 0.0603,
      "step": 23590
    },
    {
      "epoch": 4.587869362363919,
      "grad_norm": 0.09214130789041519,
      "learning_rate": 2.3138500086400554e-05,
      "loss": 0.002,
      "step": 23600
    },
    {
      "epoch": 4.5898133748055985,
      "grad_norm": 0.014777809381484985,
      "learning_rate": 2.3134180058752375e-05,
      "loss": 0.0011,
      "step": 23610
    },
    {
      "epoch": 4.591757387247278,
      "grad_norm": 0.013326245360076427,
      "learning_rate": 2.31298600311042e-05,
      "loss": 0.0059,
      "step": 23620
    },
    {
      "epoch": 4.593701399688958,
      "grad_norm": 0.003259993391111493,
      "learning_rate": 2.3125540003456023e-05,
      "loss": 0.0096,
      "step": 23630
    },
    {
      "epoch": 4.595645412130637,
      "grad_norm": 0.11760035157203674,
      "learning_rate": 2.3121219975807844e-05,
      "loss": 0.0004,
      "step": 23640
    },
    {
      "epoch": 4.597589424572317,
      "grad_norm": 0.0021419059485197067,
      "learning_rate": 2.311689994815967e-05,
      "loss": 0.0038,
      "step": 23650
    },
    {
      "epoch": 4.599533437013997,
      "grad_norm": 0.0014686728827655315,
      "learning_rate": 2.3112579920511492e-05,
      "loss": 0.001,
      "step": 23660
    },
    {
      "epoch": 4.601477449455676,
      "grad_norm": 0.2100786566734314,
      "learning_rate": 2.3108259892863313e-05,
      "loss": 0.0003,
      "step": 23670
    },
    {
      "epoch": 4.603421461897356,
      "grad_norm": 0.0017809063429012895,
      "learning_rate": 2.310393986521514e-05,
      "loss": 0.0003,
      "step": 23680
    },
    {
      "epoch": 4.6053654743390355,
      "grad_norm": 0.0026385688688606024,
      "learning_rate": 2.309961983756696e-05,
      "loss": 0.0001,
      "step": 23690
    },
    {
      "epoch": 4.607309486780715,
      "grad_norm": 0.002160952426493168,
      "learning_rate": 2.3095299809918782e-05,
      "loss": 0.0001,
      "step": 23700
    },
    {
      "epoch": 4.609253499222395,
      "grad_norm": 0.0010260079288855195,
      "learning_rate": 2.309097978227061e-05,
      "loss": 0.0001,
      "step": 23710
    },
    {
      "epoch": 4.611197511664074,
      "grad_norm": 0.002325918059796095,
      "learning_rate": 2.308665975462243e-05,
      "loss": 0.0001,
      "step": 23720
    },
    {
      "epoch": 4.613141524105754,
      "grad_norm": 0.002381528029218316,
      "learning_rate": 2.308233972697425e-05,
      "loss": 0.0007,
      "step": 23730
    },
    {
      "epoch": 4.615085536547434,
      "grad_norm": 0.002123369835317135,
      "learning_rate": 2.307801969932608e-05,
      "loss": 0.0001,
      "step": 23740
    },
    {
      "epoch": 4.617029548989113,
      "grad_norm": 0.0012420893181115389,
      "learning_rate": 2.30736996716779e-05,
      "loss": 0.0136,
      "step": 23750
    },
    {
      "epoch": 4.618973561430793,
      "grad_norm": 0.0012774851638823748,
      "learning_rate": 2.306937964402972e-05,
      "loss": 0.0001,
      "step": 23760
    },
    {
      "epoch": 4.620917573872473,
      "grad_norm": 0.0005434668273665011,
      "learning_rate": 2.3065059616381547e-05,
      "loss": 0.0001,
      "step": 23770
    },
    {
      "epoch": 4.622861586314152,
      "grad_norm": 0.0014142284635454416,
      "learning_rate": 2.3060739588733368e-05,
      "loss": 0.0001,
      "step": 23780
    },
    {
      "epoch": 4.624805598755832,
      "grad_norm": 0.0007909558480605483,
      "learning_rate": 2.305641956108519e-05,
      "loss": 0.0001,
      "step": 23790
    },
    {
      "epoch": 4.6267496111975115,
      "grad_norm": 0.0011453874176368117,
      "learning_rate": 2.3052099533437016e-05,
      "loss": 0.0001,
      "step": 23800
    },
    {
      "epoch": 4.628693623639191,
      "grad_norm": 0.000855141959618777,
      "learning_rate": 2.3047779505788837e-05,
      "loss": 0.0242,
      "step": 23810
    },
    {
      "epoch": 4.630637636080871,
      "grad_norm": 0.00599792692810297,
      "learning_rate": 2.3043459478140658e-05,
      "loss": 0.021,
      "step": 23820
    },
    {
      "epoch": 4.63258164852255,
      "grad_norm": 0.0023291828110814095,
      "learning_rate": 2.3039139450492485e-05,
      "loss": 0.0067,
      "step": 23830
    },
    {
      "epoch": 4.63452566096423,
      "grad_norm": 0.002711439272388816,
      "learning_rate": 2.3034819422844306e-05,
      "loss": 0.0002,
      "step": 23840
    },
    {
      "epoch": 4.63646967340591,
      "grad_norm": 0.005658054258674383,
      "learning_rate": 2.303049939519613e-05,
      "loss": 0.0002,
      "step": 23850
    },
    {
      "epoch": 4.638413685847589,
      "grad_norm": 1.2989487648010254,
      "learning_rate": 2.3026179367547954e-05,
      "loss": 0.0004,
      "step": 23860
    },
    {
      "epoch": 4.640357698289269,
      "grad_norm": 0.0025346665643155575,
      "learning_rate": 2.3021859339899775e-05,
      "loss": 0.0026,
      "step": 23870
    },
    {
      "epoch": 4.6423017107309485,
      "grad_norm": 0.0019845219794660807,
      "learning_rate": 2.30175393122516e-05,
      "loss": 0.0011,
      "step": 23880
    },
    {
      "epoch": 4.644245723172628,
      "grad_norm": 0.002381807891651988,
      "learning_rate": 2.3013219284603423e-05,
      "loss": 0.0001,
      "step": 23890
    },
    {
      "epoch": 4.646189735614308,
      "grad_norm": 0.0014263708144426346,
      "learning_rate": 2.3008899256955244e-05,
      "loss": 0.0001,
      "step": 23900
    },
    {
      "epoch": 4.6481337480559874,
      "grad_norm": 0.0014907009899616241,
      "learning_rate": 2.3004579229307068e-05,
      "loss": 0.0237,
      "step": 23910
    },
    {
      "epoch": 4.650077760497667,
      "grad_norm": 0.005124966613948345,
      "learning_rate": 2.3000259201658892e-05,
      "loss": 0.0003,
      "step": 23920
    },
    {
      "epoch": 4.652021772939347,
      "grad_norm": 0.0030935725662857294,
      "learning_rate": 2.2995939174010713e-05,
      "loss": 0.0002,
      "step": 23930
    },
    {
      "epoch": 4.653965785381026,
      "grad_norm": 0.033931534737348557,
      "learning_rate": 2.2991619146362537e-05,
      "loss": 0.0002,
      "step": 23940
    },
    {
      "epoch": 4.655909797822706,
      "grad_norm": 0.0014230115339159966,
      "learning_rate": 2.298729911871436e-05,
      "loss": 0.0002,
      "step": 23950
    },
    {
      "epoch": 4.657853810264386,
      "grad_norm": 0.0017543368740007281,
      "learning_rate": 2.2982979091066182e-05,
      "loss": 0.0001,
      "step": 23960
    },
    {
      "epoch": 4.659797822706065,
      "grad_norm": 0.9366825222969055,
      "learning_rate": 2.2978659063418006e-05,
      "loss": 0.0001,
      "step": 23970
    },
    {
      "epoch": 4.661741835147745,
      "grad_norm": 0.0021202254574745893,
      "learning_rate": 2.297433903576983e-05,
      "loss": 0.056,
      "step": 23980
    },
    {
      "epoch": 4.6636858475894245,
      "grad_norm": 0.00621969997882843,
      "learning_rate": 2.297001900812165e-05,
      "loss": 0.0119,
      "step": 23990
    },
    {
      "epoch": 4.665629860031104,
      "grad_norm": 0.04486294835805893,
      "learning_rate": 2.2965698980473475e-05,
      "loss": 0.0134,
      "step": 24000
    },
    {
      "epoch": 4.667573872472784,
      "grad_norm": 0.0030232826247811317,
      "learning_rate": 2.29613789528253e-05,
      "loss": 0.0004,
      "step": 24010
    },
    {
      "epoch": 4.669517884914463,
      "grad_norm": 0.009407483041286469,
      "learning_rate": 2.295705892517712e-05,
      "loss": 0.0002,
      "step": 24020
    },
    {
      "epoch": 4.671461897356143,
      "grad_norm": 0.0018623066134750843,
      "learning_rate": 2.2952738897528944e-05,
      "loss": 0.0236,
      "step": 24030
    },
    {
      "epoch": 4.673405909797823,
      "grad_norm": 0.007686882745474577,
      "learning_rate": 2.2948418869880768e-05,
      "loss": 0.0002,
      "step": 24040
    },
    {
      "epoch": 4.675349922239502,
      "grad_norm": 0.0036206920631229877,
      "learning_rate": 2.2944098842232592e-05,
      "loss": 0.0058,
      "step": 24050
    },
    {
      "epoch": 4.677293934681182,
      "grad_norm": 0.0015445949975401163,
      "learning_rate": 2.2939778814584413e-05,
      "loss": 0.0002,
      "step": 24060
    },
    {
      "epoch": 4.679237947122862,
      "grad_norm": 0.0015115351416170597,
      "learning_rate": 2.2935458786936237e-05,
      "loss": 0.0001,
      "step": 24070
    },
    {
      "epoch": 4.681181959564541,
      "grad_norm": 0.003197869984433055,
      "learning_rate": 2.293113875928806e-05,
      "loss": 0.0001,
      "step": 24080
    },
    {
      "epoch": 4.683125972006221,
      "grad_norm": 0.0022185358684509993,
      "learning_rate": 2.2926818731639885e-05,
      "loss": 0.0512,
      "step": 24090
    },
    {
      "epoch": 4.6850699844479005,
      "grad_norm": 0.0009540553437545896,
      "learning_rate": 2.2922498703991706e-05,
      "loss": 0.0007,
      "step": 24100
    },
    {
      "epoch": 4.68701399688958,
      "grad_norm": 0.006394562311470509,
      "learning_rate": 2.291817867634353e-05,
      "loss": 0.0137,
      "step": 24110
    },
    {
      "epoch": 4.68895800933126,
      "grad_norm": 0.0016680607805028558,
      "learning_rate": 2.2913858648695354e-05,
      "loss": 0.0003,
      "step": 24120
    },
    {
      "epoch": 4.690902021772939,
      "grad_norm": 0.0032916341442614794,
      "learning_rate": 2.2909538621047175e-05,
      "loss": 0.0005,
      "step": 24130
    },
    {
      "epoch": 4.692846034214619,
      "grad_norm": 0.0024849397595971823,
      "learning_rate": 2.2905218593399e-05,
      "loss": 0.0002,
      "step": 24140
    },
    {
      "epoch": 4.694790046656299,
      "grad_norm": 0.0022606702987104654,
      "learning_rate": 2.2900898565750823e-05,
      "loss": 0.0001,
      "step": 24150
    },
    {
      "epoch": 4.696734059097978,
      "grad_norm": 0.0030464178416877985,
      "learning_rate": 2.2896578538102644e-05,
      "loss": 0.0002,
      "step": 24160
    },
    {
      "epoch": 4.698678071539658,
      "grad_norm": 0.0012160531478002667,
      "learning_rate": 2.2892258510454468e-05,
      "loss": 0.0003,
      "step": 24170
    },
    {
      "epoch": 4.7006220839813375,
      "grad_norm": 0.00038209333433769643,
      "learning_rate": 2.2887938482806292e-05,
      "loss": 0.0001,
      "step": 24180
    },
    {
      "epoch": 4.702566096423017,
      "grad_norm": 30.21173667907715,
      "learning_rate": 2.2883618455158113e-05,
      "loss": 0.0245,
      "step": 24190
    },
    {
      "epoch": 4.704510108864697,
      "grad_norm": 0.00935578253120184,
      "learning_rate": 2.2879298427509937e-05,
      "loss": 0.0004,
      "step": 24200
    },
    {
      "epoch": 4.706454121306376,
      "grad_norm": 0.14774157106876373,
      "learning_rate": 2.287497839986176e-05,
      "loss": 0.0003,
      "step": 24210
    },
    {
      "epoch": 4.708398133748056,
      "grad_norm": 0.012200099416077137,
      "learning_rate": 2.287065837221358e-05,
      "loss": 0.0001,
      "step": 24220
    },
    {
      "epoch": 4.710342146189736,
      "grad_norm": 0.002010467229411006,
      "learning_rate": 2.2866338344565406e-05,
      "loss": 0.0001,
      "step": 24230
    },
    {
      "epoch": 4.712286158631415,
      "grad_norm": 0.01377774216234684,
      "learning_rate": 2.286201831691723e-05,
      "loss": 0.0292,
      "step": 24240
    },
    {
      "epoch": 4.714230171073095,
      "grad_norm": 0.002240557922050357,
      "learning_rate": 2.2857698289269054e-05,
      "loss": 0.0001,
      "step": 24250
    },
    {
      "epoch": 4.716174183514775,
      "grad_norm": 0.0004148047883063555,
      "learning_rate": 2.2853378261620875e-05,
      "loss": 0.0057,
      "step": 24260
    },
    {
      "epoch": 4.718118195956454,
      "grad_norm": 0.0014690750977024436,
      "learning_rate": 2.28490582339727e-05,
      "loss": 0.0001,
      "step": 24270
    },
    {
      "epoch": 4.720062208398134,
      "grad_norm": 0.0030115824192762375,
      "learning_rate": 2.2844738206324523e-05,
      "loss": 0.002,
      "step": 24280
    },
    {
      "epoch": 4.7220062208398135,
      "grad_norm": 0.0007979876245371997,
      "learning_rate": 2.2840418178676343e-05,
      "loss": 0.0001,
      "step": 24290
    },
    {
      "epoch": 4.723950233281493,
      "grad_norm": 0.0011721998453140259,
      "learning_rate": 2.2836098151028168e-05,
      "loss": 0.0001,
      "step": 24300
    },
    {
      "epoch": 4.725894245723173,
      "grad_norm": 0.0011696596629917622,
      "learning_rate": 2.2831778123379992e-05,
      "loss": 0.0001,
      "step": 24310
    },
    {
      "epoch": 4.727838258164852,
      "grad_norm": 0.0009923598263412714,
      "learning_rate": 2.2827458095731812e-05,
      "loss": 0.0001,
      "step": 24320
    },
    {
      "epoch": 4.729782270606532,
      "grad_norm": 0.0018299276707693934,
      "learning_rate": 2.2823138068083637e-05,
      "loss": 0.0001,
      "step": 24330
    },
    {
      "epoch": 4.731726283048212,
      "grad_norm": 0.000990855391137302,
      "learning_rate": 2.281881804043546e-05,
      "loss": 0.0001,
      "step": 24340
    },
    {
      "epoch": 4.733670295489891,
      "grad_norm": 8.270574569702148,
      "learning_rate": 2.281449801278728e-05,
      "loss": 0.0025,
      "step": 24350
    },
    {
      "epoch": 4.735614307931571,
      "grad_norm": 0.0010437846649438143,
      "learning_rate": 2.2810177985139105e-05,
      "loss": 0.0002,
      "step": 24360
    },
    {
      "epoch": 4.7375583203732505,
      "grad_norm": 0.10795687884092331,
      "learning_rate": 2.280585795749093e-05,
      "loss": 0.0001,
      "step": 24370
    },
    {
      "epoch": 4.73950233281493,
      "grad_norm": 0.00108661490958184,
      "learning_rate": 2.280153792984275e-05,
      "loss": 0.0001,
      "step": 24380
    },
    {
      "epoch": 4.74144634525661,
      "grad_norm": 0.0005169564974494278,
      "learning_rate": 2.2797217902194574e-05,
      "loss": 0.0001,
      "step": 24390
    },
    {
      "epoch": 4.743390357698289,
      "grad_norm": 0.00031080952612683177,
      "learning_rate": 2.27928978745464e-05,
      "loss": 0.0,
      "step": 24400
    },
    {
      "epoch": 4.745334370139969,
      "grad_norm": 0.0006801371928304434,
      "learning_rate": 2.278857784689822e-05,
      "loss": 0.0,
      "step": 24410
    },
    {
      "epoch": 4.747278382581649,
      "grad_norm": 0.000923022860661149,
      "learning_rate": 2.2784257819250043e-05,
      "loss": 0.0,
      "step": 24420
    },
    {
      "epoch": 4.749222395023328,
      "grad_norm": 0.00048494720249436796,
      "learning_rate": 2.2779937791601867e-05,
      "loss": 0.0,
      "step": 24430
    },
    {
      "epoch": 4.751166407465008,
      "grad_norm": 0.002480123657733202,
      "learning_rate": 2.2775617763953688e-05,
      "loss": 0.0,
      "step": 24440
    },
    {
      "epoch": 4.753110419906688,
      "grad_norm": 0.0005611455417238176,
      "learning_rate": 2.2771297736305516e-05,
      "loss": 0.0001,
      "step": 24450
    },
    {
      "epoch": 4.755054432348367,
      "grad_norm": 0.0004353882104624063,
      "learning_rate": 2.2766977708657336e-05,
      "loss": 0.0001,
      "step": 24460
    },
    {
      "epoch": 4.756998444790047,
      "grad_norm": 0.00029942102264612913,
      "learning_rate": 2.2762657681009157e-05,
      "loss": 0.0,
      "step": 24470
    },
    {
      "epoch": 4.7589424572317265,
      "grad_norm": 0.0007916534668765962,
      "learning_rate": 2.2758337653360985e-05,
      "loss": 0.0,
      "step": 24480
    },
    {
      "epoch": 4.760886469673406,
      "grad_norm": 0.0009401235729455948,
      "learning_rate": 2.2754017625712805e-05,
      "loss": 0.0104,
      "step": 24490
    },
    {
      "epoch": 4.762830482115086,
      "grad_norm": 0.00042147297062911093,
      "learning_rate": 2.2749697598064626e-05,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 4.764774494556765,
      "grad_norm": 0.0011522938730195165,
      "learning_rate": 2.2745377570416454e-05,
      "loss": 0.0,
      "step": 24510
    },
    {
      "epoch": 4.766718506998445,
      "grad_norm": 0.01758081652224064,
      "learning_rate": 2.2741057542768274e-05,
      "loss": 0.0001,
      "step": 24520
    },
    {
      "epoch": 4.768662519440125,
      "grad_norm": 0.0008444053819403052,
      "learning_rate": 2.2736737515120095e-05,
      "loss": 0.0,
      "step": 24530
    },
    {
      "epoch": 4.770606531881804,
      "grad_norm": 0.0006490798550657928,
      "learning_rate": 2.2732417487471923e-05,
      "loss": 0.0,
      "step": 24540
    },
    {
      "epoch": 4.772550544323484,
      "grad_norm": 0.013287489302456379,
      "learning_rate": 2.2728097459823743e-05,
      "loss": 0.0001,
      "step": 24550
    },
    {
      "epoch": 4.7744945567651635,
      "grad_norm": 0.0006773585337214172,
      "learning_rate": 2.2723777432175564e-05,
      "loss": 0.0,
      "step": 24560
    },
    {
      "epoch": 4.776438569206843,
      "grad_norm": 0.01132969930768013,
      "learning_rate": 2.271945740452739e-05,
      "loss": 0.0001,
      "step": 24570
    },
    {
      "epoch": 4.778382581648523,
      "grad_norm": 0.00068572600139305,
      "learning_rate": 2.2715137376879212e-05,
      "loss": 0.0,
      "step": 24580
    },
    {
      "epoch": 4.780326594090202,
      "grad_norm": 0.0006647208356298506,
      "learning_rate": 2.2710817349231033e-05,
      "loss": 0.0001,
      "step": 24590
    },
    {
      "epoch": 4.782270606531882,
      "grad_norm": 0.0009090893436223269,
      "learning_rate": 2.270649732158286e-05,
      "loss": 0.0001,
      "step": 24600
    },
    {
      "epoch": 4.784214618973562,
      "grad_norm": 0.0010584845440462232,
      "learning_rate": 2.270217729393468e-05,
      "loss": 0.0002,
      "step": 24610
    },
    {
      "epoch": 4.786158631415241,
      "grad_norm": 0.00047208910109475255,
      "learning_rate": 2.2697857266286505e-05,
      "loss": 0.0,
      "step": 24620
    },
    {
      "epoch": 4.788102643856921,
      "grad_norm": 0.0005159989232197404,
      "learning_rate": 2.269353723863833e-05,
      "loss": 0.0,
      "step": 24630
    },
    {
      "epoch": 4.790046656298601,
      "grad_norm": 0.0006397382239811122,
      "learning_rate": 2.268921721099015e-05,
      "loss": 0.0,
      "step": 24640
    },
    {
      "epoch": 4.79199066874028,
      "grad_norm": 0.0002938421384897083,
      "learning_rate": 2.2684897183341974e-05,
      "loss": 0.0,
      "step": 24650
    },
    {
      "epoch": 4.79393468118196,
      "grad_norm": 0.0006434849346987903,
      "learning_rate": 2.26805771556938e-05,
      "loss": 0.0,
      "step": 24660
    },
    {
      "epoch": 4.7958786936236395,
      "grad_norm": 0.0006178343901410699,
      "learning_rate": 2.267625712804562e-05,
      "loss": 0.0001,
      "step": 24670
    },
    {
      "epoch": 4.797822706065319,
      "grad_norm": 0.0005561243160627782,
      "learning_rate": 2.2671937100397443e-05,
      "loss": 0.0,
      "step": 24680
    },
    {
      "epoch": 4.799766718506999,
      "grad_norm": 0.00038095953641459346,
      "learning_rate": 2.2667617072749267e-05,
      "loss": 0.0,
      "step": 24690
    },
    {
      "epoch": 4.801710730948678,
      "grad_norm": 0.0003411306533962488,
      "learning_rate": 2.2663297045101088e-05,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 4.803654743390358,
      "grad_norm": 0.00064310641027987,
      "learning_rate": 2.2658977017452912e-05,
      "loss": 0.0001,
      "step": 24710
    },
    {
      "epoch": 4.805598755832038,
      "grad_norm": 0.0006107513327151537,
      "learning_rate": 2.2654656989804736e-05,
      "loss": 0.0,
      "step": 24720
    },
    {
      "epoch": 4.807542768273717,
      "grad_norm": 0.0005198079161345959,
      "learning_rate": 2.2650336962156557e-05,
      "loss": 0.0,
      "step": 24730
    },
    {
      "epoch": 4.809486780715397,
      "grad_norm": 0.000459046452306211,
      "learning_rate": 2.264601693450838e-05,
      "loss": 0.0,
      "step": 24740
    },
    {
      "epoch": 4.811430793157077,
      "grad_norm": 0.00030553012038581073,
      "learning_rate": 2.2641696906860205e-05,
      "loss": 0.0,
      "step": 24750
    },
    {
      "epoch": 4.813374805598756,
      "grad_norm": 0.00041999775567092,
      "learning_rate": 2.2637376879212026e-05,
      "loss": 0.0021,
      "step": 24760
    },
    {
      "epoch": 4.815318818040436,
      "grad_norm": 0.000482595874927938,
      "learning_rate": 2.263305685156385e-05,
      "loss": 0.0402,
      "step": 24770
    },
    {
      "epoch": 4.8172628304821155,
      "grad_norm": 0.00048240050091408193,
      "learning_rate": 2.2628736823915674e-05,
      "loss": 0.0007,
      "step": 24780
    },
    {
      "epoch": 4.819206842923795,
      "grad_norm": 0.0002837105712387711,
      "learning_rate": 2.2624416796267495e-05,
      "loss": 0.0001,
      "step": 24790
    },
    {
      "epoch": 4.821150855365475,
      "grad_norm": 0.0005708871176466346,
      "learning_rate": 2.262009676861932e-05,
      "loss": 0.0,
      "step": 24800
    },
    {
      "epoch": 4.823094867807154,
      "grad_norm": 0.000600686704274267,
      "learning_rate": 2.2615776740971143e-05,
      "loss": 0.0001,
      "step": 24810
    },
    {
      "epoch": 4.825038880248833,
      "grad_norm": 0.0006222163792699575,
      "learning_rate": 2.2611456713322967e-05,
      "loss": 0.0,
      "step": 24820
    },
    {
      "epoch": 4.826982892690513,
      "grad_norm": 0.00046891183592379093,
      "learning_rate": 2.2607136685674788e-05,
      "loss": 0.0,
      "step": 24830
    },
    {
      "epoch": 4.828926905132192,
      "grad_norm": 0.0005624240729957819,
      "learning_rate": 2.2602816658026612e-05,
      "loss": 0.0,
      "step": 24840
    },
    {
      "epoch": 4.830870917573872,
      "grad_norm": 0.0005258016171865165,
      "learning_rate": 2.2598496630378436e-05,
      "loss": 0.0001,
      "step": 24850
    },
    {
      "epoch": 4.832814930015552,
      "grad_norm": 0.000445405428763479,
      "learning_rate": 2.2594176602730257e-05,
      "loss": 0.0002,
      "step": 24860
    },
    {
      "epoch": 4.834758942457231,
      "grad_norm": 0.00036454215296544135,
      "learning_rate": 2.258985657508208e-05,
      "loss": 0.0,
      "step": 24870
    },
    {
      "epoch": 4.836702954898911,
      "grad_norm": 0.0007012791465967894,
      "learning_rate": 2.2585536547433905e-05,
      "loss": 0.0,
      "step": 24880
    },
    {
      "epoch": 4.8386469673405905,
      "grad_norm": 0.0005523716099560261,
      "learning_rate": 2.2581216519785726e-05,
      "loss": 0.0,
      "step": 24890
    },
    {
      "epoch": 4.84059097978227,
      "grad_norm": 0.001423095352947712,
      "learning_rate": 2.257689649213755e-05,
      "loss": 0.0,
      "step": 24900
    },
    {
      "epoch": 4.84253499222395,
      "grad_norm": 0.0003350512415636331,
      "learning_rate": 2.2572576464489374e-05,
      "loss": 0.015,
      "step": 24910
    },
    {
      "epoch": 4.844479004665629,
      "grad_norm": 0.00047589087625965476,
      "learning_rate": 2.2568256436841195e-05,
      "loss": 0.0,
      "step": 24920
    },
    {
      "epoch": 4.846423017107309,
      "grad_norm": 0.00039096787804737687,
      "learning_rate": 2.256393640919302e-05,
      "loss": 0.0,
      "step": 24930
    },
    {
      "epoch": 4.848367029548989,
      "grad_norm": 0.00025504076620563865,
      "learning_rate": 2.2559616381544843e-05,
      "loss": 0.0,
      "step": 24940
    },
    {
      "epoch": 4.850311041990668,
      "grad_norm": 0.00041290820809081197,
      "learning_rate": 2.2555296353896664e-05,
      "loss": 0.0,
      "step": 24950
    },
    {
      "epoch": 4.852255054432348,
      "grad_norm": 0.0005737537867389619,
      "learning_rate": 2.2550976326248488e-05,
      "loss": 0.0,
      "step": 24960
    },
    {
      "epoch": 4.854199066874028,
      "grad_norm": 0.0014455568743869662,
      "learning_rate": 2.2546656298600312e-05,
      "loss": 0.0,
      "step": 24970
    },
    {
      "epoch": 4.856143079315707,
      "grad_norm": 0.0004336211131885648,
      "learning_rate": 2.2542336270952133e-05,
      "loss": 0.019,
      "step": 24980
    },
    {
      "epoch": 4.858087091757387,
      "grad_norm": 0.001076311687938869,
      "learning_rate": 2.2538016243303957e-05,
      "loss": 0.0086,
      "step": 24990
    },
    {
      "epoch": 4.8600311041990665,
      "grad_norm": 0.0002963159931823611,
      "learning_rate": 2.253369621565578e-05,
      "loss": 0.0012,
      "step": 25000
    },
    {
      "epoch": 4.861975116640746,
      "grad_norm": 0.0006541887414641678,
      "learning_rate": 2.2529376188007605e-05,
      "loss": 0.0,
      "step": 25010
    },
    {
      "epoch": 4.863919129082426,
      "grad_norm": 0.0004435133596416563,
      "learning_rate": 2.252505616035943e-05,
      "loss": 0.0,
      "step": 25020
    },
    {
      "epoch": 4.865863141524105,
      "grad_norm": 0.0006685418775305152,
      "learning_rate": 2.252073613271125e-05,
      "loss": 0.0,
      "step": 25030
    },
    {
      "epoch": 4.867807153965785,
      "grad_norm": 0.0005333608714863658,
      "learning_rate": 2.2516416105063074e-05,
      "loss": 0.013,
      "step": 25040
    },
    {
      "epoch": 4.869751166407465,
      "grad_norm": 0.0025277824606746435,
      "learning_rate": 2.2512096077414898e-05,
      "loss": 0.019,
      "step": 25050
    },
    {
      "epoch": 4.871695178849144,
      "grad_norm": 0.0013805747730657458,
      "learning_rate": 2.250777604976672e-05,
      "loss": 0.0001,
      "step": 25060
    },
    {
      "epoch": 4.873639191290824,
      "grad_norm": 0.0013232002966105938,
      "learning_rate": 2.2503456022118543e-05,
      "loss": 0.0001,
      "step": 25070
    },
    {
      "epoch": 4.8755832037325035,
      "grad_norm": 0.0008047823794186115,
      "learning_rate": 2.2499135994470367e-05,
      "loss": 0.0001,
      "step": 25080
    },
    {
      "epoch": 4.877527216174183,
      "grad_norm": 0.0014176308177411556,
      "learning_rate": 2.2494815966822188e-05,
      "loss": 0.0001,
      "step": 25090
    },
    {
      "epoch": 4.879471228615863,
      "grad_norm": 0.0027778062503784895,
      "learning_rate": 2.2490495939174012e-05,
      "loss": 0.0001,
      "step": 25100
    },
    {
      "epoch": 4.881415241057542,
      "grad_norm": 0.0024760733358561993,
      "learning_rate": 2.2486175911525836e-05,
      "loss": 0.0002,
      "step": 25110
    },
    {
      "epoch": 4.883359253499222,
      "grad_norm": 0.0006062762695364654,
      "learning_rate": 2.2481855883877657e-05,
      "loss": 0.0,
      "step": 25120
    },
    {
      "epoch": 4.885303265940902,
      "grad_norm": 0.0003002758021466434,
      "learning_rate": 2.247753585622948e-05,
      "loss": 0.0001,
      "step": 25130
    },
    {
      "epoch": 4.887247278382581,
      "grad_norm": 0.001106844749301672,
      "learning_rate": 2.2473215828581305e-05,
      "loss": 0.0001,
      "step": 25140
    },
    {
      "epoch": 4.889191290824261,
      "grad_norm": 0.00027893565129488707,
      "learning_rate": 2.2468895800933126e-05,
      "loss": 0.001,
      "step": 25150
    },
    {
      "epoch": 4.891135303265941,
      "grad_norm": 0.0006241547525860369,
      "learning_rate": 2.246457577328495e-05,
      "loss": 0.0,
      "step": 25160
    },
    {
      "epoch": 4.89307931570762,
      "grad_norm": 0.0005180968437343836,
      "learning_rate": 2.2460255745636774e-05,
      "loss": 0.0001,
      "step": 25170
    },
    {
      "epoch": 4.8950233281493,
      "grad_norm": 0.00047906936379149556,
      "learning_rate": 2.2455935717988594e-05,
      "loss": 0.0001,
      "step": 25180
    },
    {
      "epoch": 4.8969673405909795,
      "grad_norm": 0.0005291568813845515,
      "learning_rate": 2.245161569034042e-05,
      "loss": 0.0,
      "step": 25190
    },
    {
      "epoch": 4.898911353032659,
      "grad_norm": 0.00031895158463157713,
      "learning_rate": 2.2447295662692243e-05,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 4.900855365474339,
      "grad_norm": 0.0003968708624597639,
      "learning_rate": 2.2442975635044063e-05,
      "loss": 0.0,
      "step": 25210
    },
    {
      "epoch": 4.902799377916018,
      "grad_norm": 0.00047097355127334595,
      "learning_rate": 2.243865560739589e-05,
      "loss": 0.0007,
      "step": 25220
    },
    {
      "epoch": 4.904743390357698,
      "grad_norm": 0.000492115446832031,
      "learning_rate": 2.243433557974771e-05,
      "loss": 0.0,
      "step": 25230
    },
    {
      "epoch": 4.906687402799378,
      "grad_norm": 0.0004305398615542799,
      "learning_rate": 2.2430015552099532e-05,
      "loss": 0.0,
      "step": 25240
    },
    {
      "epoch": 4.908631415241057,
      "grad_norm": 0.0005686880904249847,
      "learning_rate": 2.242569552445136e-05,
      "loss": 0.0,
      "step": 25250
    },
    {
      "epoch": 4.910575427682737,
      "grad_norm": 0.0005324991070665419,
      "learning_rate": 2.242137549680318e-05,
      "loss": 0.0,
      "step": 25260
    },
    {
      "epoch": 4.9125194401244165,
      "grad_norm": 0.0009538854355923831,
      "learning_rate": 2.2417055469155e-05,
      "loss": 0.0,
      "step": 25270
    },
    {
      "epoch": 4.914463452566096,
      "grad_norm": 0.000287603703327477,
      "learning_rate": 2.241273544150683e-05,
      "loss": 0.0002,
      "step": 25280
    },
    {
      "epoch": 4.916407465007776,
      "grad_norm": 0.0003931982209905982,
      "learning_rate": 2.240841541385865e-05,
      "loss": 0.0001,
      "step": 25290
    },
    {
      "epoch": 4.9183514774494554,
      "grad_norm": 0.001340188435278833,
      "learning_rate": 2.240409538621047e-05,
      "loss": 0.0,
      "step": 25300
    },
    {
      "epoch": 4.920295489891135,
      "grad_norm": 0.0004584326525218785,
      "learning_rate": 2.2399775358562298e-05,
      "loss": 0.0,
      "step": 25310
    },
    {
      "epoch": 4.922239502332815,
      "grad_norm": 0.0004338599683251232,
      "learning_rate": 2.239545533091412e-05,
      "loss": 0.0,
      "step": 25320
    },
    {
      "epoch": 4.924183514774494,
      "grad_norm": 0.00035027478588745,
      "learning_rate": 2.239113530326594e-05,
      "loss": 0.0,
      "step": 25330
    },
    {
      "epoch": 4.926127527216174,
      "grad_norm": 0.0006040077423676848,
      "learning_rate": 2.2386815275617767e-05,
      "loss": 0.0,
      "step": 25340
    },
    {
      "epoch": 4.928071539657854,
      "grad_norm": 0.0003141649067401886,
      "learning_rate": 2.2382495247969587e-05,
      "loss": 0.0,
      "step": 25350
    },
    {
      "epoch": 4.930015552099533,
      "grad_norm": 0.00041140333632938564,
      "learning_rate": 2.2378175220321408e-05,
      "loss": 0.0,
      "step": 25360
    },
    {
      "epoch": 4.931959564541213,
      "grad_norm": 0.00027995530399493873,
      "learning_rate": 2.2373855192673236e-05,
      "loss": 0.0,
      "step": 25370
    },
    {
      "epoch": 4.9339035769828925,
      "grad_norm": 0.00023173655790742487,
      "learning_rate": 2.2369535165025056e-05,
      "loss": 0.0,
      "step": 25380
    },
    {
      "epoch": 4.935847589424572,
      "grad_norm": 0.0005049622268415987,
      "learning_rate": 2.2365215137376877e-05,
      "loss": 0.0,
      "step": 25390
    },
    {
      "epoch": 4.937791601866252,
      "grad_norm": 0.00030745757976546884,
      "learning_rate": 2.2360895109728705e-05,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 4.939735614307931,
      "grad_norm": 0.0002458214294165373,
      "learning_rate": 2.2356575082080525e-05,
      "loss": 0.0,
      "step": 25410
    },
    {
      "epoch": 4.941679626749611,
      "grad_norm": 0.0002245456271339208,
      "learning_rate": 2.235225505443235e-05,
      "loss": 0.0001,
      "step": 25420
    },
    {
      "epoch": 4.943623639191291,
      "grad_norm": 0.00037300976691767573,
      "learning_rate": 2.2347935026784174e-05,
      "loss": 0.0,
      "step": 25430
    },
    {
      "epoch": 4.94556765163297,
      "grad_norm": 0.00023323512868955731,
      "learning_rate": 2.2343614999135994e-05,
      "loss": 0.0,
      "step": 25440
    },
    {
      "epoch": 4.94751166407465,
      "grad_norm": 0.0005104751326143742,
      "learning_rate": 2.233929497148782e-05,
      "loss": 0.0,
      "step": 25450
    },
    {
      "epoch": 4.94945567651633,
      "grad_norm": 55.30643081665039,
      "learning_rate": 2.2334974943839642e-05,
      "loss": 0.0072,
      "step": 25460
    },
    {
      "epoch": 4.951399688958009,
      "grad_norm": 0.00022364873439073563,
      "learning_rate": 2.2330654916191463e-05,
      "loss": 0.0,
      "step": 25470
    },
    {
      "epoch": 4.953343701399689,
      "grad_norm": 0.0002437862567603588,
      "learning_rate": 2.2326334888543287e-05,
      "loss": 0.0,
      "step": 25480
    },
    {
      "epoch": 4.9552877138413685,
      "grad_norm": 0.00022357482521329075,
      "learning_rate": 2.232201486089511e-05,
      "loss": 0.0,
      "step": 25490
    },
    {
      "epoch": 4.957231726283048,
      "grad_norm": 0.00023987190797924995,
      "learning_rate": 2.2317694833246932e-05,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 4.959175738724728,
      "grad_norm": 0.0002739353512879461,
      "learning_rate": 2.2313374805598756e-05,
      "loss": 0.0,
      "step": 25510
    },
    {
      "epoch": 4.961119751166407,
      "grad_norm": 0.00035090078017674387,
      "learning_rate": 2.230905477795058e-05,
      "loss": 0.0,
      "step": 25520
    },
    {
      "epoch": 4.963063763608087,
      "grad_norm": 0.0002754357410594821,
      "learning_rate": 2.23047347503024e-05,
      "loss": 0.0,
      "step": 25530
    },
    {
      "epoch": 4.965007776049767,
      "grad_norm": 0.0002415762864984572,
      "learning_rate": 2.2300414722654225e-05,
      "loss": 0.0012,
      "step": 25540
    },
    {
      "epoch": 4.966951788491446,
      "grad_norm": 0.00022677094966638833,
      "learning_rate": 2.229609469500605e-05,
      "loss": 0.0271,
      "step": 25550
    },
    {
      "epoch": 4.968895800933126,
      "grad_norm": 0.0005067060701549053,
      "learning_rate": 2.229177466735787e-05,
      "loss": 0.0002,
      "step": 25560
    },
    {
      "epoch": 4.9708398133748055,
      "grad_norm": 0.0003282122779637575,
      "learning_rate": 2.2287454639709694e-05,
      "loss": 0.0004,
      "step": 25570
    },
    {
      "epoch": 4.972783825816485,
      "grad_norm": 0.0003296505892649293,
      "learning_rate": 2.2283134612061518e-05,
      "loss": 0.0,
      "step": 25580
    },
    {
      "epoch": 4.974727838258165,
      "grad_norm": 0.00027775330818258226,
      "learning_rate": 2.227881458441334e-05,
      "loss": 0.0,
      "step": 25590
    },
    {
      "epoch": 4.976671850699844,
      "grad_norm": 0.00021836446831002831,
      "learning_rate": 2.2274494556765163e-05,
      "loss": 0.0,
      "step": 25600
    },
    {
      "epoch": 4.978615863141524,
      "grad_norm": 0.00028559728525578976,
      "learning_rate": 2.2270174529116987e-05,
      "loss": 0.0028,
      "step": 25610
    },
    {
      "epoch": 4.980559875583204,
      "grad_norm": 0.0004088490968570113,
      "learning_rate": 2.226585450146881e-05,
      "loss": 0.0001,
      "step": 25620
    },
    {
      "epoch": 4.982503888024883,
      "grad_norm": 0.0007566962158307433,
      "learning_rate": 2.2261534473820632e-05,
      "loss": 0.0,
      "step": 25630
    },
    {
      "epoch": 4.984447900466563,
      "grad_norm": 0.000322014675475657,
      "learning_rate": 2.2257214446172456e-05,
      "loss": 0.0,
      "step": 25640
    },
    {
      "epoch": 4.986391912908243,
      "grad_norm": 0.012056772597134113,
      "learning_rate": 2.225289441852428e-05,
      "loss": 0.0,
      "step": 25650
    },
    {
      "epoch": 4.988335925349922,
      "grad_norm": 0.0002205879718530923,
      "learning_rate": 2.22485743908761e-05,
      "loss": 0.0,
      "step": 25660
    },
    {
      "epoch": 4.990279937791602,
      "grad_norm": 0.000231439815252088,
      "learning_rate": 2.2244254363227925e-05,
      "loss": 0.0,
      "step": 25670
    },
    {
      "epoch": 4.9922239502332815,
      "grad_norm": 0.0004640412807930261,
      "learning_rate": 2.223993433557975e-05,
      "loss": 0.0,
      "step": 25680
    },
    {
      "epoch": 4.994167962674961,
      "grad_norm": 0.0002880498068407178,
      "learning_rate": 2.223561430793157e-05,
      "loss": 0.0433,
      "step": 25690
    },
    {
      "epoch": 4.996111975116641,
      "grad_norm": 0.0626855418086052,
      "learning_rate": 2.2231294280283394e-05,
      "loss": 0.0001,
      "step": 25700
    },
    {
      "epoch": 4.99805598755832,
      "grad_norm": 0.0004489046987146139,
      "learning_rate": 2.2226974252635218e-05,
      "loss": 0.0006,
      "step": 25710
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.00027914252132177353,
      "learning_rate": 2.222265422498704e-05,
      "loss": 0.0,
      "step": 25720
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.9964311955494909,
      "eval_loss": 0.011151009239256382,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.9964311955494909,
          "precision": 0.9969544213400546,
          "recall": 0.9959085186739404,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.9964311955494909,
          "precision": 0.9969544213400546,
          "recall": 0.9959085186739404,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.9964311955494909,
          "precision": 0.9969544213400546,
          "recall": 0.9959085186739404,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9964311955494908,
          "precision": 0.9969544213400547,
          "recall": 0.9959085186739404,
          "support": 9532
        }
      },
      "eval_runtime": 71.7394,
      "eval_samples_per_second": 106.873,
      "eval_steps_per_second": 13.368,
      "step": 25720
    },
    {
      "epoch": 5.00194401244168,
      "grad_norm": 0.00022084727243054658,
      "learning_rate": 2.2218334197338863e-05,
      "loss": 0.0061,
      "step": 25730
    },
    {
      "epoch": 5.003888024883359,
      "grad_norm": 0.00025790295330807567,
      "learning_rate": 2.2214014169690687e-05,
      "loss": 0.0,
      "step": 25740
    },
    {
      "epoch": 5.005832037325039,
      "grad_norm": 0.00029275199631229043,
      "learning_rate": 2.2209694142042508e-05,
      "loss": 0.0006,
      "step": 25750
    },
    {
      "epoch": 5.0077760497667185,
      "grad_norm": 0.0005334619781933725,
      "learning_rate": 2.2205374114394332e-05,
      "loss": 0.0,
      "step": 25760
    },
    {
      "epoch": 5.009720062208398,
      "grad_norm": 0.0003337386006023735,
      "learning_rate": 2.2201054086746156e-05,
      "loss": 0.0,
      "step": 25770
    },
    {
      "epoch": 5.011664074650078,
      "grad_norm": 0.00023579098342452198,
      "learning_rate": 2.2196734059097977e-05,
      "loss": 0.0,
      "step": 25780
    },
    {
      "epoch": 5.013608087091757,
      "grad_norm": 0.00033469239133410156,
      "learning_rate": 2.21924140314498e-05,
      "loss": 0.0,
      "step": 25790
    },
    {
      "epoch": 5.015552099533437,
      "grad_norm": 0.00046158881741575897,
      "learning_rate": 2.2188094003801625e-05,
      "loss": 0.0,
      "step": 25800
    },
    {
      "epoch": 5.017496111975117,
      "grad_norm": 0.00023509823950007558,
      "learning_rate": 2.2183773976153446e-05,
      "loss": 0.0,
      "step": 25810
    },
    {
      "epoch": 5.019440124416796,
      "grad_norm": 0.00020301542826928198,
      "learning_rate": 2.2179453948505273e-05,
      "loss": 0.0,
      "step": 25820
    },
    {
      "epoch": 5.021384136858476,
      "grad_norm": 0.0002589646610431373,
      "learning_rate": 2.2175133920857094e-05,
      "loss": 0.0,
      "step": 25830
    },
    {
      "epoch": 5.023328149300156,
      "grad_norm": 0.07207004725933075,
      "learning_rate": 2.2170813893208915e-05,
      "loss": 0.0,
      "step": 25840
    },
    {
      "epoch": 5.025272161741835,
      "grad_norm": 0.00023202368174679577,
      "learning_rate": 2.2166493865560742e-05,
      "loss": 0.0,
      "step": 25850
    },
    {
      "epoch": 5.027216174183515,
      "grad_norm": 0.00021305048721842468,
      "learning_rate": 2.2162173837912563e-05,
      "loss": 0.0,
      "step": 25860
    },
    {
      "epoch": 5.0291601866251945,
      "grad_norm": 0.00019213644554838538,
      "learning_rate": 2.2157853810264384e-05,
      "loss": 0.0,
      "step": 25870
    },
    {
      "epoch": 5.031104199066874,
      "grad_norm": 0.0002637760480865836,
      "learning_rate": 2.215353378261621e-05,
      "loss": 0.0,
      "step": 25880
    },
    {
      "epoch": 5.033048211508554,
      "grad_norm": 1.4381271600723267,
      "learning_rate": 2.2149213754968032e-05,
      "loss": 0.0221,
      "step": 25890
    },
    {
      "epoch": 5.034992223950233,
      "grad_norm": 0.002180325798690319,
      "learning_rate": 2.2144893727319856e-05,
      "loss": 0.0,
      "step": 25900
    },
    {
      "epoch": 5.036936236391913,
      "grad_norm": 0.00026628622435964644,
      "learning_rate": 2.214057369967168e-05,
      "loss": 0.0195,
      "step": 25910
    },
    {
      "epoch": 5.038880248833593,
      "grad_norm": 0.0003747892624232918,
      "learning_rate": 2.21362536720235e-05,
      "loss": 0.0164,
      "step": 25920
    },
    {
      "epoch": 5.040824261275272,
      "grad_norm": 0.0035079980734735727,
      "learning_rate": 2.2131933644375325e-05,
      "loss": 0.0001,
      "step": 25930
    },
    {
      "epoch": 5.042768273716952,
      "grad_norm": 0.003795136231929064,
      "learning_rate": 2.212761361672715e-05,
      "loss": 0.0001,
      "step": 25940
    },
    {
      "epoch": 5.0447122861586315,
      "grad_norm": 0.0036119127180427313,
      "learning_rate": 2.212329358907897e-05,
      "loss": 0.0001,
      "step": 25950
    },
    {
      "epoch": 5.046656298600311,
      "grad_norm": 0.001989813055843115,
      "learning_rate": 2.2118973561430794e-05,
      "loss": 0.0209,
      "step": 25960
    },
    {
      "epoch": 5.048600311041991,
      "grad_norm": 0.006375277414917946,
      "learning_rate": 2.2114653533782618e-05,
      "loss": 0.0007,
      "step": 25970
    },
    {
      "epoch": 5.05054432348367,
      "grad_norm": 0.0002665629726834595,
      "learning_rate": 2.211033350613444e-05,
      "loss": 0.0002,
      "step": 25980
    },
    {
      "epoch": 5.05248833592535,
      "grad_norm": 0.0014969161711633205,
      "learning_rate": 2.2106013478486263e-05,
      "loss": 0.0284,
      "step": 25990
    },
    {
      "epoch": 5.05443234836703,
      "grad_norm": 0.004938371945172548,
      "learning_rate": 2.2101693450838087e-05,
      "loss": 0.0021,
      "step": 26000
    },
    {
      "epoch": 5.056376360808709,
      "grad_norm": 0.002986270235851407,
      "learning_rate": 2.2097373423189908e-05,
      "loss": 0.0001,
      "step": 26010
    },
    {
      "epoch": 5.058320373250389,
      "grad_norm": 0.0006741181132383645,
      "learning_rate": 2.2093053395541735e-05,
      "loss": 0.0099,
      "step": 26020
    },
    {
      "epoch": 5.060264385692069,
      "grad_norm": 0.0004050784045830369,
      "learning_rate": 2.2088733367893556e-05,
      "loss": 0.0343,
      "step": 26030
    },
    {
      "epoch": 5.062208398133748,
      "grad_norm": 0.0018011837964877486,
      "learning_rate": 2.2084413340245377e-05,
      "loss": 0.0004,
      "step": 26040
    },
    {
      "epoch": 5.064152410575428,
      "grad_norm": 0.0018117742147296667,
      "learning_rate": 2.2080093312597204e-05,
      "loss": 0.0001,
      "step": 26050
    },
    {
      "epoch": 5.0660964230171075,
      "grad_norm": 0.0005886631552129984,
      "learning_rate": 2.2075773284949025e-05,
      "loss": 0.0002,
      "step": 26060
    },
    {
      "epoch": 5.068040435458787,
      "grad_norm": 0.09975122660398483,
      "learning_rate": 2.2071453257300845e-05,
      "loss": 0.0002,
      "step": 26070
    },
    {
      "epoch": 5.069984447900467,
      "grad_norm": 0.0004165896389167756,
      "learning_rate": 2.2067133229652673e-05,
      "loss": 0.0,
      "step": 26080
    },
    {
      "epoch": 5.071928460342146,
      "grad_norm": 0.0012195099843665957,
      "learning_rate": 2.2062813202004494e-05,
      "loss": 0.0,
      "step": 26090
    },
    {
      "epoch": 5.073872472783826,
      "grad_norm": 0.0013920830097049475,
      "learning_rate": 2.2058493174356314e-05,
      "loss": 0.0,
      "step": 26100
    },
    {
      "epoch": 5.075816485225506,
      "grad_norm": 0.0002549091586843133,
      "learning_rate": 2.2054173146708142e-05,
      "loss": 0.0191,
      "step": 26110
    },
    {
      "epoch": 5.077760497667185,
      "grad_norm": 0.04940534383058548,
      "learning_rate": 2.2049853119059963e-05,
      "loss": 0.0043,
      "step": 26120
    },
    {
      "epoch": 5.079704510108865,
      "grad_norm": 0.006715239956974983,
      "learning_rate": 2.2045533091411783e-05,
      "loss": 0.0001,
      "step": 26130
    },
    {
      "epoch": 5.0816485225505446,
      "grad_norm": 0.003225760068744421,
      "learning_rate": 2.204121306376361e-05,
      "loss": 0.028,
      "step": 26140
    },
    {
      "epoch": 5.083592534992224,
      "grad_norm": 0.003888543928042054,
      "learning_rate": 2.203689303611543e-05,
      "loss": 0.0001,
      "step": 26150
    },
    {
      "epoch": 5.085536547433904,
      "grad_norm": 0.0009358201641589403,
      "learning_rate": 2.2032573008467252e-05,
      "loss": 0.0079,
      "step": 26160
    },
    {
      "epoch": 5.0874805598755835,
      "grad_norm": 0.04740564525127411,
      "learning_rate": 2.202825298081908e-05,
      "loss": 0.0001,
      "step": 26170
    },
    {
      "epoch": 5.089424572317263,
      "grad_norm": 0.0002571327204350382,
      "learning_rate": 2.20239329531709e-05,
      "loss": 0.001,
      "step": 26180
    },
    {
      "epoch": 5.091368584758943,
      "grad_norm": 0.0008430726593360305,
      "learning_rate": 2.2019612925522725e-05,
      "loss": 0.0001,
      "step": 26190
    },
    {
      "epoch": 5.093312597200622,
      "grad_norm": 0.019557466730475426,
      "learning_rate": 2.201529289787455e-05,
      "loss": 0.0001,
      "step": 26200
    },
    {
      "epoch": 5.095256609642302,
      "grad_norm": 0.0012334119528532028,
      "learning_rate": 2.201097287022637e-05,
      "loss": 0.0096,
      "step": 26210
    },
    {
      "epoch": 5.097200622083982,
      "grad_norm": 0.002298186533153057,
      "learning_rate": 2.2006652842578194e-05,
      "loss": 0.0001,
      "step": 26220
    },
    {
      "epoch": 5.099144634525661,
      "grad_norm": 0.0004786471836268902,
      "learning_rate": 2.2002332814930018e-05,
      "loss": 0.0001,
      "step": 26230
    },
    {
      "epoch": 5.101088646967341,
      "grad_norm": 0.0015518312575295568,
      "learning_rate": 2.199801278728184e-05,
      "loss": 0.0001,
      "step": 26240
    },
    {
      "epoch": 5.1030326594090205,
      "grad_norm": 0.00033192019327543676,
      "learning_rate": 2.1993692759633662e-05,
      "loss": 0.0,
      "step": 26250
    },
    {
      "epoch": 5.1049766718507,
      "grad_norm": 0.0013597059296444058,
      "learning_rate": 2.1989372731985487e-05,
      "loss": 0.0,
      "step": 26260
    },
    {
      "epoch": 5.10692068429238,
      "grad_norm": 0.00035578591632656753,
      "learning_rate": 2.1985052704337307e-05,
      "loss": 0.0001,
      "step": 26270
    },
    {
      "epoch": 5.108864696734059,
      "grad_norm": 0.001137779327109456,
      "learning_rate": 2.198073267668913e-05,
      "loss": 0.0065,
      "step": 26280
    },
    {
      "epoch": 5.110808709175739,
      "grad_norm": 0.0028326299507170916,
      "learning_rate": 2.1976412649040956e-05,
      "loss": 0.0001,
      "step": 26290
    },
    {
      "epoch": 5.112752721617419,
      "grad_norm": 0.00022626839927397668,
      "learning_rate": 2.1972092621392776e-05,
      "loss": 0.0,
      "step": 26300
    },
    {
      "epoch": 5.114696734059098,
      "grad_norm": 0.00037159110070206225,
      "learning_rate": 2.19677725937446e-05,
      "loss": 0.0001,
      "step": 26310
    },
    {
      "epoch": 5.116640746500778,
      "grad_norm": 0.0011503174901008606,
      "learning_rate": 2.1963452566096424e-05,
      "loss": 0.0,
      "step": 26320
    },
    {
      "epoch": 5.118584758942458,
      "grad_norm": 0.00036909946356900036,
      "learning_rate": 2.1959132538448245e-05,
      "loss": 0.011,
      "step": 26330
    },
    {
      "epoch": 5.120528771384137,
      "grad_norm": 0.0003466241469141096,
      "learning_rate": 2.195481251080007e-05,
      "loss": 0.0001,
      "step": 26340
    },
    {
      "epoch": 5.122472783825817,
      "grad_norm": 0.00022448578965850174,
      "learning_rate": 2.1950492483151893e-05,
      "loss": 0.0,
      "step": 26350
    },
    {
      "epoch": 5.1244167962674965,
      "grad_norm": 0.009302623569965363,
      "learning_rate": 2.1946172455503714e-05,
      "loss": 0.0001,
      "step": 26360
    },
    {
      "epoch": 5.126360808709176,
      "grad_norm": 0.0004118482465855777,
      "learning_rate": 2.1941852427855538e-05,
      "loss": 0.0002,
      "step": 26370
    },
    {
      "epoch": 5.128304821150856,
      "grad_norm": 0.0014774054288864136,
      "learning_rate": 2.1937532400207362e-05,
      "loss": 0.0,
      "step": 26380
    },
    {
      "epoch": 5.130248833592535,
      "grad_norm": 0.0012523764744400978,
      "learning_rate": 2.1933212372559186e-05,
      "loss": 0.0,
      "step": 26390
    },
    {
      "epoch": 5.132192846034215,
      "grad_norm": 0.0002710947301238775,
      "learning_rate": 2.1928892344911007e-05,
      "loss": 0.0,
      "step": 26400
    },
    {
      "epoch": 5.134136858475895,
      "grad_norm": 0.0004218256217427552,
      "learning_rate": 2.192457231726283e-05,
      "loss": 0.0,
      "step": 26410
    },
    {
      "epoch": 5.136080870917574,
      "grad_norm": 0.0003020080621354282,
      "learning_rate": 2.1920252289614655e-05,
      "loss": 0.0484,
      "step": 26420
    },
    {
      "epoch": 5.138024883359254,
      "grad_norm": 0.00577014684677124,
      "learning_rate": 2.1915932261966476e-05,
      "loss": 0.0002,
      "step": 26430
    },
    {
      "epoch": 5.1399688958009335,
      "grad_norm": 0.0018432633951306343,
      "learning_rate": 2.19116122343183e-05,
      "loss": 0.0004,
      "step": 26440
    },
    {
      "epoch": 5.141912908242613,
      "grad_norm": 0.0018664509989321232,
      "learning_rate": 2.1907292206670124e-05,
      "loss": 0.0003,
      "step": 26450
    },
    {
      "epoch": 5.143856920684293,
      "grad_norm": 0.0011401149677112699,
      "learning_rate": 2.1902972179021945e-05,
      "loss": 0.0001,
      "step": 26460
    },
    {
      "epoch": 5.145800933125972,
      "grad_norm": 0.000943136285059154,
      "learning_rate": 2.189865215137377e-05,
      "loss": 0.0,
      "step": 26470
    },
    {
      "epoch": 5.147744945567652,
      "grad_norm": 0.0014672125689685345,
      "learning_rate": 2.1894332123725593e-05,
      "loss": 0.0001,
      "step": 26480
    },
    {
      "epoch": 5.149688958009332,
      "grad_norm": 0.0007989968871697783,
      "learning_rate": 2.1890012096077414e-05,
      "loss": 0.0001,
      "step": 26490
    },
    {
      "epoch": 5.151632970451011,
      "grad_norm": 0.001261546858586371,
      "learning_rate": 2.1885692068429238e-05,
      "loss": 0.0,
      "step": 26500
    },
    {
      "epoch": 5.153576982892691,
      "grad_norm": 0.00021761069365311414,
      "learning_rate": 2.1881372040781062e-05,
      "loss": 0.0012,
      "step": 26510
    },
    {
      "epoch": 5.155520995334371,
      "grad_norm": 0.0007192914490588009,
      "learning_rate": 2.1877052013132883e-05,
      "loss": 0.0,
      "step": 26520
    },
    {
      "epoch": 5.15746500777605,
      "grad_norm": 0.0005703012575395405,
      "learning_rate": 2.1872731985484707e-05,
      "loss": 0.0,
      "step": 26530
    },
    {
      "epoch": 5.15940902021773,
      "grad_norm": 0.0008209233055822551,
      "learning_rate": 2.186841195783653e-05,
      "loss": 0.0,
      "step": 26540
    },
    {
      "epoch": 5.161353032659409,
      "grad_norm": 0.00043147121323272586,
      "learning_rate": 2.1864091930188352e-05,
      "loss": 0.0,
      "step": 26550
    },
    {
      "epoch": 5.163297045101088,
      "grad_norm": 0.0005026801372878253,
      "learning_rate": 2.1859771902540176e-05,
      "loss": 0.0108,
      "step": 26560
    },
    {
      "epoch": 5.165241057542768,
      "grad_norm": 0.00035482802195474505,
      "learning_rate": 2.1855451874892e-05,
      "loss": 0.0,
      "step": 26570
    },
    {
      "epoch": 5.1671850699844475,
      "grad_norm": 0.0002115757088176906,
      "learning_rate": 2.185113184724382e-05,
      "loss": 0.0,
      "step": 26580
    },
    {
      "epoch": 5.169129082426127,
      "grad_norm": 0.0004884633235633373,
      "learning_rate": 2.184681181959565e-05,
      "loss": 0.0002,
      "step": 26590
    },
    {
      "epoch": 5.171073094867807,
      "grad_norm": 0.0012620362685993314,
      "learning_rate": 2.184249179194747e-05,
      "loss": 0.0,
      "step": 26600
    },
    {
      "epoch": 5.173017107309486,
      "grad_norm": 0.0006855155224911869,
      "learning_rate": 2.183817176429929e-05,
      "loss": 0.0001,
      "step": 26610
    },
    {
      "epoch": 5.174961119751166,
      "grad_norm": 0.0005977690452709794,
      "learning_rate": 2.1833851736651117e-05,
      "loss": 0.0,
      "step": 26620
    },
    {
      "epoch": 5.176905132192846,
      "grad_norm": 0.0008534755324944854,
      "learning_rate": 2.1829531709002938e-05,
      "loss": 0.0,
      "step": 26630
    },
    {
      "epoch": 5.178849144634525,
      "grad_norm": 0.0007873403374105692,
      "learning_rate": 2.182521168135476e-05,
      "loss": 0.0,
      "step": 26640
    },
    {
      "epoch": 5.180793157076205,
      "grad_norm": 0.0008445567800663412,
      "learning_rate": 2.1820891653706586e-05,
      "loss": 0.0,
      "step": 26650
    },
    {
      "epoch": 5.1827371695178845,
      "grad_norm": 0.0007069779676385224,
      "learning_rate": 2.1816571626058407e-05,
      "loss": 0.0,
      "step": 26660
    },
    {
      "epoch": 5.184681181959564,
      "grad_norm": 0.0003942660696338862,
      "learning_rate": 2.1812251598410228e-05,
      "loss": 0.0,
      "step": 26670
    },
    {
      "epoch": 5.186625194401244,
      "grad_norm": 0.0002173522225348279,
      "learning_rate": 2.1807931570762055e-05,
      "loss": 0.001,
      "step": 26680
    },
    {
      "epoch": 5.188569206842923,
      "grad_norm": 0.0002561211003921926,
      "learning_rate": 2.1803611543113876e-05,
      "loss": 0.0001,
      "step": 26690
    },
    {
      "epoch": 5.190513219284603,
      "grad_norm": 0.00020262408361304551,
      "learning_rate": 2.1799291515465697e-05,
      "loss": 0.0,
      "step": 26700
    },
    {
      "epoch": 5.192457231726283,
      "grad_norm": 0.00025188029394485056,
      "learning_rate": 2.1794971487817524e-05,
      "loss": 0.0,
      "step": 26710
    },
    {
      "epoch": 5.194401244167962,
      "grad_norm": 0.00026306178187951446,
      "learning_rate": 2.1790651460169345e-05,
      "loss": 0.0,
      "step": 26720
    },
    {
      "epoch": 5.196345256609642,
      "grad_norm": 0.000744667777325958,
      "learning_rate": 2.1786331432521166e-05,
      "loss": 0.0,
      "step": 26730
    },
    {
      "epoch": 5.198289269051322,
      "grad_norm": 0.00021245278185233474,
      "learning_rate": 2.1782011404872993e-05,
      "loss": 0.0,
      "step": 26740
    },
    {
      "epoch": 5.200233281493001,
      "grad_norm": 0.00022074882872402668,
      "learning_rate": 2.1777691377224814e-05,
      "loss": 0.0,
      "step": 26750
    },
    {
      "epoch": 5.202177293934681,
      "grad_norm": 0.0002798452624119818,
      "learning_rate": 2.1773371349576635e-05,
      "loss": 0.0,
      "step": 26760
    },
    {
      "epoch": 5.2041213063763605,
      "grad_norm": 0.00023740562028251588,
      "learning_rate": 2.1769051321928462e-05,
      "loss": 0.0,
      "step": 26770
    },
    {
      "epoch": 5.20606531881804,
      "grad_norm": 0.00022102247748989612,
      "learning_rate": 2.1764731294280283e-05,
      "loss": 0.0,
      "step": 26780
    },
    {
      "epoch": 5.20800933125972,
      "grad_norm": 0.0002876664511859417,
      "learning_rate": 2.1760411266632107e-05,
      "loss": 0.0,
      "step": 26790
    },
    {
      "epoch": 5.209953343701399,
      "grad_norm": 0.0002068833855446428,
      "learning_rate": 2.175609123898393e-05,
      "loss": 0.0001,
      "step": 26800
    },
    {
      "epoch": 5.211897356143079,
      "grad_norm": 0.00029151097987778485,
      "learning_rate": 2.1751771211335752e-05,
      "loss": 0.0,
      "step": 26810
    },
    {
      "epoch": 5.213841368584759,
      "grad_norm": 0.000199747591977939,
      "learning_rate": 2.174745118368758e-05,
      "loss": 0.0,
      "step": 26820
    },
    {
      "epoch": 5.215785381026438,
      "grad_norm": 0.00022353667009156197,
      "learning_rate": 2.17431311560394e-05,
      "loss": 0.0007,
      "step": 26830
    },
    {
      "epoch": 5.217729393468118,
      "grad_norm": 0.0003905954654328525,
      "learning_rate": 2.173881112839122e-05,
      "loss": 0.0,
      "step": 26840
    },
    {
      "epoch": 5.219673405909798,
      "grad_norm": 0.0003546015068423003,
      "learning_rate": 2.1734491100743048e-05,
      "loss": 0.0,
      "step": 26850
    },
    {
      "epoch": 5.221617418351477,
      "grad_norm": 0.0002790214493870735,
      "learning_rate": 2.173017107309487e-05,
      "loss": 0.0,
      "step": 26860
    },
    {
      "epoch": 5.223561430793157,
      "grad_norm": 0.00042338433559052646,
      "learning_rate": 2.172585104544669e-05,
      "loss": 0.0,
      "step": 26870
    },
    {
      "epoch": 5.2255054432348365,
      "grad_norm": 0.00021839850523974746,
      "learning_rate": 2.1721531017798517e-05,
      "loss": 0.0,
      "step": 26880
    },
    {
      "epoch": 5.227449455676516,
      "grad_norm": 0.0002803616807796061,
      "learning_rate": 2.1717210990150338e-05,
      "loss": 0.0,
      "step": 26890
    },
    {
      "epoch": 5.229393468118196,
      "grad_norm": 0.11731020361185074,
      "learning_rate": 2.171289096250216e-05,
      "loss": 0.0001,
      "step": 26900
    },
    {
      "epoch": 5.231337480559875,
      "grad_norm": 1.627476692199707,
      "learning_rate": 2.1708570934853986e-05,
      "loss": 0.0124,
      "step": 26910
    },
    {
      "epoch": 5.233281493001555,
      "grad_norm": 0.00019673291535582393,
      "learning_rate": 2.1704250907205807e-05,
      "loss": 0.0011,
      "step": 26920
    },
    {
      "epoch": 5.235225505443235,
      "grad_norm": 0.00028171692974865437,
      "learning_rate": 2.1699930879557627e-05,
      "loss": 0.0,
      "step": 26930
    },
    {
      "epoch": 5.237169517884914,
      "grad_norm": 0.0003113232378382236,
      "learning_rate": 2.1695610851909455e-05,
      "loss": 0.0,
      "step": 26940
    },
    {
      "epoch": 5.239113530326594,
      "grad_norm": 4.262712478637695,
      "learning_rate": 2.1691290824261276e-05,
      "loss": 0.0096,
      "step": 26950
    },
    {
      "epoch": 5.2410575427682735,
      "grad_norm": 0.00023334792058449239,
      "learning_rate": 2.16869707966131e-05,
      "loss": 0.0,
      "step": 26960
    },
    {
      "epoch": 5.243001555209953,
      "grad_norm": 0.00023743715428281575,
      "learning_rate": 2.1682650768964924e-05,
      "loss": 0.0002,
      "step": 26970
    },
    {
      "epoch": 5.244945567651633,
      "grad_norm": 0.006937407422810793,
      "learning_rate": 2.1678330741316745e-05,
      "loss": 0.0,
      "step": 26980
    },
    {
      "epoch": 5.246889580093312,
      "grad_norm": 0.00022761113359592855,
      "learning_rate": 2.167401071366857e-05,
      "loss": 0.0,
      "step": 26990
    },
    {
      "epoch": 5.248833592534992,
      "grad_norm": 0.00047618267126381397,
      "learning_rate": 2.1669690686020393e-05,
      "loss": 0.0,
      "step": 27000
    },
    {
      "epoch": 5.250777604976672,
      "grad_norm": 0.0002004035486606881,
      "learning_rate": 2.1665370658372214e-05,
      "loss": 0.0,
      "step": 27010
    },
    {
      "epoch": 5.252721617418351,
      "grad_norm": 0.00018332999025005847,
      "learning_rate": 2.1661050630724038e-05,
      "loss": 0.0,
      "step": 27020
    },
    {
      "epoch": 5.254665629860031,
      "grad_norm": 0.0001886593527160585,
      "learning_rate": 2.1656730603075862e-05,
      "loss": 0.001,
      "step": 27030
    },
    {
      "epoch": 5.256609642301711,
      "grad_norm": 0.00022424061899073422,
      "learning_rate": 2.1652410575427683e-05,
      "loss": 0.0011,
      "step": 27040
    },
    {
      "epoch": 5.25855365474339,
      "grad_norm": 0.00018793351773638278,
      "learning_rate": 2.1648090547779507e-05,
      "loss": 0.0008,
      "step": 27050
    },
    {
      "epoch": 5.26049766718507,
      "grad_norm": 0.005752651486545801,
      "learning_rate": 2.164377052013133e-05,
      "loss": 0.0,
      "step": 27060
    },
    {
      "epoch": 5.2624416796267495,
      "grad_norm": 0.0004893636796623468,
      "learning_rate": 2.163945049248315e-05,
      "loss": 0.0,
      "step": 27070
    },
    {
      "epoch": 5.264385692068429,
      "grad_norm": 0.0003136981977149844,
      "learning_rate": 2.1635130464834976e-05,
      "loss": 0.0036,
      "step": 27080
    },
    {
      "epoch": 5.266329704510109,
      "grad_norm": 0.00019718537805601954,
      "learning_rate": 2.16308104371868e-05,
      "loss": 0.0,
      "step": 27090
    },
    {
      "epoch": 5.268273716951788,
      "grad_norm": 0.0003331014304421842,
      "learning_rate": 2.162649040953862e-05,
      "loss": 0.0,
      "step": 27100
    },
    {
      "epoch": 5.270217729393468,
      "grad_norm": 0.00026657103444449604,
      "learning_rate": 2.1622170381890445e-05,
      "loss": 0.0392,
      "step": 27110
    },
    {
      "epoch": 5.272161741835148,
      "grad_norm": 0.0006668188143521547,
      "learning_rate": 2.161785035424227e-05,
      "loss": 0.0,
      "step": 27120
    },
    {
      "epoch": 5.274105754276827,
      "grad_norm": 0.0002477773232385516,
      "learning_rate": 2.161353032659409e-05,
      "loss": 0.0,
      "step": 27130
    },
    {
      "epoch": 5.276049766718507,
      "grad_norm": 0.00028119783382862806,
      "learning_rate": 2.1609210298945913e-05,
      "loss": 0.0,
      "step": 27140
    },
    {
      "epoch": 5.2779937791601865,
      "grad_norm": 0.00031990473507903516,
      "learning_rate": 2.1604890271297738e-05,
      "loss": 0.0,
      "step": 27150
    },
    {
      "epoch": 5.279937791601866,
      "grad_norm": 0.00021305758855305612,
      "learning_rate": 2.160057024364956e-05,
      "loss": 0.0,
      "step": 27160
    },
    {
      "epoch": 5.281881804043546,
      "grad_norm": 0.00022767941118218005,
      "learning_rate": 2.1596250216001382e-05,
      "loss": 0.0,
      "step": 27170
    },
    {
      "epoch": 5.283825816485225,
      "grad_norm": 0.0016572705935686827,
      "learning_rate": 2.1591930188353207e-05,
      "loss": 0.0,
      "step": 27180
    },
    {
      "epoch": 5.285769828926905,
      "grad_norm": 0.01252829935401678,
      "learning_rate": 2.158761016070503e-05,
      "loss": 0.0422,
      "step": 27190
    },
    {
      "epoch": 5.287713841368585,
      "grad_norm": 0.0003400389105081558,
      "learning_rate": 2.158329013305685e-05,
      "loss": 0.0,
      "step": 27200
    },
    {
      "epoch": 5.289657853810264,
      "grad_norm": 0.001125360606238246,
      "learning_rate": 2.1578970105408675e-05,
      "loss": 0.0001,
      "step": 27210
    },
    {
      "epoch": 5.291601866251944,
      "grad_norm": 0.000542967114597559,
      "learning_rate": 2.15746500777605e-05,
      "loss": 0.0047,
      "step": 27220
    },
    {
      "epoch": 5.293545878693624,
      "grad_norm": 0.001840834622271359,
      "learning_rate": 2.157033005011232e-05,
      "loss": 0.0,
      "step": 27230
    },
    {
      "epoch": 5.295489891135303,
      "grad_norm": 0.00033537563285790384,
      "learning_rate": 2.1566010022464144e-05,
      "loss": 0.0001,
      "step": 27240
    },
    {
      "epoch": 5.297433903576983,
      "grad_norm": 0.0006476943381130695,
      "learning_rate": 2.156168999481597e-05,
      "loss": 0.0001,
      "step": 27250
    },
    {
      "epoch": 5.2993779160186625,
      "grad_norm": 0.08822676539421082,
      "learning_rate": 2.155736996716779e-05,
      "loss": 0.0003,
      "step": 27260
    },
    {
      "epoch": 5.301321928460342,
      "grad_norm": 0.0006586092058569193,
      "learning_rate": 2.1553049939519613e-05,
      "loss": 0.0001,
      "step": 27270
    },
    {
      "epoch": 5.303265940902022,
      "grad_norm": 0.00039307939005084336,
      "learning_rate": 2.1548729911871437e-05,
      "loss": 0.0,
      "step": 27280
    },
    {
      "epoch": 5.305209953343701,
      "grad_norm": 0.0006251578452065587,
      "learning_rate": 2.1544409884223258e-05,
      "loss": 0.0,
      "step": 27290
    },
    {
      "epoch": 5.307153965785381,
      "grad_norm": 0.0007044787053018808,
      "learning_rate": 2.1540089856575082e-05,
      "loss": 0.0,
      "step": 27300
    },
    {
      "epoch": 5.309097978227061,
      "grad_norm": 0.00048561629955656826,
      "learning_rate": 2.1535769828926906e-05,
      "loss": 0.0,
      "step": 27310
    },
    {
      "epoch": 5.31104199066874,
      "grad_norm": 0.0003801217535510659,
      "learning_rate": 2.1531449801278727e-05,
      "loss": 0.0,
      "step": 27320
    },
    {
      "epoch": 5.31298600311042,
      "grad_norm": 0.0008702445775270462,
      "learning_rate": 2.152712977363055e-05,
      "loss": 0.0,
      "step": 27330
    },
    {
      "epoch": 5.3149300155520995,
      "grad_norm": 0.29515957832336426,
      "learning_rate": 2.1522809745982375e-05,
      "loss": 0.0001,
      "step": 27340
    },
    {
      "epoch": 5.316874027993779,
      "grad_norm": 0.00021242944058030844,
      "learning_rate": 2.1518489718334196e-05,
      "loss": 0.0,
      "step": 27350
    },
    {
      "epoch": 5.318818040435459,
      "grad_norm": 0.00028133767773397267,
      "learning_rate": 2.1514169690686024e-05,
      "loss": 0.0,
      "step": 27360
    },
    {
      "epoch": 5.320762052877138,
      "grad_norm": 0.00046302404371090233,
      "learning_rate": 2.1509849663037844e-05,
      "loss": 0.0,
      "step": 27370
    },
    {
      "epoch": 5.322706065318818,
      "grad_norm": 0.0001929235295392573,
      "learning_rate": 2.1505529635389665e-05,
      "loss": 0.0,
      "step": 27380
    },
    {
      "epoch": 5.324650077760498,
      "grad_norm": 0.00029643799643963575,
      "learning_rate": 2.1501209607741493e-05,
      "loss": 0.0,
      "step": 27390
    },
    {
      "epoch": 5.326594090202177,
      "grad_norm": 0.00024101085728034377,
      "learning_rate": 2.1496889580093313e-05,
      "loss": 0.0001,
      "step": 27400
    },
    {
      "epoch": 5.328538102643857,
      "grad_norm": 0.00020459356892388314,
      "learning_rate": 2.1492569552445134e-05,
      "loss": 0.0,
      "step": 27410
    },
    {
      "epoch": 5.330482115085537,
      "grad_norm": 0.0009220484644174576,
      "learning_rate": 2.148824952479696e-05,
      "loss": 0.0,
      "step": 27420
    },
    {
      "epoch": 5.332426127527216,
      "grad_norm": 0.00018876095418818295,
      "learning_rate": 2.1483929497148782e-05,
      "loss": 0.0,
      "step": 27430
    },
    {
      "epoch": 5.334370139968896,
      "grad_norm": 0.00021673261653631926,
      "learning_rate": 2.1479609469500603e-05,
      "loss": 0.0,
      "step": 27440
    },
    {
      "epoch": 5.3363141524105755,
      "grad_norm": 0.0004810143436770886,
      "learning_rate": 2.147528944185243e-05,
      "loss": 0.0,
      "step": 27450
    },
    {
      "epoch": 5.338258164852255,
      "grad_norm": 0.001704389345832169,
      "learning_rate": 2.147096941420425e-05,
      "loss": 0.0003,
      "step": 27460
    },
    {
      "epoch": 5.340202177293935,
      "grad_norm": 0.00028321417630650103,
      "learning_rate": 2.1466649386556072e-05,
      "loss": 0.0,
      "step": 27470
    },
    {
      "epoch": 5.342146189735614,
      "grad_norm": 0.00027581778704188764,
      "learning_rate": 2.14623293589079e-05,
      "loss": 0.0,
      "step": 27480
    },
    {
      "epoch": 5.344090202177294,
      "grad_norm": 0.00016609231533948332,
      "learning_rate": 2.145800933125972e-05,
      "loss": 0.0,
      "step": 27490
    },
    {
      "epoch": 5.346034214618974,
      "grad_norm": 0.0003306891885586083,
      "learning_rate": 2.145368930361154e-05,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 5.347978227060653,
      "grad_norm": 0.0002703038917388767,
      "learning_rate": 2.1449369275963368e-05,
      "loss": 0.0,
      "step": 27510
    },
    {
      "epoch": 5.349922239502333,
      "grad_norm": 0.0002488518657628447,
      "learning_rate": 2.144504924831519e-05,
      "loss": 0.0,
      "step": 27520
    },
    {
      "epoch": 5.3518662519440126,
      "grad_norm": 0.0006272795726545155,
      "learning_rate": 2.144072922066701e-05,
      "loss": 0.0,
      "step": 27530
    },
    {
      "epoch": 5.353810264385692,
      "grad_norm": 0.00022679030371364206,
      "learning_rate": 2.1436409193018837e-05,
      "loss": 0.0,
      "step": 27540
    },
    {
      "epoch": 5.355754276827372,
      "grad_norm": 0.00025944531080313027,
      "learning_rate": 2.1432089165370658e-05,
      "loss": 0.0,
      "step": 27550
    },
    {
      "epoch": 5.3576982892690515,
      "grad_norm": 0.00021586145157925785,
      "learning_rate": 2.1427769137722482e-05,
      "loss": 0.0,
      "step": 27560
    },
    {
      "epoch": 5.359642301710731,
      "grad_norm": 0.0005181600572541356,
      "learning_rate": 2.1423449110074306e-05,
      "loss": 0.0,
      "step": 27570
    },
    {
      "epoch": 5.361586314152411,
      "grad_norm": 0.0002338769700145349,
      "learning_rate": 2.1419129082426127e-05,
      "loss": 0.0,
      "step": 27580
    },
    {
      "epoch": 5.36353032659409,
      "grad_norm": 0.00025099440244957805,
      "learning_rate": 2.141480905477795e-05,
      "loss": 0.0,
      "step": 27590
    },
    {
      "epoch": 5.36547433903577,
      "grad_norm": 0.00016245691222138703,
      "learning_rate": 2.1410489027129775e-05,
      "loss": 0.0,
      "step": 27600
    },
    {
      "epoch": 5.36741835147745,
      "grad_norm": 0.0002232870610896498,
      "learning_rate": 2.1406168999481596e-05,
      "loss": 0.0,
      "step": 27610
    },
    {
      "epoch": 5.369362363919129,
      "grad_norm": 0.0002954808878712356,
      "learning_rate": 2.140184897183342e-05,
      "loss": 0.0,
      "step": 27620
    },
    {
      "epoch": 5.371306376360809,
      "grad_norm": 0.00019132359011564404,
      "learning_rate": 2.1397528944185244e-05,
      "loss": 0.0002,
      "step": 27630
    },
    {
      "epoch": 5.3732503888024885,
      "grad_norm": 0.00018177606398239732,
      "learning_rate": 2.1393208916537065e-05,
      "loss": 0.0,
      "step": 27640
    },
    {
      "epoch": 5.375194401244168,
      "grad_norm": 0.00033493811497464776,
      "learning_rate": 2.138888888888889e-05,
      "loss": 0.0,
      "step": 27650
    },
    {
      "epoch": 5.377138413685848,
      "grad_norm": 0.00020112063793931156,
      "learning_rate": 2.1384568861240713e-05,
      "loss": 0.0,
      "step": 27660
    },
    {
      "epoch": 5.379082426127527,
      "grad_norm": 0.00017178835696540773,
      "learning_rate": 2.1380248833592534e-05,
      "loss": 0.0,
      "step": 27670
    },
    {
      "epoch": 5.381026438569207,
      "grad_norm": 0.00020001811208203435,
      "learning_rate": 2.1375928805944358e-05,
      "loss": 0.0173,
      "step": 27680
    },
    {
      "epoch": 5.382970451010887,
      "grad_norm": 0.0002055022632703185,
      "learning_rate": 2.1371608778296182e-05,
      "loss": 0.0018,
      "step": 27690
    },
    {
      "epoch": 5.384914463452566,
      "grad_norm": 0.00036257150350138545,
      "learning_rate": 2.1367288750648003e-05,
      "loss": 0.0,
      "step": 27700
    },
    {
      "epoch": 5.386858475894246,
      "grad_norm": 0.00019116113253403455,
      "learning_rate": 2.136296872299983e-05,
      "loss": 0.0001,
      "step": 27710
    },
    {
      "epoch": 5.388802488335926,
      "grad_norm": 0.0006092404946684837,
      "learning_rate": 2.135864869535165e-05,
      "loss": 0.0001,
      "step": 27720
    },
    {
      "epoch": 5.390746500777605,
      "grad_norm": 0.00023685593623667955,
      "learning_rate": 2.135432866770347e-05,
      "loss": 0.0,
      "step": 27730
    },
    {
      "epoch": 5.392690513219285,
      "grad_norm": 0.01228424347937107,
      "learning_rate": 2.13500086400553e-05,
      "loss": 0.0,
      "step": 27740
    },
    {
      "epoch": 5.3946345256609645,
      "grad_norm": 0.00026631064247339964,
      "learning_rate": 2.134568861240712e-05,
      "loss": 0.0,
      "step": 27750
    },
    {
      "epoch": 5.396578538102644,
      "grad_norm": 0.0001804390485631302,
      "learning_rate": 2.1341368584758944e-05,
      "loss": 0.0007,
      "step": 27760
    },
    {
      "epoch": 5.398522550544324,
      "grad_norm": 0.0001583216362632811,
      "learning_rate": 2.1337048557110768e-05,
      "loss": 0.0102,
      "step": 27770
    },
    {
      "epoch": 5.400466562986003,
      "grad_norm": 0.0001775153068592772,
      "learning_rate": 2.133272852946259e-05,
      "loss": 0.0,
      "step": 27780
    },
    {
      "epoch": 5.402410575427683,
      "grad_norm": 0.0007755733095109463,
      "learning_rate": 2.1328408501814413e-05,
      "loss": 0.0,
      "step": 27790
    },
    {
      "epoch": 5.404354587869363,
      "grad_norm": 0.00020273166592232883,
      "learning_rate": 2.1324088474166237e-05,
      "loss": 0.0,
      "step": 27800
    },
    {
      "epoch": 5.406298600311042,
      "grad_norm": 0.00024798401864245534,
      "learning_rate": 2.1319768446518058e-05,
      "loss": 0.0,
      "step": 27810
    },
    {
      "epoch": 5.408242612752722,
      "grad_norm": 0.0001556306960992515,
      "learning_rate": 2.1315448418869882e-05,
      "loss": 0.0,
      "step": 27820
    },
    {
      "epoch": 5.4101866251944015,
      "grad_norm": 0.00020264262275304645,
      "learning_rate": 2.1311128391221706e-05,
      "loss": 0.0,
      "step": 27830
    },
    {
      "epoch": 5.412130637636081,
      "grad_norm": 0.00022810792142990977,
      "learning_rate": 2.1306808363573527e-05,
      "loss": 0.0,
      "step": 27840
    },
    {
      "epoch": 5.414074650077761,
      "grad_norm": 0.0002817300264723599,
      "learning_rate": 2.130248833592535e-05,
      "loss": 0.0,
      "step": 27850
    },
    {
      "epoch": 5.41601866251944,
      "grad_norm": 0.0001979373919311911,
      "learning_rate": 2.1298168308277175e-05,
      "loss": 0.0,
      "step": 27860
    },
    {
      "epoch": 5.41796267496112,
      "grad_norm": 0.0012407292379066348,
      "learning_rate": 2.1293848280628996e-05,
      "loss": 0.0,
      "step": 27870
    },
    {
      "epoch": 5.4199066874028,
      "grad_norm": 0.00018942425958812237,
      "learning_rate": 2.128952825298082e-05,
      "loss": 0.0,
      "step": 27880
    },
    {
      "epoch": 5.421850699844479,
      "grad_norm": 0.0015973118133842945,
      "learning_rate": 2.1285208225332644e-05,
      "loss": 0.0,
      "step": 27890
    },
    {
      "epoch": 5.423794712286159,
      "grad_norm": 0.00014851237938273698,
      "learning_rate": 2.1280888197684465e-05,
      "loss": 0.0,
      "step": 27900
    },
    {
      "epoch": 5.425738724727839,
      "grad_norm": 0.00016555727052036673,
      "learning_rate": 2.127656817003629e-05,
      "loss": 0.0,
      "step": 27910
    },
    {
      "epoch": 5.427682737169518,
      "grad_norm": 0.0001668455224717036,
      "learning_rate": 2.1272248142388113e-05,
      "loss": 0.0,
      "step": 27920
    },
    {
      "epoch": 5.429626749611198,
      "grad_norm": 0.00016866950318217278,
      "learning_rate": 2.1267928114739934e-05,
      "loss": 0.0,
      "step": 27930
    },
    {
      "epoch": 5.4315707620528775,
      "grad_norm": 0.00017721914628054947,
      "learning_rate": 2.1263608087091758e-05,
      "loss": 0.0,
      "step": 27940
    },
    {
      "epoch": 5.433514774494557,
      "grad_norm": 0.0006343289278447628,
      "learning_rate": 2.1259288059443582e-05,
      "loss": 0.0,
      "step": 27950
    },
    {
      "epoch": 5.435458786936237,
      "grad_norm": 0.00023667101049795747,
      "learning_rate": 2.1254968031795406e-05,
      "loss": 0.0183,
      "step": 27960
    },
    {
      "epoch": 5.437402799377916,
      "grad_norm": 0.0009987934026867151,
      "learning_rate": 2.1250648004147227e-05,
      "loss": 0.0,
      "step": 27970
    },
    {
      "epoch": 5.439346811819596,
      "grad_norm": 0.004918154329061508,
      "learning_rate": 2.124632797649905e-05,
      "loss": 0.0001,
      "step": 27980
    },
    {
      "epoch": 5.441290824261276,
      "grad_norm": 15.545232772827148,
      "learning_rate": 2.1242007948850875e-05,
      "loss": 0.0174,
      "step": 27990
    },
    {
      "epoch": 5.443234836702955,
      "grad_norm": 0.0013849370880052447,
      "learning_rate": 2.1237687921202695e-05,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 5.445178849144635,
      "grad_norm": 0.0037219123914837837,
      "learning_rate": 2.123336789355452e-05,
      "loss": 0.0113,
      "step": 28010
    },
    {
      "epoch": 5.4471228615863145,
      "grad_norm": 0.014081860892474651,
      "learning_rate": 2.1229047865906344e-05,
      "loss": 0.0005,
      "step": 28020
    },
    {
      "epoch": 5.449066874027994,
      "grad_norm": 0.00913985911756754,
      "learning_rate": 2.1224727838258164e-05,
      "loss": 0.0001,
      "step": 28030
    },
    {
      "epoch": 5.451010886469674,
      "grad_norm": 0.0007111312006600201,
      "learning_rate": 2.122040781060999e-05,
      "loss": 0.0,
      "step": 28040
    },
    {
      "epoch": 5.452954898911353,
      "grad_norm": 0.000390635832445696,
      "learning_rate": 2.1216087782961813e-05,
      "loss": 0.0,
      "step": 28050
    },
    {
      "epoch": 5.454898911353033,
      "grad_norm": 0.00028630541055463254,
      "learning_rate": 2.1211767755313633e-05,
      "loss": 0.0,
      "step": 28060
    },
    {
      "epoch": 5.456842923794713,
      "grad_norm": 0.0007829436799511313,
      "learning_rate": 2.1207447727665457e-05,
      "loss": 0.0,
      "step": 28070
    },
    {
      "epoch": 5.458786936236392,
      "grad_norm": 0.0005115853855386376,
      "learning_rate": 2.120312770001728e-05,
      "loss": 0.0,
      "step": 28080
    },
    {
      "epoch": 5.460730948678071,
      "grad_norm": 0.00022603532124776393,
      "learning_rate": 2.1198807672369102e-05,
      "loss": 0.0011,
      "step": 28090
    },
    {
      "epoch": 5.462674961119751,
      "grad_norm": 11.555225372314453,
      "learning_rate": 2.1194487644720926e-05,
      "loss": 0.0043,
      "step": 28100
    },
    {
      "epoch": 5.46461897356143,
      "grad_norm": 0.00036793158506043255,
      "learning_rate": 2.119016761707275e-05,
      "loss": 0.0,
      "step": 28110
    },
    {
      "epoch": 5.46656298600311,
      "grad_norm": 0.0006228241254575551,
      "learning_rate": 2.118584758942457e-05,
      "loss": 0.0,
      "step": 28120
    },
    {
      "epoch": 5.46850699844479,
      "grad_norm": 0.0003584598598536104,
      "learning_rate": 2.1181527561776395e-05,
      "loss": 0.0001,
      "step": 28130
    },
    {
      "epoch": 5.470451010886469,
      "grad_norm": 0.00020038807997480035,
      "learning_rate": 2.117720753412822e-05,
      "loss": 0.0,
      "step": 28140
    },
    {
      "epoch": 5.472395023328149,
      "grad_norm": 0.0014238731237128377,
      "learning_rate": 2.117288750648004e-05,
      "loss": 0.0,
      "step": 28150
    },
    {
      "epoch": 5.4743390357698285,
      "grad_norm": 0.00028827355708926916,
      "learning_rate": 2.1168567478831868e-05,
      "loss": 0.0,
      "step": 28160
    },
    {
      "epoch": 5.476283048211508,
      "grad_norm": 0.11031047999858856,
      "learning_rate": 2.116424745118369e-05,
      "loss": 0.0157,
      "step": 28170
    },
    {
      "epoch": 5.478227060653188,
      "grad_norm": 0.005375580862164497,
      "learning_rate": 2.115992742353551e-05,
      "loss": 0.0001,
      "step": 28180
    },
    {
      "epoch": 5.480171073094867,
      "grad_norm": 0.0031173040624707937,
      "learning_rate": 2.1155607395887337e-05,
      "loss": 0.0001,
      "step": 28190
    },
    {
      "epoch": 5.482115085536547,
      "grad_norm": 0.0019452044507488608,
      "learning_rate": 2.1151287368239157e-05,
      "loss": 0.0001,
      "step": 28200
    },
    {
      "epoch": 5.484059097978227,
      "grad_norm": 0.0021841912530362606,
      "learning_rate": 2.1146967340590978e-05,
      "loss": 0.0183,
      "step": 28210
    },
    {
      "epoch": 5.486003110419906,
      "grad_norm": 0.0013963044621050358,
      "learning_rate": 2.1142647312942806e-05,
      "loss": 0.0067,
      "step": 28220
    },
    {
      "epoch": 5.487947122861586,
      "grad_norm": 0.013246380724012852,
      "learning_rate": 2.1138327285294626e-05,
      "loss": 0.0001,
      "step": 28230
    },
    {
      "epoch": 5.489891135303266,
      "grad_norm": 0.0011222953908145428,
      "learning_rate": 2.1134007257646447e-05,
      "loss": 0.0,
      "step": 28240
    },
    {
      "epoch": 5.491835147744945,
      "grad_norm": 0.15266619622707367,
      "learning_rate": 2.1129687229998275e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 5.493779160186625,
      "grad_norm": 0.00024069467326626182,
      "learning_rate": 2.1125367202350095e-05,
      "loss": 0.0025,
      "step": 28260
    },
    {
      "epoch": 5.4957231726283045,
      "grad_norm": 0.000432330125477165,
      "learning_rate": 2.1121047174701916e-05,
      "loss": 0.0,
      "step": 28270
    },
    {
      "epoch": 5.497667185069984,
      "grad_norm": 0.000511311402078718,
      "learning_rate": 2.1116727147053743e-05,
      "loss": 0.0146,
      "step": 28280
    },
    {
      "epoch": 5.499611197511664,
      "grad_norm": 0.0005129873752593994,
      "learning_rate": 2.1112407119405564e-05,
      "loss": 0.0,
      "step": 28290
    },
    {
      "epoch": 5.501555209953343,
      "grad_norm": 0.00038215387030504644,
      "learning_rate": 2.1108087091757385e-05,
      "loss": 0.0,
      "step": 28300
    },
    {
      "epoch": 5.503499222395023,
      "grad_norm": 0.0004454878799151629,
      "learning_rate": 2.1103767064109212e-05,
      "loss": 0.0,
      "step": 28310
    },
    {
      "epoch": 5.505443234836703,
      "grad_norm": 0.00018873182125389576,
      "learning_rate": 2.1099447036461033e-05,
      "loss": 0.0,
      "step": 28320
    },
    {
      "epoch": 5.507387247278382,
      "grad_norm": 0.008121167309582233,
      "learning_rate": 2.1095127008812857e-05,
      "loss": 0.0,
      "step": 28330
    },
    {
      "epoch": 5.509331259720062,
      "grad_norm": 0.000634942261967808,
      "learning_rate": 2.109080698116468e-05,
      "loss": 0.0,
      "step": 28340
    },
    {
      "epoch": 5.5112752721617415,
      "grad_norm": 0.00038373752613551915,
      "learning_rate": 2.1086486953516502e-05,
      "loss": 0.0,
      "step": 28350
    },
    {
      "epoch": 5.513219284603421,
      "grad_norm": 0.00039349275175482035,
      "learning_rate": 2.1082166925868326e-05,
      "loss": 0.012,
      "step": 28360
    },
    {
      "epoch": 5.515163297045101,
      "grad_norm": 0.0004913992597721517,
      "learning_rate": 2.107784689822015e-05,
      "loss": 0.0,
      "step": 28370
    },
    {
      "epoch": 5.51710730948678,
      "grad_norm": 0.0007436699816025794,
      "learning_rate": 2.107352687057197e-05,
      "loss": 0.0131,
      "step": 28380
    },
    {
      "epoch": 5.51905132192846,
      "grad_norm": 0.0002189052029279992,
      "learning_rate": 2.1069206842923795e-05,
      "loss": 0.0,
      "step": 28390
    },
    {
      "epoch": 5.52099533437014,
      "grad_norm": 0.0004996388452127576,
      "learning_rate": 2.106488681527562e-05,
      "loss": 0.0,
      "step": 28400
    },
    {
      "epoch": 5.522939346811819,
      "grad_norm": 0.00024777077487669885,
      "learning_rate": 2.106056678762744e-05,
      "loss": 0.0003,
      "step": 28410
    },
    {
      "epoch": 5.524883359253499,
      "grad_norm": 0.000300008337944746,
      "learning_rate": 2.1056246759979264e-05,
      "loss": 0.0,
      "step": 28420
    },
    {
      "epoch": 5.526827371695179,
      "grad_norm": 0.0004345092747826129,
      "learning_rate": 2.1051926732331088e-05,
      "loss": 0.0,
      "step": 28430
    },
    {
      "epoch": 5.528771384136858,
      "grad_norm": 0.0002732710272539407,
      "learning_rate": 2.104760670468291e-05,
      "loss": 0.0,
      "step": 28440
    },
    {
      "epoch": 5.530715396578538,
      "grad_norm": 0.00018235668540000916,
      "learning_rate": 2.1043286677034733e-05,
      "loss": 0.0005,
      "step": 28450
    },
    {
      "epoch": 5.5326594090202175,
      "grad_norm": 0.00019822742615360767,
      "learning_rate": 2.1038966649386557e-05,
      "loss": 0.0,
      "step": 28460
    },
    {
      "epoch": 5.534603421461897,
      "grad_norm": 0.00023401767248287797,
      "learning_rate": 2.1034646621738378e-05,
      "loss": 0.0001,
      "step": 28470
    },
    {
      "epoch": 5.536547433903577,
      "grad_norm": 0.0003347221645526588,
      "learning_rate": 2.1030326594090202e-05,
      "loss": 0.0,
      "step": 28480
    },
    {
      "epoch": 5.538491446345256,
      "grad_norm": 0.000171810039319098,
      "learning_rate": 2.1026006566442026e-05,
      "loss": 0.0001,
      "step": 28490
    },
    {
      "epoch": 5.540435458786936,
      "grad_norm": 0.00025347794871777296,
      "learning_rate": 2.1021686538793847e-05,
      "loss": 0.001,
      "step": 28500
    },
    {
      "epoch": 5.542379471228616,
      "grad_norm": 0.00019395173876546323,
      "learning_rate": 2.101736651114567e-05,
      "loss": 0.0041,
      "step": 28510
    },
    {
      "epoch": 5.544323483670295,
      "grad_norm": 0.00018956435087602586,
      "learning_rate": 2.1013046483497495e-05,
      "loss": 0.0,
      "step": 28520
    },
    {
      "epoch": 5.546267496111975,
      "grad_norm": 0.0002158919523935765,
      "learning_rate": 2.100872645584932e-05,
      "loss": 0.0,
      "step": 28530
    },
    {
      "epoch": 5.5482115085536545,
      "grad_norm": 0.0006552225677296519,
      "learning_rate": 2.100440642820114e-05,
      "loss": 0.0081,
      "step": 28540
    },
    {
      "epoch": 5.550155520995334,
      "grad_norm": 0.0001917601184686646,
      "learning_rate": 2.1000086400552964e-05,
      "loss": 0.011,
      "step": 28550
    },
    {
      "epoch": 5.552099533437014,
      "grad_norm": 0.002458499977365136,
      "learning_rate": 2.0995766372904788e-05,
      "loss": 0.0,
      "step": 28560
    },
    {
      "epoch": 5.554043545878693,
      "grad_norm": 0.0007411674596369267,
      "learning_rate": 2.099144634525661e-05,
      "loss": 0.0,
      "step": 28570
    },
    {
      "epoch": 5.555987558320373,
      "grad_norm": 0.0012296376517042518,
      "learning_rate": 2.0987126317608433e-05,
      "loss": 0.0,
      "step": 28580
    },
    {
      "epoch": 5.557931570762053,
      "grad_norm": 0.00040805150638334453,
      "learning_rate": 2.0982806289960257e-05,
      "loss": 0.0,
      "step": 28590
    },
    {
      "epoch": 5.559875583203732,
      "grad_norm": 0.0002801749506033957,
      "learning_rate": 2.0978486262312078e-05,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 5.561819595645412,
      "grad_norm": 0.0002043437270913273,
      "learning_rate": 2.0974166234663902e-05,
      "loss": 0.0053,
      "step": 28610
    },
    {
      "epoch": 5.563763608087092,
      "grad_norm": 0.0002469236496835947,
      "learning_rate": 2.0969846207015726e-05,
      "loss": 0.007,
      "step": 28620
    },
    {
      "epoch": 5.565707620528771,
      "grad_norm": 0.0003337009693495929,
      "learning_rate": 2.096552617936755e-05,
      "loss": 0.0,
      "step": 28630
    },
    {
      "epoch": 5.567651632970451,
      "grad_norm": 0.0003100759640801698,
      "learning_rate": 2.096120615171937e-05,
      "loss": 0.0,
      "step": 28640
    },
    {
      "epoch": 5.5695956454121305,
      "grad_norm": 0.00020165301975794137,
      "learning_rate": 2.0956886124071195e-05,
      "loss": 0.0,
      "step": 28650
    },
    {
      "epoch": 5.57153965785381,
      "grad_norm": 0.00021472317166626453,
      "learning_rate": 2.095256609642302e-05,
      "loss": 0.0047,
      "step": 28660
    },
    {
      "epoch": 5.57348367029549,
      "grad_norm": 0.00022373537649400532,
      "learning_rate": 2.094824606877484e-05,
      "loss": 0.0,
      "step": 28670
    },
    {
      "epoch": 5.575427682737169,
      "grad_norm": 0.0006002497975714505,
      "learning_rate": 2.0943926041126664e-05,
      "loss": 0.0,
      "step": 28680
    },
    {
      "epoch": 5.577371695178849,
      "grad_norm": 0.0007582625257782638,
      "learning_rate": 2.0939606013478488e-05,
      "loss": 0.0,
      "step": 28690
    },
    {
      "epoch": 5.579315707620529,
      "grad_norm": 0.00019627410802058876,
      "learning_rate": 2.093528598583031e-05,
      "loss": 0.0,
      "step": 28700
    },
    {
      "epoch": 5.581259720062208,
      "grad_norm": 0.00026292336406186223,
      "learning_rate": 2.0930965958182133e-05,
      "loss": 0.0,
      "step": 28710
    },
    {
      "epoch": 5.583203732503888,
      "grad_norm": 0.0001815681898733601,
      "learning_rate": 2.0926645930533957e-05,
      "loss": 0.0,
      "step": 28720
    },
    {
      "epoch": 5.5851477449455675,
      "grad_norm": 0.0017779816407710314,
      "learning_rate": 2.092232590288578e-05,
      "loss": 0.0,
      "step": 28730
    },
    {
      "epoch": 5.587091757387247,
      "grad_norm": 0.0002600459847599268,
      "learning_rate": 2.0918005875237602e-05,
      "loss": 0.0074,
      "step": 28740
    },
    {
      "epoch": 5.589035769828927,
      "grad_norm": 0.0014315147418528795,
      "learning_rate": 2.0913685847589426e-05,
      "loss": 0.0,
      "step": 28750
    },
    {
      "epoch": 5.590979782270606,
      "grad_norm": 0.00042841676622629166,
      "learning_rate": 2.090936581994125e-05,
      "loss": 0.0016,
      "step": 28760
    },
    {
      "epoch": 5.592923794712286,
      "grad_norm": 0.00048551923828199506,
      "learning_rate": 2.090504579229307e-05,
      "loss": 0.0207,
      "step": 28770
    },
    {
      "epoch": 5.594867807153966,
      "grad_norm": 0.006366083864122629,
      "learning_rate": 2.0900725764644895e-05,
      "loss": 0.0366,
      "step": 28780
    },
    {
      "epoch": 5.596811819595645,
      "grad_norm": 0.0007187065202742815,
      "learning_rate": 2.089640573699672e-05,
      "loss": 0.0001,
      "step": 28790
    },
    {
      "epoch": 5.598755832037325,
      "grad_norm": 0.003683236660435796,
      "learning_rate": 2.089208570934854e-05,
      "loss": 0.0002,
      "step": 28800
    },
    {
      "epoch": 5.600699844479005,
      "grad_norm": 0.001077577704563737,
      "learning_rate": 2.0887765681700364e-05,
      "loss": 0.0,
      "step": 28810
    },
    {
      "epoch": 5.602643856920684,
      "grad_norm": 0.0007215218502096832,
      "learning_rate": 2.0883445654052188e-05,
      "loss": 0.0001,
      "step": 28820
    },
    {
      "epoch": 5.604587869362364,
      "grad_norm": 0.0009141151676885784,
      "learning_rate": 2.087912562640401e-05,
      "loss": 0.0162,
      "step": 28830
    },
    {
      "epoch": 5.6065318818040435,
      "grad_norm": 0.0026938156224787235,
      "learning_rate": 2.0874805598755833e-05,
      "loss": 0.0002,
      "step": 28840
    },
    {
      "epoch": 5.608475894245723,
      "grad_norm": 0.0036457625683397055,
      "learning_rate": 2.0870485571107657e-05,
      "loss": 0.0002,
      "step": 28850
    },
    {
      "epoch": 5.610419906687403,
      "grad_norm": 0.0025136673357337713,
      "learning_rate": 2.0866165543459478e-05,
      "loss": 0.0008,
      "step": 28860
    },
    {
      "epoch": 5.612363919129082,
      "grad_norm": 0.001859478303231299,
      "learning_rate": 2.08618455158113e-05,
      "loss": 0.0003,
      "step": 28870
    },
    {
      "epoch": 5.614307931570762,
      "grad_norm": 0.0010006397496908903,
      "learning_rate": 2.0857525488163126e-05,
      "loss": 0.0001,
      "step": 28880
    },
    {
      "epoch": 5.616251944012442,
      "grad_norm": 0.0006493314285762608,
      "learning_rate": 2.0853205460514946e-05,
      "loss": 0.0001,
      "step": 28890
    },
    {
      "epoch": 5.618195956454121,
      "grad_norm": 0.000685544335283339,
      "learning_rate": 2.084888543286677e-05,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 5.620139968895801,
      "grad_norm": 0.0004700185963883996,
      "learning_rate": 2.0844565405218595e-05,
      "loss": 0.015,
      "step": 28910
    },
    {
      "epoch": 5.6220839813374806,
      "grad_norm": 0.0004864679358433932,
      "learning_rate": 2.0840245377570415e-05,
      "loss": 0.0001,
      "step": 28920
    },
    {
      "epoch": 5.62402799377916,
      "grad_norm": 0.00037062581395730376,
      "learning_rate": 2.0835925349922243e-05,
      "loss": 0.0,
      "step": 28930
    },
    {
      "epoch": 5.62597200622084,
      "grad_norm": 0.0007554905023425817,
      "learning_rate": 2.0831605322274064e-05,
      "loss": 0.0001,
      "step": 28940
    },
    {
      "epoch": 5.6279160186625194,
      "grad_norm": 0.0006800502887926996,
      "learning_rate": 2.0827285294625884e-05,
      "loss": 0.0274,
      "step": 28950
    },
    {
      "epoch": 5.629860031104199,
      "grad_norm": 0.0011561681749299169,
      "learning_rate": 2.0822965266977712e-05,
      "loss": 0.0,
      "step": 28960
    },
    {
      "epoch": 5.631804043545879,
      "grad_norm": 0.0004958774661645293,
      "learning_rate": 2.0818645239329533e-05,
      "loss": 0.0001,
      "step": 28970
    },
    {
      "epoch": 5.633748055987558,
      "grad_norm": 0.0007904027006588876,
      "learning_rate": 2.0814325211681353e-05,
      "loss": 0.0001,
      "step": 28980
    },
    {
      "epoch": 5.635692068429238,
      "grad_norm": 0.0008669003145769238,
      "learning_rate": 2.081000518403318e-05,
      "loss": 0.0004,
      "step": 28990
    },
    {
      "epoch": 5.637636080870918,
      "grad_norm": 0.0005357504123821855,
      "learning_rate": 2.0805685156385e-05,
      "loss": 0.0,
      "step": 29000
    },
    {
      "epoch": 5.639580093312597,
      "grad_norm": 0.044031597673892975,
      "learning_rate": 2.0801365128736822e-05,
      "loss": 0.0001,
      "step": 29010
    },
    {
      "epoch": 5.641524105754277,
      "grad_norm": 0.0010726607870310545,
      "learning_rate": 2.079704510108865e-05,
      "loss": 0.0001,
      "step": 29020
    },
    {
      "epoch": 5.6434681181959565,
      "grad_norm": 0.00043758205720223486,
      "learning_rate": 2.079272507344047e-05,
      "loss": 0.0,
      "step": 29030
    },
    {
      "epoch": 5.645412130637636,
      "grad_norm": 0.00035879117785952985,
      "learning_rate": 2.078840504579229e-05,
      "loss": 0.0,
      "step": 29040
    },
    {
      "epoch": 5.647356143079316,
      "grad_norm": 0.0004436555609572679,
      "learning_rate": 2.078408501814412e-05,
      "loss": 0.0003,
      "step": 29050
    },
    {
      "epoch": 5.649300155520995,
      "grad_norm": 0.07524383068084717,
      "learning_rate": 2.077976499049594e-05,
      "loss": 0.0001,
      "step": 29060
    },
    {
      "epoch": 5.651244167962675,
      "grad_norm": 0.00020176704856567085,
      "learning_rate": 2.077544496284776e-05,
      "loss": 0.0001,
      "step": 29070
    },
    {
      "epoch": 5.653188180404355,
      "grad_norm": 0.0003101301263086498,
      "learning_rate": 2.0771124935199588e-05,
      "loss": 0.0,
      "step": 29080
    },
    {
      "epoch": 5.655132192846034,
      "grad_norm": 0.00025590104633010924,
      "learning_rate": 2.076680490755141e-05,
      "loss": 0.0,
      "step": 29090
    },
    {
      "epoch": 5.657076205287714,
      "grad_norm": 0.0003362104471307248,
      "learning_rate": 2.076248487990323e-05,
      "loss": 0.0,
      "step": 29100
    },
    {
      "epoch": 5.659020217729394,
      "grad_norm": 0.00034064752981066704,
      "learning_rate": 2.0758164852255057e-05,
      "loss": 0.0,
      "step": 29110
    },
    {
      "epoch": 5.660964230171073,
      "grad_norm": 0.0003182128129992634,
      "learning_rate": 2.0753844824606877e-05,
      "loss": 0.0,
      "step": 29120
    },
    {
      "epoch": 5.662908242612753,
      "grad_norm": 0.1336052119731903,
      "learning_rate": 2.07495247969587e-05,
      "loss": 0.0004,
      "step": 29130
    },
    {
      "epoch": 5.6648522550544325,
      "grad_norm": 0.0006279450026340783,
      "learning_rate": 2.0745204769310526e-05,
      "loss": 0.0,
      "step": 29140
    },
    {
      "epoch": 5.666796267496112,
      "grad_norm": 0.00016668364696670324,
      "learning_rate": 2.0740884741662346e-05,
      "loss": 0.0,
      "step": 29150
    },
    {
      "epoch": 5.668740279937792,
      "grad_norm": 0.0002895072102546692,
      "learning_rate": 2.073656471401417e-05,
      "loss": 0.0001,
      "step": 29160
    },
    {
      "epoch": 5.670684292379471,
      "grad_norm": 0.00018189156253356487,
      "learning_rate": 2.0732244686365994e-05,
      "loss": 0.0,
      "step": 29170
    },
    {
      "epoch": 5.672628304821151,
      "grad_norm": 0.00021072456729598343,
      "learning_rate": 2.0727924658717815e-05,
      "loss": 0.0,
      "step": 29180
    },
    {
      "epoch": 5.674572317262831,
      "grad_norm": 0.00027343095280230045,
      "learning_rate": 2.072360463106964e-05,
      "loss": 0.0,
      "step": 29190
    },
    {
      "epoch": 5.67651632970451,
      "grad_norm": 0.00018805573927238584,
      "learning_rate": 2.0719284603421463e-05,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 5.67846034214619,
      "grad_norm": 0.00016976511687971652,
      "learning_rate": 2.0714964575773284e-05,
      "loss": 0.0,
      "step": 29210
    },
    {
      "epoch": 5.6804043545878695,
      "grad_norm": 0.00021254480816423893,
      "learning_rate": 2.0710644548125108e-05,
      "loss": 0.0037,
      "step": 29220
    },
    {
      "epoch": 5.682348367029549,
      "grad_norm": 0.004271421581506729,
      "learning_rate": 2.0706324520476932e-05,
      "loss": 0.0,
      "step": 29230
    },
    {
      "epoch": 5.684292379471229,
      "grad_norm": 0.00021338157239370048,
      "learning_rate": 2.0702004492828753e-05,
      "loss": 0.0,
      "step": 29240
    },
    {
      "epoch": 5.686236391912908,
      "grad_norm": 0.00020286998187657446,
      "learning_rate": 2.0697684465180577e-05,
      "loss": 0.0,
      "step": 29250
    },
    {
      "epoch": 5.688180404354588,
      "grad_norm": 0.00024372436746489257,
      "learning_rate": 2.06933644375324e-05,
      "loss": 0.0,
      "step": 29260
    },
    {
      "epoch": 5.690124416796268,
      "grad_norm": 0.0033040964044630527,
      "learning_rate": 2.0689044409884222e-05,
      "loss": 0.0,
      "step": 29270
    },
    {
      "epoch": 5.692068429237947,
      "grad_norm": 0.00015715054178144783,
      "learning_rate": 2.0684724382236046e-05,
      "loss": 0.0,
      "step": 29280
    },
    {
      "epoch": 5.694012441679627,
      "grad_norm": 0.0002921318809967488,
      "learning_rate": 2.068040435458787e-05,
      "loss": 0.0,
      "step": 29290
    },
    {
      "epoch": 5.695956454121307,
      "grad_norm": 0.0002114827511832118,
      "learning_rate": 2.067608432693969e-05,
      "loss": 0.0,
      "step": 29300
    },
    {
      "epoch": 5.697900466562986,
      "grad_norm": 0.00029449930298142135,
      "learning_rate": 2.0671764299291515e-05,
      "loss": 0.0,
      "step": 29310
    },
    {
      "epoch": 5.699844479004666,
      "grad_norm": 0.0012182049686089158,
      "learning_rate": 2.066744427164334e-05,
      "loss": 0.0,
      "step": 29320
    },
    {
      "epoch": 5.7017884914463455,
      "grad_norm": 0.0002503572904970497,
      "learning_rate": 2.0663124243995163e-05,
      "loss": 0.0,
      "step": 29330
    },
    {
      "epoch": 5.703732503888025,
      "grad_norm": 0.00021472682419698685,
      "learning_rate": 2.0658804216346984e-05,
      "loss": 0.0,
      "step": 29340
    },
    {
      "epoch": 5.705676516329705,
      "grad_norm": 5.781309127807617,
      "learning_rate": 2.0654484188698808e-05,
      "loss": 0.0198,
      "step": 29350
    },
    {
      "epoch": 5.707620528771384,
      "grad_norm": 0.0002938839024864137,
      "learning_rate": 2.0650164161050632e-05,
      "loss": 0.0,
      "step": 29360
    },
    {
      "epoch": 5.709564541213064,
      "grad_norm": 0.00046221690718084574,
      "learning_rate": 2.0645844133402453e-05,
      "loss": 0.0,
      "step": 29370
    },
    {
      "epoch": 5.711508553654744,
      "grad_norm": 0.0002196234418079257,
      "learning_rate": 2.0641524105754277e-05,
      "loss": 0.0,
      "step": 29380
    },
    {
      "epoch": 5.713452566096423,
      "grad_norm": 0.00015742590767331421,
      "learning_rate": 2.06372040781061e-05,
      "loss": 0.0335,
      "step": 29390
    },
    {
      "epoch": 5.715396578538103,
      "grad_norm": 0.000342937302775681,
      "learning_rate": 2.0632884050457922e-05,
      "loss": 0.0,
      "step": 29400
    },
    {
      "epoch": 5.7173405909797825,
      "grad_norm": 0.007117110770195723,
      "learning_rate": 2.0628564022809746e-05,
      "loss": 0.0,
      "step": 29410
    },
    {
      "epoch": 5.719284603421462,
      "grad_norm": 0.006249927915632725,
      "learning_rate": 2.062424399516157e-05,
      "loss": 0.0,
      "step": 29420
    },
    {
      "epoch": 5.721228615863142,
      "grad_norm": 0.001459420076571405,
      "learning_rate": 2.061992396751339e-05,
      "loss": 0.0,
      "step": 29430
    },
    {
      "epoch": 5.723172628304821,
      "grad_norm": 0.00020023998513352126,
      "learning_rate": 2.0615603939865215e-05,
      "loss": 0.0001,
      "step": 29440
    },
    {
      "epoch": 5.725116640746501,
      "grad_norm": 0.6627782583236694,
      "learning_rate": 2.061128391221704e-05,
      "loss": 0.0011,
      "step": 29450
    },
    {
      "epoch": 5.727060653188181,
      "grad_norm": 0.000299976411042735,
      "learning_rate": 2.060696388456886e-05,
      "loss": 0.0093,
      "step": 29460
    },
    {
      "epoch": 5.72900466562986,
      "grad_norm": 0.0011261830804869533,
      "learning_rate": 2.0602643856920684e-05,
      "loss": 0.0006,
      "step": 29470
    },
    {
      "epoch": 5.73094867807154,
      "grad_norm": 0.0003172704018652439,
      "learning_rate": 2.0598323829272508e-05,
      "loss": 0.0062,
      "step": 29480
    },
    {
      "epoch": 5.73289269051322,
      "grad_norm": 0.002322582993656397,
      "learning_rate": 2.059400380162433e-05,
      "loss": 0.0,
      "step": 29490
    },
    {
      "epoch": 5.734836702954899,
      "grad_norm": 0.00023639229766558856,
      "learning_rate": 2.0589683773976153e-05,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 5.736780715396579,
      "grad_norm": 0.0004242096620146185,
      "learning_rate": 2.0585363746327977e-05,
      "loss": 0.0,
      "step": 29510
    },
    {
      "epoch": 5.7387247278382585,
      "grad_norm": 0.00043189222924411297,
      "learning_rate": 2.05810437186798e-05,
      "loss": 0.0124,
      "step": 29520
    },
    {
      "epoch": 5.740668740279938,
      "grad_norm": 0.0001687759067863226,
      "learning_rate": 2.0576723691031625e-05,
      "loss": 0.0,
      "step": 29530
    },
    {
      "epoch": 5.742612752721618,
      "grad_norm": 0.000749637430999428,
      "learning_rate": 2.0572403663383446e-05,
      "loss": 0.0001,
      "step": 29540
    },
    {
      "epoch": 5.744556765163297,
      "grad_norm": 0.00016828937805257738,
      "learning_rate": 2.056808363573527e-05,
      "loss": 0.0066,
      "step": 29550
    },
    {
      "epoch": 5.746500777604977,
      "grad_norm": 0.004624938126653433,
      "learning_rate": 2.0563763608087094e-05,
      "loss": 0.0,
      "step": 29560
    },
    {
      "epoch": 5.748444790046657,
      "grad_norm": 0.002047850750386715,
      "learning_rate": 2.0559443580438915e-05,
      "loss": 0.0008,
      "step": 29570
    },
    {
      "epoch": 5.750388802488336,
      "grad_norm": 0.0006034841644577682,
      "learning_rate": 2.055512355279074e-05,
      "loss": 0.0001,
      "step": 29580
    },
    {
      "epoch": 5.752332814930016,
      "grad_norm": 0.00041785064968280494,
      "learning_rate": 2.0550803525142563e-05,
      "loss": 0.0071,
      "step": 29590
    },
    {
      "epoch": 5.7542768273716955,
      "grad_norm": 0.05063759163022041,
      "learning_rate": 2.0546483497494384e-05,
      "loss": 0.0001,
      "step": 29600
    },
    {
      "epoch": 5.756220839813375,
      "grad_norm": 0.00044932327000424266,
      "learning_rate": 2.0542163469846208e-05,
      "loss": 0.0,
      "step": 29610
    },
    {
      "epoch": 5.758164852255055,
      "grad_norm": 0.0015660268254578114,
      "learning_rate": 2.0537843442198032e-05,
      "loss": 0.0027,
      "step": 29620
    },
    {
      "epoch": 5.760108864696734,
      "grad_norm": 0.0011240205494686961,
      "learning_rate": 2.0533523414549853e-05,
      "loss": 0.0,
      "step": 29630
    },
    {
      "epoch": 5.762052877138414,
      "grad_norm": 0.00020249266526661813,
      "learning_rate": 2.0529203386901677e-05,
      "loss": 0.0,
      "step": 29640
    },
    {
      "epoch": 5.763996889580094,
      "grad_norm": 0.0001713876990834251,
      "learning_rate": 2.05248833592535e-05,
      "loss": 0.001,
      "step": 29650
    },
    {
      "epoch": 5.765940902021773,
      "grad_norm": 0.00021161968470551074,
      "learning_rate": 2.052056333160532e-05,
      "loss": 0.0,
      "step": 29660
    },
    {
      "epoch": 5.767884914463453,
      "grad_norm": 0.0020011714659631252,
      "learning_rate": 2.0516243303957146e-05,
      "loss": 0.0,
      "step": 29670
    },
    {
      "epoch": 5.769828926905133,
      "grad_norm": 0.007395491003990173,
      "learning_rate": 2.051192327630897e-05,
      "loss": 0.0,
      "step": 29680
    },
    {
      "epoch": 5.771772939346812,
      "grad_norm": 0.00017001351807266474,
      "learning_rate": 2.050760324866079e-05,
      "loss": 0.0,
      "step": 29690
    },
    {
      "epoch": 5.773716951788492,
      "grad_norm": 0.00018007977632805705,
      "learning_rate": 2.0503283221012618e-05,
      "loss": 0.0,
      "step": 29700
    },
    {
      "epoch": 5.7756609642301715,
      "grad_norm": 0.00023904738191049546,
      "learning_rate": 2.049896319336444e-05,
      "loss": 0.0,
      "step": 29710
    },
    {
      "epoch": 5.777604976671851,
      "grad_norm": 0.0002283517678733915,
      "learning_rate": 2.049464316571626e-05,
      "loss": 0.0,
      "step": 29720
    },
    {
      "epoch": 5.779548989113531,
      "grad_norm": 0.0002626261848490685,
      "learning_rate": 2.0490323138068087e-05,
      "loss": 0.0001,
      "step": 29730
    },
    {
      "epoch": 5.78149300155521,
      "grad_norm": 0.6708336472511292,
      "learning_rate": 2.0486003110419908e-05,
      "loss": 0.0002,
      "step": 29740
    },
    {
      "epoch": 5.78343701399689,
      "grad_norm": 0.00020478945225477219,
      "learning_rate": 2.048168308277173e-05,
      "loss": 0.0002,
      "step": 29750
    },
    {
      "epoch": 5.78538102643857,
      "grad_norm": 0.00018746816203929484,
      "learning_rate": 2.0477363055123556e-05,
      "loss": 0.0,
      "step": 29760
    },
    {
      "epoch": 5.787325038880249,
      "grad_norm": 0.0001639797555981204,
      "learning_rate": 2.0473043027475377e-05,
      "loss": 0.0167,
      "step": 29770
    },
    {
      "epoch": 5.789269051321929,
      "grad_norm": 0.0004274285165593028,
      "learning_rate": 2.0468722999827197e-05,
      "loss": 0.0028,
      "step": 29780
    },
    {
      "epoch": 5.791213063763609,
      "grad_norm": 0.0003935498825740069,
      "learning_rate": 2.0464402972179025e-05,
      "loss": 0.0,
      "step": 29790
    },
    {
      "epoch": 5.793157076205288,
      "grad_norm": 0.00019532917940523475,
      "learning_rate": 2.0460082944530846e-05,
      "loss": 0.0001,
      "step": 29800
    },
    {
      "epoch": 5.795101088646968,
      "grad_norm": 0.00016923781367950141,
      "learning_rate": 2.0455762916882666e-05,
      "loss": 0.0217,
      "step": 29810
    },
    {
      "epoch": 5.7970451010886475,
      "grad_norm": 0.00025204510893672705,
      "learning_rate": 2.0451442889234494e-05,
      "loss": 0.0,
      "step": 29820
    },
    {
      "epoch": 5.798989113530327,
      "grad_norm": 0.00024339811352547258,
      "learning_rate": 2.0447122861586315e-05,
      "loss": 0.0,
      "step": 29830
    },
    {
      "epoch": 5.800933125972006,
      "grad_norm": 0.00020964402938261628,
      "learning_rate": 2.0442802833938135e-05,
      "loss": 0.0,
      "step": 29840
    },
    {
      "epoch": 5.8028771384136855,
      "grad_norm": 0.00016070604033302516,
      "learning_rate": 2.0438482806289963e-05,
      "loss": 0.0,
      "step": 29850
    },
    {
      "epoch": 5.804821150855365,
      "grad_norm": 0.00025857536820694804,
      "learning_rate": 2.0434162778641784e-05,
      "loss": 0.0,
      "step": 29860
    },
    {
      "epoch": 5.806765163297045,
      "grad_norm": 0.00016287638572975993,
      "learning_rate": 2.0429842750993604e-05,
      "loss": 0.0,
      "step": 29870
    },
    {
      "epoch": 5.808709175738724,
      "grad_norm": 0.00017908313020598143,
      "learning_rate": 2.0425522723345432e-05,
      "loss": 0.0,
      "step": 29880
    },
    {
      "epoch": 5.810653188180404,
      "grad_norm": 0.0016219638055190444,
      "learning_rate": 2.0421202695697252e-05,
      "loss": 0.0,
      "step": 29890
    },
    {
      "epoch": 5.812597200622084,
      "grad_norm": 0.00018999596068169922,
      "learning_rate": 2.0416882668049077e-05,
      "loss": 0.0,
      "step": 29900
    },
    {
      "epoch": 5.814541213063763,
      "grad_norm": 0.00020783903892152011,
      "learning_rate": 2.04125626404009e-05,
      "loss": 0.0,
      "step": 29910
    },
    {
      "epoch": 5.816485225505443,
      "grad_norm": 0.00017846765695139766,
      "learning_rate": 2.040824261275272e-05,
      "loss": 0.0,
      "step": 29920
    },
    {
      "epoch": 5.8184292379471225,
      "grad_norm": 0.014891130849719048,
      "learning_rate": 2.0403922585104546e-05,
      "loss": 0.0289,
      "step": 29930
    },
    {
      "epoch": 5.820373250388802,
      "grad_norm": 0.002868375973775983,
      "learning_rate": 2.039960255745637e-05,
      "loss": 0.0012,
      "step": 29940
    },
    {
      "epoch": 5.822317262830482,
      "grad_norm": 0.0022575468756258488,
      "learning_rate": 2.039528252980819e-05,
      "loss": 0.0002,
      "step": 29950
    },
    {
      "epoch": 5.824261275272161,
      "grad_norm": 0.0011892645852640271,
      "learning_rate": 2.0390962502160014e-05,
      "loss": 0.0001,
      "step": 29960
    },
    {
      "epoch": 5.826205287713841,
      "grad_norm": 0.0007395628490485251,
      "learning_rate": 2.038664247451184e-05,
      "loss": 0.0001,
      "step": 29970
    },
    {
      "epoch": 5.828149300155521,
      "grad_norm": 0.0012236618204042315,
      "learning_rate": 2.038232244686366e-05,
      "loss": 0.0,
      "step": 29980
    },
    {
      "epoch": 5.8300933125972,
      "grad_norm": 0.0015039652353152633,
      "learning_rate": 2.0378002419215483e-05,
      "loss": 0.0192,
      "step": 29990
    },
    {
      "epoch": 5.83203732503888,
      "grad_norm": 0.0014874290209263563,
      "learning_rate": 2.0373682391567308e-05,
      "loss": 0.0002,
      "step": 30000
    },
    {
      "epoch": 5.83398133748056,
      "grad_norm": 0.002620136132463813,
      "learning_rate": 2.0369362363919128e-05,
      "loss": 0.0001,
      "step": 30010
    },
    {
      "epoch": 5.835925349922239,
      "grad_norm": 0.0005514616495929658,
      "learning_rate": 2.0365042336270952e-05,
      "loss": 0.0,
      "step": 30020
    },
    {
      "epoch": 5.837869362363919,
      "grad_norm": 0.0016135129844769835,
      "learning_rate": 2.0360722308622776e-05,
      "loss": 0.0001,
      "step": 30030
    },
    {
      "epoch": 5.8398133748055985,
      "grad_norm": 0.0008062177221290767,
      "learning_rate": 2.0356402280974597e-05,
      "loss": 0.0,
      "step": 30040
    },
    {
      "epoch": 5.841757387247278,
      "grad_norm": 0.0019160234369337559,
      "learning_rate": 2.035208225332642e-05,
      "loss": 0.0043,
      "step": 30050
    },
    {
      "epoch": 5.843701399688958,
      "grad_norm": 0.000955602212343365,
      "learning_rate": 2.0347762225678245e-05,
      "loss": 0.0,
      "step": 30060
    },
    {
      "epoch": 5.845645412130637,
      "grad_norm": 0.0009050645167008042,
      "learning_rate": 2.0343442198030066e-05,
      "loss": 0.0,
      "step": 30070
    },
    {
      "epoch": 5.847589424572317,
      "grad_norm": 0.0003265859268140048,
      "learning_rate": 2.033912217038189e-05,
      "loss": 0.0001,
      "step": 30080
    },
    {
      "epoch": 5.849533437013997,
      "grad_norm": 0.0004481444775592536,
      "learning_rate": 2.0334802142733714e-05,
      "loss": 0.0001,
      "step": 30090
    },
    {
      "epoch": 5.851477449455676,
      "grad_norm": 0.0011976982932537794,
      "learning_rate": 2.033048211508554e-05,
      "loss": 0.0,
      "step": 30100
    },
    {
      "epoch": 5.853421461897356,
      "grad_norm": 0.0004018476465716958,
      "learning_rate": 2.032616208743736e-05,
      "loss": 0.0,
      "step": 30110
    },
    {
      "epoch": 5.8553654743390355,
      "grad_norm": 0.00033736912882886827,
      "learning_rate": 2.0321842059789183e-05,
      "loss": 0.0024,
      "step": 30120
    },
    {
      "epoch": 5.857309486780715,
      "grad_norm": 0.0034348226618021727,
      "learning_rate": 2.0317522032141007e-05,
      "loss": 0.0,
      "step": 30130
    },
    {
      "epoch": 5.859253499222395,
      "grad_norm": 0.0007548494613729417,
      "learning_rate": 2.0313202004492828e-05,
      "loss": 0.0122,
      "step": 30140
    },
    {
      "epoch": 5.861197511664074,
      "grad_norm": 33.54035568237305,
      "learning_rate": 2.0308881976844652e-05,
      "loss": 0.0233,
      "step": 30150
    },
    {
      "epoch": 5.863141524105754,
      "grad_norm": 0.0005655708955600858,
      "learning_rate": 2.0304561949196476e-05,
      "loss": 0.0,
      "step": 30160
    },
    {
      "epoch": 5.865085536547434,
      "grad_norm": 0.00042873583151958883,
      "learning_rate": 2.0300241921548297e-05,
      "loss": 0.0,
      "step": 30170
    },
    {
      "epoch": 5.867029548989113,
      "grad_norm": 0.0003702020621858537,
      "learning_rate": 2.029592189390012e-05,
      "loss": 0.0,
      "step": 30180
    },
    {
      "epoch": 5.868973561430793,
      "grad_norm": 0.0006329884054139256,
      "learning_rate": 2.0291601866251945e-05,
      "loss": 0.0041,
      "step": 30190
    },
    {
      "epoch": 5.870917573872473,
      "grad_norm": 0.00025639653904363513,
      "learning_rate": 2.0287281838603766e-05,
      "loss": 0.0,
      "step": 30200
    },
    {
      "epoch": 5.872861586314152,
      "grad_norm": 0.0004007115785498172,
      "learning_rate": 2.028296181095559e-05,
      "loss": 0.0,
      "step": 30210
    },
    {
      "epoch": 5.874805598755832,
      "grad_norm": 0.03837648779153824,
      "learning_rate": 2.0278641783307414e-05,
      "loss": 0.0001,
      "step": 30220
    },
    {
      "epoch": 5.8767496111975115,
      "grad_norm": 0.0003058875445276499,
      "learning_rate": 2.0274321755659235e-05,
      "loss": 0.0001,
      "step": 30230
    },
    {
      "epoch": 5.878693623639191,
      "grad_norm": 0.00030889458139427006,
      "learning_rate": 2.027000172801106e-05,
      "loss": 0.0155,
      "step": 30240
    },
    {
      "epoch": 5.880637636080871,
      "grad_norm": 0.0006279832450672984,
      "learning_rate": 2.0265681700362883e-05,
      "loss": 0.0,
      "step": 30250
    },
    {
      "epoch": 5.88258164852255,
      "grad_norm": 0.0004840217006858438,
      "learning_rate": 2.0261361672714704e-05,
      "loss": 0.0002,
      "step": 30260
    },
    {
      "epoch": 5.88452566096423,
      "grad_norm": 0.0004912810400128365,
      "learning_rate": 2.0257041645066528e-05,
      "loss": 0.0,
      "step": 30270
    },
    {
      "epoch": 5.88646967340591,
      "grad_norm": 0.0006249268190003932,
      "learning_rate": 2.0252721617418352e-05,
      "loss": 0.0,
      "step": 30280
    },
    {
      "epoch": 5.888413685847589,
      "grad_norm": 0.00027259765192866325,
      "learning_rate": 2.0248401589770173e-05,
      "loss": 0.0,
      "step": 30290
    },
    {
      "epoch": 5.890357698289269,
      "grad_norm": 0.000865280395373702,
      "learning_rate": 2.0244081562122e-05,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 5.8923017107309485,
      "grad_norm": 0.00033794084447436035,
      "learning_rate": 2.023976153447382e-05,
      "loss": 0.0001,
      "step": 30310
    },
    {
      "epoch": 5.894245723172628,
      "grad_norm": 0.0002958620898425579,
      "learning_rate": 2.0235441506825642e-05,
      "loss": 0.0,
      "step": 30320
    },
    {
      "epoch": 5.896189735614308,
      "grad_norm": 0.0004842762718908489,
      "learning_rate": 2.023112147917747e-05,
      "loss": 0.0,
      "step": 30330
    },
    {
      "epoch": 5.8981337480559874,
      "grad_norm": 0.0004282548907212913,
      "learning_rate": 2.022680145152929e-05,
      "loss": 0.0,
      "step": 30340
    },
    {
      "epoch": 5.900077760497667,
      "grad_norm": 0.000367457396350801,
      "learning_rate": 2.022248142388111e-05,
      "loss": 0.0,
      "step": 30350
    },
    {
      "epoch": 5.902021772939347,
      "grad_norm": 0.0004310726362746209,
      "learning_rate": 2.0218161396232938e-05,
      "loss": 0.0,
      "step": 30360
    },
    {
      "epoch": 5.903965785381026,
      "grad_norm": 0.0003290453751105815,
      "learning_rate": 2.021384136858476e-05,
      "loss": 0.0001,
      "step": 30370
    },
    {
      "epoch": 5.905909797822706,
      "grad_norm": 0.0002220961614511907,
      "learning_rate": 2.020952134093658e-05,
      "loss": 0.0,
      "step": 30380
    },
    {
      "epoch": 5.907853810264386,
      "grad_norm": 0.0002677059092093259,
      "learning_rate": 2.0205201313288407e-05,
      "loss": 0.0,
      "step": 30390
    },
    {
      "epoch": 5.909797822706065,
      "grad_norm": 0.00045624878839589655,
      "learning_rate": 2.0200881285640228e-05,
      "loss": 0.0012,
      "step": 30400
    },
    {
      "epoch": 5.911741835147745,
      "grad_norm": 0.0002594945835880935,
      "learning_rate": 2.019656125799205e-05,
      "loss": 0.0,
      "step": 30410
    },
    {
      "epoch": 5.9136858475894245,
      "grad_norm": 0.003482327563688159,
      "learning_rate": 2.0192241230343876e-05,
      "loss": 0.0,
      "step": 30420
    },
    {
      "epoch": 5.915629860031104,
      "grad_norm": 0.0009459654684178531,
      "learning_rate": 2.0187921202695697e-05,
      "loss": 0.0,
      "step": 30430
    },
    {
      "epoch": 5.917573872472784,
      "grad_norm": 0.00022754403471481055,
      "learning_rate": 2.018360117504752e-05,
      "loss": 0.0,
      "step": 30440
    },
    {
      "epoch": 5.919517884914463,
      "grad_norm": 0.000416413793573156,
      "learning_rate": 2.0179281147399345e-05,
      "loss": 0.0016,
      "step": 30450
    },
    {
      "epoch": 5.921461897356143,
      "grad_norm": 0.00043921777978539467,
      "learning_rate": 2.0174961119751166e-05,
      "loss": 0.0,
      "step": 30460
    },
    {
      "epoch": 5.923405909797823,
      "grad_norm": 0.0002356609475100413,
      "learning_rate": 2.017064109210299e-05,
      "loss": 0.0,
      "step": 30470
    },
    {
      "epoch": 5.925349922239502,
      "grad_norm": 0.0002090316265821457,
      "learning_rate": 2.0166321064454814e-05,
      "loss": 0.0009,
      "step": 30480
    },
    {
      "epoch": 5.927293934681182,
      "grad_norm": 0.00025685701984912157,
      "learning_rate": 2.0162001036806635e-05,
      "loss": 0.0001,
      "step": 30490
    },
    {
      "epoch": 5.929237947122862,
      "grad_norm": 0.00026418804191052914,
      "learning_rate": 2.0157681009158462e-05,
      "loss": 0.0001,
      "step": 30500
    },
    {
      "epoch": 5.931181959564541,
      "grad_norm": 0.0002634634729474783,
      "learning_rate": 2.0153360981510283e-05,
      "loss": 0.0,
      "step": 30510
    },
    {
      "epoch": 5.933125972006221,
      "grad_norm": 0.00027308985590934753,
      "learning_rate": 2.0149040953862104e-05,
      "loss": 0.0,
      "step": 30520
    },
    {
      "epoch": 5.9350699844479005,
      "grad_norm": 0.00028937775641679764,
      "learning_rate": 2.014472092621393e-05,
      "loss": 0.0008,
      "step": 30530
    },
    {
      "epoch": 5.93701399688958,
      "grad_norm": 0.00029176456155255437,
      "learning_rate": 2.0140400898565752e-05,
      "loss": 0.0013,
      "step": 30540
    },
    {
      "epoch": 5.93895800933126,
      "grad_norm": 0.00045210865209810436,
      "learning_rate": 2.0136080870917573e-05,
      "loss": 0.0,
      "step": 30550
    },
    {
      "epoch": 5.940902021772939,
      "grad_norm": 0.00024706171825528145,
      "learning_rate": 2.01317608432694e-05,
      "loss": 0.0,
      "step": 30560
    },
    {
      "epoch": 5.942846034214619,
      "grad_norm": 0.00031900283647701144,
      "learning_rate": 2.012744081562122e-05,
      "loss": 0.0005,
      "step": 30570
    },
    {
      "epoch": 5.944790046656299,
      "grad_norm": 0.00015939550939947367,
      "learning_rate": 2.012312078797304e-05,
      "loss": 0.0,
      "step": 30580
    },
    {
      "epoch": 5.946734059097978,
      "grad_norm": 0.001570648280903697,
      "learning_rate": 2.011880076032487e-05,
      "loss": 0.0,
      "step": 30590
    },
    {
      "epoch": 5.948678071539658,
      "grad_norm": 0.00016866203804966062,
      "learning_rate": 2.011448073267669e-05,
      "loss": 0.0,
      "step": 30600
    },
    {
      "epoch": 5.9506220839813375,
      "grad_norm": 0.01917416788637638,
      "learning_rate": 2.011016070502851e-05,
      "loss": 0.0,
      "step": 30610
    },
    {
      "epoch": 5.952566096423017,
      "grad_norm": 0.000229593861149624,
      "learning_rate": 2.0105840677380338e-05,
      "loss": 0.0,
      "step": 30620
    },
    {
      "epoch": 5.954510108864697,
      "grad_norm": 0.00029870777507312596,
      "learning_rate": 2.010152064973216e-05,
      "loss": 0.0,
      "step": 30630
    },
    {
      "epoch": 5.956454121306376,
      "grad_norm": 0.0001667713950155303,
      "learning_rate": 2.009720062208398e-05,
      "loss": 0.0,
      "step": 30640
    },
    {
      "epoch": 5.958398133748056,
      "grad_norm": 0.00026483958936296403,
      "learning_rate": 2.0092880594435807e-05,
      "loss": 0.0,
      "step": 30650
    },
    {
      "epoch": 5.960342146189736,
      "grad_norm": 0.0002265166986035183,
      "learning_rate": 2.0088560566787628e-05,
      "loss": 0.0,
      "step": 30660
    },
    {
      "epoch": 5.962286158631415,
      "grad_norm": 0.00021525569900404662,
      "learning_rate": 2.0084240539139452e-05,
      "loss": 0.0,
      "step": 30670
    },
    {
      "epoch": 5.964230171073095,
      "grad_norm": 0.000261913170106709,
      "learning_rate": 2.0079920511491276e-05,
      "loss": 0.0001,
      "step": 30680
    },
    {
      "epoch": 5.966174183514775,
      "grad_norm": 0.00017587242473382503,
      "learning_rate": 2.0075600483843097e-05,
      "loss": 0.0,
      "step": 30690
    },
    {
      "epoch": 5.968118195956454,
      "grad_norm": 0.0001510010624770075,
      "learning_rate": 2.007128045619492e-05,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 5.970062208398134,
      "grad_norm": 0.0002337745245313272,
      "learning_rate": 2.0066960428546745e-05,
      "loss": 0.0,
      "step": 30710
    },
    {
      "epoch": 5.9720062208398135,
      "grad_norm": 0.000247712159762159,
      "learning_rate": 2.0062640400898566e-05,
      "loss": 0.0,
      "step": 30720
    },
    {
      "epoch": 5.973950233281493,
      "grad_norm": 0.00019420208991505206,
      "learning_rate": 2.005832037325039e-05,
      "loss": 0.0,
      "step": 30730
    },
    {
      "epoch": 5.975894245723173,
      "grad_norm": 0.00023779863840900362,
      "learning_rate": 2.0054000345602214e-05,
      "loss": 0.0,
      "step": 30740
    },
    {
      "epoch": 5.977838258164852,
      "grad_norm": 0.0002724651130847633,
      "learning_rate": 2.0049680317954035e-05,
      "loss": 0.0,
      "step": 30750
    },
    {
      "epoch": 5.979782270606532,
      "grad_norm": 0.00018265368998982012,
      "learning_rate": 2.004536029030586e-05,
      "loss": 0.0,
      "step": 30760
    },
    {
      "epoch": 5.981726283048212,
      "grad_norm": 0.0002492407220415771,
      "learning_rate": 2.0041040262657683e-05,
      "loss": 0.0,
      "step": 30770
    },
    {
      "epoch": 5.983670295489891,
      "grad_norm": 0.00023641661391593516,
      "learning_rate": 2.0036720235009503e-05,
      "loss": 0.0,
      "step": 30780
    },
    {
      "epoch": 5.985614307931571,
      "grad_norm": 0.00020058501104358584,
      "learning_rate": 2.0032400207361328e-05,
      "loss": 0.0,
      "step": 30790
    },
    {
      "epoch": 5.9875583203732505,
      "grad_norm": 0.0002203310577897355,
      "learning_rate": 2.002808017971315e-05,
      "loss": 0.0438,
      "step": 30800
    },
    {
      "epoch": 5.98950233281493,
      "grad_norm": 0.00024618604220449924,
      "learning_rate": 2.0023760152064972e-05,
      "loss": 0.0,
      "step": 30810
    },
    {
      "epoch": 5.99144634525661,
      "grad_norm": 0.00026437226915732026,
      "learning_rate": 2.0019440124416797e-05,
      "loss": 0.0,
      "step": 30820
    },
    {
      "epoch": 5.993390357698289,
      "grad_norm": 0.0001657154061831534,
      "learning_rate": 2.001512009676862e-05,
      "loss": 0.0,
      "step": 30830
    },
    {
      "epoch": 5.995334370139969,
      "grad_norm": 0.0007354448898695409,
      "learning_rate": 2.001080006912044e-05,
      "loss": 0.0096,
      "step": 30840
    },
    {
      "epoch": 5.997278382581649,
      "grad_norm": 0.037582576274871826,
      "learning_rate": 2.0006480041472265e-05,
      "loss": 0.0,
      "step": 30850
    },
    {
      "epoch": 5.999222395023328,
      "grad_norm": 0.00028773394296877086,
      "learning_rate": 2.000216001382409e-05,
      "loss": 0.0,
      "step": 30860
    },
    {
      "epoch": 6.0,
      "eval_f1": 0.996487180831542,
      "eval_loss": 0.01357267890125513,
      "eval_report": {
        "PRODUCT": {
          "f1-score": 0.996487180831542,
          "precision": 0.9960171889739021,
          "recall": 0.9969576164498531,
          "support": 9532
        },
        "macro avg": {
          "f1-score": 0.996487180831542,
          "precision": 0.9960171889739021,
          "recall": 0.9969576164498531,
          "support": 9532
        },
        "micro avg": {
          "f1-score": 0.996487180831542,
          "precision": 0.9960171889739021,
          "recall": 0.9969576164498531,
          "support": 9532
        },
        "weighted avg": {
          "f1-score": 0.9964871808315421,
          "precision": 0.9960171889739021,
          "recall": 0.9969576164498531,
          "support": 9532
        }
      },
      "eval_runtime": 74.3126,
      "eval_samples_per_second": 103.172,
      "eval_steps_per_second": 12.905,
      "step": 30864
    }
  ],
  "logging_steps": 10,
  "max_steps": 77160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2439745792275312.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
